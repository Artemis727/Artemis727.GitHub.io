[{"title":"CART | Errors in CART","url":"/2023/09/18/CART-Errors-in-CART/","content":"CART全称是Classification and Regression Trees。\n“Trainset error” 和 “CV error”对于 CART（Classification and Regression Trees）算法，”Trainset error” 和 “CV error” 分别代表了两种不同的误差度量：\n\nTrainset Error（训练集误差）：\n这是在构建决策树时使用训练数据集来评估模型的误差。具体来说，它是指模型在训练数据集上的预测误差或者拟合不准确度。训练集误差通常是通过将模型对训练数据集的预测与实际观测值进行比较来计算的。\n训练集误差的一个问题是它可能会过于乐观地估计了模型的性能，因为模型在训练数据上进行了拟合。这可能导致模型在未见过的新数据上的性能表现不佳。\n\nCross-Validation Error（交叉验证误差）：\n为了更准确地评估模型的性能，通常会将数据分成训练集和测试集两部分。交叉验证（Cross-Validation）是一种常用的方法，它将数据分成多个折（folds），然后分别使用其中一个折作为测试集，其余折作为训练集来训练模型。这样可以多次进行模型训练和评估，从而得到一个更稳健的性能估计。\nCV error 是在交叉验证中得到的，它表示模型在不同的测试集上的平均预测误差。通常，通过计算多次交叉验证的结果的平均值来得到最终的 CV error。\n\n\n总的来说，Trainset Error 是在训练数据上的误差，它可能会过于乐观地估计模型的性能；而 CV error 则是通过在多次独立的测试集上进行交叉验证得到的，它提供了对模型在未见过的数据上性能的更稳健的估计。 CV error 通常被认为是对模型性能的更可靠的评估。\n解释一个CP table一个 CART（Classification and Regression Trees）模型的 cp table 包含了与树的复杂度参数（通常用 α 表示）相关的信息。CART 模型会根据训练数据构建一棵树，但这棵树可能会过于复杂，导致在训练数据上表现很好，但在未见过的数据上表现较差（过拟合）。\ncp table 提供了一种帮助找到适当树大小的方法。其中 cp 代表复杂度参数，它可以理解为控制树的复杂程度的一个调节参数。\ncp table 通常包括以下列：\n\nCP（复杂度参数）：\n\n这列列出了不同的复杂度参数值。它们是一个递减的有序序列，从最大的复杂度开始，逐渐减小。\n\n\nrel error（相对误差）：\n\n这列列出了在给定复杂度参数下，与完全展开的树相比，模型的相对误差。相对误差是模型的预测误差与完全展开树的预测误差之比。\n\n\nxerror（交叉验证误差）：\n\n这列列出了在给定复杂度参数下，通过交叉验证得到的模型的平均预测误差。\n\n\nxstd（交叉验证误差的标准差）：\n\n这列列出了在给定复杂度参数下，通过交叉验证得到的模型的平均预测误差的标准差。\n\n\n\n解释一个 cp table 的过程通常包括以下步骤：\n\n选择最小的 CP 值：通常会选择具有最小相对误差或交叉验证误差的复杂度参数作为最终模型的复杂度参数。\n\n对比相对误差和交叉验证误差：相对误差提供了一种在训练集上进行模型评估的方法，而交叉验证误差提供了对模型在未见过数据上的性能的估计。\n\n考虑模型的解释性和复杂度：选择一个合适的复杂度参数需要在模型的性能和复杂度之间进行权衡。更复杂的模型可能在训练数据上表现得更好，但可能在新数据上表现较差。\n\n\n总的来说，cp table 提供了一个帮助找到合适树大小的指南，以避免过拟合和提高模型的泛化能力。\n","tags":["算法"]},{"title":"CART｜CART的各种误差","url":"/2023/03/21/CART%EF%BD%9C%22Trainset%20error%22%20%E5%92%8C%20%22CV%20error%22%20/","content":""},{"title":"NLP｜命名实体识别","url":"/2023/03/21/NLP%EF%BD%9C%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/","content":"中文命名实体识别（Named Entity Recognition，简称NER）标注中常用的标签如下。每个标签都表示一种命名实体类型。\n\nO（大写字母O）表示该词不是命名实体，即other。\nS 表示该词是单独成一个实体。\nB 表示该词是一个实体的开头。\nI 表示该词是一个实体的中间部分。\nE 表示该词是一个实体的结束部分。\n\nNh、Ni、Ns 等则表示命名实体的具体类别，如人名、机构名、地名等。\nntag[-2:] 表示将 ntag 字符串的最后两个字符截取出来作为新的字符串，因为在这个代码段中，实体标记（entity tag）总是由一个标记类型和一个 B、I、E 或 S 等指示词组成的，如 B-Nh 表示一个人名实体的开头，而 I-Nh 表示人名实体的中间部分，E-Nh 表示人名实体的结尾部分，S-Nh 表示独立成词的人名实体。由此可知，实体标记的类型总是在字符串的最后两个字符中，因此这个代码中使用 [-2:] 来取出实体标记类型。\n","tags":["NLP"]},{"title":"SQL｜刷题笔记","url":"/2023/02/07/SQL%EF%BD%9C%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/","content":"1. 查询列列查询、多列查询、限制返回数量、in、like、聚合函数。\n# 查询所有列SELECT * FROM user_profile# 查询多列SELECT device_id, gender, age, university FROM user_profile# 查询结果去重SELECT DISTINCT university FROM user_profile# 查询结果限制返回行数SELECT device_id FROM user_profile LIMIT 2# 查询后重命名SELECT device_id FROM user_profile AS user_infos_example LIMIT 2# 否定查询select device_id, gender, age, universityfrom user_profilewhere not university = &#x27;复旦大学&#x27;# 过滤空值select device_id, gender, age, universityfrom user_profilewhere not age is null# inselect device_id, gender, age, university, gpa from user_profilewhere university in (&#x27;北京大学&#x27;, &#x27;复旦大学&#x27;, &#x27;山东大学&#x27;)# likeselect device_id, age, universityfrom user_profilewhere university like &#x27;%北京%&#x27;# max() min()select max(gpa)from user_profilewhere university = &#x27;复旦大学&#x27;# avg() count()select count(gender) as male_num, avg(gpa) as avg_gpafrom user_profilewhere gender = &#x27;male&#x27;# havingselect university, avg(question_cnt) avg_question_cnt, avg(answer_cnt) avg_answer_cntfrom user_profilegroup by universityhaving avg_question_cnt &lt; 5 or avg_answer_cnt &lt; 20# 生成新字段后不能用where要用having\n\n\n\n2. 涉及到多个表的情况select university, (count(q.question_id)/count(distinct(q.device_id))) avg_answer_cntfrom user_profile ujoin question_practice_detail qon u.device_id = q.device_idgroup by universityorder by university asc\n\nselect u.university, q.difficult_level, count(qp.question_id)/count(distinct qp.device_id) avg_answer_cntfrom user_profile u, question_practice_detail qp, question_detail qwhere u.university = &#x27;山东大学&#x27; and u.device_id = qp.device_id and q.question_id = qp.question_idgroup by u.university, difficult_levelorder by avg_answer_cnt\n\n\n\nSQL25 查找山东大学或者性别为男生的信息题目：现在运营想要分别查看学校为山东大学或者性别为男性的用户的device_id、gender、age和gpa数据，请取出相应结果，结果不去重。\n示例：user_profile\n\n\n\nid\ndevice_id\ngender\nage\nuniversity\ngpa\nactive_days_within_30\nquestion_cnt\nanswer_cnt\n\n\n\n1\n2138\nmale\n21\n北京大学\n3.4\n7\n2\n12\n\n\n2\n3214\nmale\n\n复旦大学\n4\n15\n5\n25\n\n\n3\n6543\nfemale\n20\n北京大学\n3.2\n12\n3\n30\n\n\n4\n2315\nfemale\n23\n浙江大学\n3.6\n5\n1\n2\n\n\n5\n5432\nmale\n25\n山东大学\n3.8\n20\n15\n70\n\n\n6\n2131\nmale\n28\n山东大学\n3.3\n15\n7\n13\n\n\n7\n4321\nmale\n26\n复旦大学\n3.6\n9\n6\n52\n\n\n根据示例，你的查询应返回以下结果（注意输出的顺序，先输出学校为山东大学再输出性别为男生的信息）：\n\n\n\ndevice_id\ngender\nage\ngpa\n\n\n\n5432\nmale\n25\n3.8\n\n\n2131\nmale\n28\n3.3\n\n\n2138\nmale\n21\n3.4\n\n\n3214\nmale\nNone\n4\n\n\n5432\nmale\n25\n3.8\n\n\n2131\nmale\n28\n3.3\n\n\n4321\nmale\n28\n3.6\n\n\nselect device_id, gender, age, gpafrom user_profilewhere university = &#x27;山东大学&#x27;union all select device_id, gender, age, gpafrom user_profilewhere gender = &#x27;male&#x27;\n\nunion可以，但是结果是去重的，所以要用union all。\nwhere gender = ‘male’ or university = ‘山东大学’也不行，结果也是去重的。\n3. ifSQL26 计算25岁以上和以下的用户数量题目：现在运营想要将用户划分为25岁以下和25岁及以上两个年龄段，分别查看这两个年龄段用户数量\n本题注意：age为null 也记为 25岁以下\n示例：user_profile\n\n\n\nid\ndevice_id\ngender\nage\nuniversity\ngpa\nactive_days_within_30\nquestion_cnt\nanswer_cnt\n\n\n\n1\n2138\nmale\n21\n北京大学\n3.4\n7\n2\n12\n\n\n2\n3214\nmale\n\n复旦大学\n4\n15\n5\n25\n\n\n3\n6543\nfemale\n20\n北京大学\n3.2\n12\n3\n30\n\n\n4\n2315\nfemale\n23\n浙江大学\n3.6\n5\n1\n2\n\n\n5\n5432\nmale\n25\n山东大学\n3.8\n20\n15\n70\n\n\n6\n2131\nmale\n28\n山东大学\n3.3\n15\n7\n13\n\n\n7\n4321\nmale\n26\n复旦大学\n3.6\n9\n6\n52\n\n\n根据示例，你的查询应返回以下结果：\n\n\n\nage_cut\nnumber\n\n\n\n25岁以下\n4\n\n\n25岁及以上\n3\n\n\nselect age_cut, count(device_id) numberfrom(select if(age &gt;= 25, &#x27;25岁及以上&#x27;, &#x27;25岁以下&#x27;) as age_cut, device_id from user_profile) t1group by age_cut\n\n\n\n4. caseSQL27 查看不同年龄段的用户明细题目：现在运营想要将用户划分为20岁以下，20-24岁，25岁及以上三个年龄段，分别查看不同年龄段用户的明细情况，请取出相应数据。（注：若年龄为空请返回其他。）\n示例：user_profile\n\n\n\nid\ndevice_id\ngender\nage\nuniversity\ngpa\nactive_days_within_30\nquestion_cnt\nanswer_cnt\n\n\n\n1\n2138\nmale\n21\n北京大学\n3.4\n7\n2\n12\n\n\n2\n3214\nmale\n\n复旦大学\n4\n15\n5\n25\n\n\n3\n6543\nfemale\n20\n北京大学\n3.2\n12\n3\n30\n\n\n4\n2315\nfemale\n23\n浙江大学\n3.6\n5\n1\n2\n\n\n5\n5432\nmale\n25\n山东大学\n3.8\n20\n15\n70\n\n\n6\n2131\nmale\n28\n山东大学\n3.3\n15\n7\n13\n\n\n7\n4321\nmale\n26\n复旦大学\n3.6\n9\n6\n52\n\n\n根据示例，你的查询应返回以下结果：\n\n\n\ndevice_id\ngender\nage_cut\n\n\n\n2138\nmale\n20-24岁\n\n\n3214\nmale\n其他\n\n\n6543\nfemale\n20-24岁\n\n\n2315\nfemale\n20-24岁\n\n\n5432\nmale\n25岁及以上\n\n\n2131\nmale\n25岁及以上\n\n\n4321\nmale\n25岁及以上\n\n\nselect device_id, gender, case    when age &lt; 20 then &#x27;20岁以下&#x27;    when age &lt; 25 then &#x27;20-24岁&#x27;    when age &gt;= 25 then &#x27;25岁及以上&#x27;    else &#x27;其他&#x27;end age_cutfrom user_profile\n\n\n\n5. day()\nday()\n\nmonth()\n\nyear()\n\n\n6. 用户留存率计算SQL-计算用户次日留存率.md\n7. 字符串相关SQL-字符串相关.md\n","categories":["刷题笔记"],"tags":["SQL"]},{"title":"SQL｜复习1","url":"/2023/03/06/SQL%EF%BD%9C%E5%A4%8D%E4%B9%A01/","content":"SQL语句顺序sql语句的书写顺序:select &gt;&gt; from &gt;&gt; where &gt;&gt; group by &gt;&gt; having &gt;&gt; order by &gt;&gt; limit注意：\n\nselect和from是必须的；\nwhere和having不能同时使用;\nhaving和group by联合使用；\n\nsql语句的解析顺序 :from &gt;&gt; on&gt;&gt; join &gt;&gt; where &gt;&gt; group by &gt;&gt; having &gt;&gt; select &gt;&gt; distinct &gt;&gt; order by &gt;&gt; limit注意：虽然select在having后执行，但是mysql中仍然可以在having中使用select语句定义的别名\nselect [ALL | DISTINCT | DISTINCTROW | TOP] 字段from 表[inner join  right join | left join 表2][on 连接条件][where 条件][group by 分组规则][having 分组条件][order by 排序规则][limit 分页规则]\n\n\n对于 join，如果不写 left, inner, right ，默认是什么联接呢？是inner join。\nselect * from a join b on a.id = b.idselect * from a inner join b on a.id = b.idselect * from a, b where a.id = b.id# 上面的三个是相等的.# 剩下的join类型有:left joinright joincross joinfull join# 2005新加cross applyouter apply\n\n 各种连接方式的区别？\ninner_join：  内连接，根据两个表共有的列来匹配其中的行，强调只有两个表共有的列值对应的行才能匹配出来。\nleft join&#x2F;right join&#x2F;all join： （左，右，全）外连接，以left join 为例，如果指定了需要匹配的列名，无论右表对应行是否包含满足连接条件的数据，左表的数据都会提取出来，则结果会将右表的这些值以空值的形式匹配进来。\ncross join：  交叉连接，结果是笛卡尔积，就是第一个表符合查询条件的行数乘以第二个表符合查询条件的行数。\nSQL窗口函数窗口函数原则上只能写在select语句中，对where或group by子句处理后的结果进行操作，可以分为以下两种函数：\n1） 专用窗口函数，包括后面要讲到的rank, dense_rank, row_number等专用窗口函数。\n2） 聚合函数，如sum. avg, count, max, min等\n窗口函数的基本语法如下：\n&lt;窗口函数&gt; over (partition by &lt;用于分组的列名&gt;                order by &lt;用于排序的列名&gt;)\n\n窗口函数使用\n转自：https://zhuanlan.zhihu.com/p/92654574\n\nrankselect *, rank() over(\tpartition by class\torder by grade desc) as rankingfrom classtable\n\n1）每个班级内：按班级分组\npartition by用来对表分组。在这个例子中，所以我们指定了按“班级”分组（partition by 班级）2）按成绩排名\norder by子句的功能是对分组后的结果进行排序，默认是按照升序（asc）排列。在本例中（order by 成绩 desc）是按成绩这一列排序，加了desc关键词表示降序排列。\n窗口函数具备了我们之前学过的group by子句分组的功能和order by子句排序的功能。那么，为什么还要用窗口函数呢？\n这是因为，group by分组汇总后改变了表的行数，一行只有一个类别。而partiition by和rank函数不会减少原表中的行数。例如下面统计每个班级的人数。\n\n现在我们说回来，为什么叫“窗口”函数呢？这是因为partition by分组后的结果称为“窗口”，这里的窗口不是我们家里的门窗，而是表示“范围”的意思。\n简单来说，窗口函数有以下功能：\n1）同时具有分组和排序的功能\n2）不减少原表的行数\n其他窗口函数专用窗口函数rank, dense_rank, row_number有什么区别呢？\nselect *,   rank() over (order by 成绩 desc) as ranking,   dense_rank() over (order by 成绩 desc) as dese_rank,   row_number() over (order by 成绩 desc) as row_numfrom 班级表\n\n\n\nrank函数：这个例子中是5位，5位，5位，8位，也就是如果有并列名次的行，会占用下一名次的位置。比如正常排名是1，2，3，4，但是现在前3名是并列的名次，结果是：1，1，1，4。\ndense_rank函数：这个例子中是5位，5位，5位，6位，也就是如果有并列名次的行，不占用下一名次的位置。比如正常排名是1，2，3，4，但是现在前3名是并列的名次，结果是：1，1，1，2。\nrow_number函数：这个例子中是5位，6位，7位，8位，也就是不考虑并列名次的情况。比如前3名是并列的名次，排名是正常的1，2，3，4。\n在上述的这三个专用窗口函数中，函数后面的括号不需要任何参数，保持()空着就可以。\n聚合函数作为窗口函数聚和窗口函数和上面提到的专用窗口函数用法完全相同，只需要把聚合函数写在窗口函数的位置即可，但是函数后面括号里面不能为空，需要指定聚合的列名。\n我们来看一下窗口函数是聚合函数时，会出来什么结果：\nselect *,   sum(成绩) over (order by 学号) as current_sum,   avg(成绩) over (order by 学号) as current_avg,   count(成绩) over (order by 学号) as current_count,   max(成绩) over (order by 学号) as current_max,   min(成绩) over (order by 学号) as current_minfrom 班级表\n\n\n\n有发现什么吗？我单独用sum举个例子：\n如上图，聚合函数sum在窗口函数中，是对自身记录、及位于自身记录以上的数据进行求和的结果。比如0004号，在使用sum窗口函数后的结果，是对0001，0002，0003，0004号的成绩求和，若是0005号，则结果是0001号~0005号成绩的求和，以此类推。\n不仅是sum求和，平均、计数、最大最小值，也是同理，都是针对自身记录、以及自身记录之上的所有数据进行计算，现在再结合刚才得到的结果（下图），是不是理解起来容易多了？\n如果想要知道所有人成绩的总和、平均等聚合结果，看最后一行即可。\n这样使用窗口函数有什么用呢？\n聚合函数作为窗口函数，可以在每一行的数据里直观的看到，截止到本行数据，统计数据是多少（最大值、最小值等）。同时可以看出每一行数据，对整体统计数据的影响。\n注意事项partition子句可省略，省略就是不指定分组，结果如下，只是按成绩由高到低进行了排序：\nselect *,   rank() over (order by 成绩 desc) as rankingfrom 班级表\n\n得到结果：\n\n\n但是，这就失去了窗口函数的功能，所以一般不要这么使用。\n总结1.窗口函数语法\n&lt;窗口函数&gt; over (partition by &lt;用于分组的列名&gt;                order by &lt;用于排序的列名&gt;)\n\n&lt;窗口函数&gt;的位置，可以放以下两种函数：\n1） 专用窗口函数，比如rank, dense_rank, row_number等\n2） 聚合函数，如sum. avg, count, max, min等\n2.窗口函数有以下功能：\n1）同时具有分组（partition by）和排序（order by）的功能\n2）不减少原表的行数，所以经常用来在每组内排名\n3.注意事项\n窗口函数原则上只能写在select子句中\n4.窗口函数使用场景\n1）业务需求“在每组内排名”，比如：\n\n排名问题：每个部门按业绩来排名topN问题：找出每个部门排名前N的员工进行奖励\n\non和where的区别\n参考：https://blog.csdn.net/tayngh/article/details/99684035\n\n前提：数据库在连接多张表返回记录时，都会生成一个中间临时表。\n在多表查询时，ON和where都表示筛选条件，on先执行，where后执行。区别：外连接时，on条件是在生成临时表时使用的条件，它不管on中的条件是否为真，都会返回左边表中的记录。而where条件是在临时表生成好后，再对临时表进行过滤的条件。\nSELECT * FROM emp e LEFT JOIN dept d ON e.deptno=d.`deptno` AND e.`deptno`=40;\n\n\nSELECT * FROM emp e LEFT JOIN dept d ON e.deptno=d.`deptno` WHERE e.`deptno`=40;\n\n\n来我们分析一下为什么会造成以上两种不同的结果。\n\non是生成临时表时使用的条件，上面我们采用的是左外连接，左外连接是以左表为基础的，左表的记录将会全部表示出来，而右表只会显示符合搜索条件的记录。也就是说emp是左表，dept是右表，条件是emp的deptno与dept中的deptno相等且为40时才连接，但emp表中不存在deptno为40的记录，也就是右表没有符合条件的记录，而记录不足的地方均用NULL来补充。\n而where是在临时表生成好后，再对临时表进行过滤。也就是说emp表与dept的连接条件只是emp的deptno与dept中的deptno相等，然后在对生成的临时表进行筛选，由于emp表中不存在deptno为40的记录，所以未找到符合条件的记录。\n\n由于内连接是从结果表中删除与其他被连接表中没有匹配行的所有行，所以在内连接时on和where的结果是相同的。而左外、右外与全连接由于它的特殊性，on和where造成的差别大小取决于表达式和表中的数据。\n\n参考：https://www.runoob.com/w3cnote/sql-different-on-and-where.html\n\n数据库在通过连接两张或多张表来返回记录时，都会生成一张中间的临时表，然后再将这张临时表返回给用户。\n在使用 left join 时，on 和 where 条件的区别如下：\n1、on 条件是在生成临时表时使用的条件，它不管 on 中的条件是否为真，都会返回左边表中的记录。\n2、where 条件是在临时表生成好后，再对临时表进行过滤的条件。这时已经没有 left join 的含义（必须返回左边表的记录）了，条件不为真的就全部过滤掉。\n假设有两张表：\n表1：tab1\nid size1  102  203  30\n\n表2：tab2\nsize name10   AAA20   BBB20   CCC\n\n两条SQL:\n1、select * from tab1 left join tab2 on tab1.size = tab2.size where tab2.name=&#x27;AAA&#x27;2、select * from tab1 left join tab2 on tab1.size = tab2.size and tab2.name=&#x27;AAA&#x27;\n\n第一条SQL的过程：\n1、中间表\non 条件:\ntab1.size = tab2.sizetab1.id tab1.size tab2.size tab2.name1 10 10 AAA2 20 20 BBB2 20 20 CCC3 30 (null) (null)\n\n2、再对中间表过滤\nwhere 条件：\ntab2.name&#x3D;’AAA’\ntab1.id tab1.size tab2.size tab2.name1 10 10 AAA\n\n第二条SQL的过程：\n1、中间表\non 条件:\ntab1.size = tab2.size and tab2.name=&#x27;AAA&#x27;(条件不为真也会返回左表中的记录) tab1.id tab1.size tab2.size tab2.name1 10 10 AAA2 20 (null) (null)3 30 (null) (null)\n\n其实以上结果的关键原因就是 left join,right join,full join 的特殊性。\n不管 on 上的条件是否为真都会返回 left 或 right 表中的记录，full 则具有 left 和 right 的特性的并集。\n而 inner jion 没这个特殊性，则条件放在 on 中和 where 中，返回的结果集是相同的。\n总结：前提：数据库在连接多张表返回记录时，都会生成一个中间临时表。\n在内连接中，使用on或者where没有区别。\n在外连接里，例如使用left join时：\non是在生成临时表时使用的条件，不管on的条件是否为真，都会返回左边表中的全部记录。\nwhere条件是在临时表生成好后，再对临时表进行过滤的条件。这时已经没有left join的含义（必须返回左边表的记录）了，条件不为真的就全部过滤掉。\nSQL行列转换\n参考：https://www.jianshu.com/p/1c6fb0df9f58\n\n行转列假如我们有下表：\n\nSELECT *FROM studentPIVOT (    SUM(score) FOR subject IN (语文, 数学, 英语))\n\n通过上面 SQL 语句即可得到下面的结果\n\nPIVOT 后跟一个聚合函数来拿到结果，FOR 后面跟的科目是我们要转换的列，这样的话科目中的语文、数学、英语就就被转换为列。IN 后面跟的就是具体的科目值。\npivot将原来表中 课程字段中的 数据行 语文，数学，英语 转换为列，并用sum取对应列的值。\n当然我们也可以用 CASE WHEN 得到同样的结果，就是写起来麻烦一点。\nSELECT name,  MAX(  CASE    WHEN subject=&#x27;语文&#x27;    THEN score    ELSE 0  END) AS &quot;语文&quot;,  MAX(  CASE    WHEN subject=&#x27;数学&#x27;    THEN score    ELSE 0  END) AS &quot;数学&quot;,  MAX(  CASE    WHEN subject=&#x27;英语&#x27;    THEN score    ELSE 0  END) AS &quot;英语&quot;FROM studentGROUP BY name\n\n使用 CASE WHEN 可以得到和 PIVOT 同样的结果，没有 PIVOT 简单直观。\n列转行假设我们有下表 student1\n\nSELECT *FROM student1UNPIVOT (    score FOR subject IN (&quot;语文&quot;,&quot;数学&quot;,&quot;英语&quot;))\n\n通过 UNPIVOT 即可得到如下结果：\n\n我们也可以使用下面方法得到同样结果\nSELECT    NAME,    &#x27;语文&#x27; AS subject ,    MAX(&quot;语文&quot;) AS scoreFROM student1 GROUP BY NAMEUNIONSELECT    NAME,    &#x27;数学&#x27; AS subject ,    MAX(&quot;数学&quot;) AS scoreFROM student1 GROUP BY NAMEUNIONSELECT    NAME,    &#x27;英语&#x27; AS subject ,    MAX(&quot;英语&quot;) AS scoreFROM student1 GROUP BY NAME\n\n索引的作用索引是为了提高数据库查询数据的速度而增加的标志符号（通过创建唯一性索引，可以保证表中每一行数据的唯一性）。索引主要建立在①经常搜索的列；②主键所在列；③外键所在列\n索引包括聚集索引与非聚集索引，它们的区别在于索引记录的顺序与表记录的顺序是否一致。\n聚集索引:  可以理解为索引记录的顺序与表记录的顺序一致，SQL默认在依次递增的主键上建立聚集索引，例如，id为1的数据在第一条，id为2的数据在第二条。聚集索引会按照主键的顺序来排序。（例如，用字典找字，对于认识的字可以通过拼音排序对应正文找到页码）\n非聚集索引:  可以理解数据存储在一个地方，索引指向数据存储的位置，索引的顺序与表中数据记录的顺序不一定一致。例如说，建立数据表登记学生考试成绩，字段包括姓名，学号与分数。假定该表按照成绩排序、学号信息错乱，可以考虑构建非聚集索引，第一名对应1，第二名对应2……，想要提取第10个学生的学号，查找索引10指向的数据即可。（用字典找字，不认识的字可以采用部首结合笔画等信息在检字表中搜索，找到页码。比如查”张”字，检字表中”张”的页码是60页，检字表中”张”的上面是”驰”字，但页码却是100页，”张”的下面是”弩”字，页面是200页。很显然，在正文里面这些字并不是真正的分别位于”张”字的上下方，而检字表中连续的”驰、张、弩”三字实际上就是他们在非聚集索引中的排序）\n（关于聚集索引和非聚集索引的区别可以百度学习下，我记得好几家面试都直接问了……）\n排名函数与排序函数排序函数：order by （默认asc升序，指定desc降序），例如将表格数据按照考试成绩从低到高排序。\n排名函数：rank, dense rank, row number ，得到的成绩的排序后，根据成绩的高低对学生排名，100分对应第一名，99分第二名。它们的区别在于：\nrank函数：如果有并列名次的行，会占用下一名次的位置。1，1，1，4。\ndense_rank函数：如果有并列名次的行，不占用下一名次的位置。1，1，1，2。\nrow_number函数：不考虑并列名次的情况。1，2，3，4。\n连接多个select？**union:**连接select，不允许重复值，而且select的对象要有相同的列以及数据类型；(例如A表中某字段的数据是1,1,2,3,4，B表中对应的数据是（0,0,0,0,0），则提取的数据是（1,0；2,0；3,0；4,0），也就是说（1,0）这个组合只会出现一次。)\n**union all:**作用同union,但是允许重复值（也就是说，与上面一样的操作里，(1,0)这个组合会出现2次）\n一般来说如果select 字段大于1个，用union all比用union速度快，因为union 会将多个结果中重复的数据合并，union all则是直接合并\nIntersect: 和 union指令类似，intersect也是合并两个select语句结果的函数。不同的地方是， union的处理结果类似于全集 (如果这个值存在于第一个select或者第二个select，它就会被选出)，而intersect则比较像取出交集 ( 值要同时存在于第一个select和第二个select)。\n**minus:**先找出第一个 select 语句所产生的结果，然后看这些结果有没有在第二个 select语句的结果中。最后会输出第一个select中没有，但是第二个select中有的数据\n主键和外建？主键是一张表中能够确定一条记录的唯一标志(数据库中的一条记录中有若干个属性，若其中某一个属性组(注意是组)能唯一标识一条记录，该属性组就可以成为一个主键 )，比如身份证号。\n外键用于和另一张表进行关联。例如，A字段是A表的主键，那么出现在B表中的A字段能够作为B表的外键，实现A,B表的连接查询。\n向表中插入数据insert into tablename values:  普通插入数据模式\ninsert or ignore into: 如果没有则插入数据，如果有则忽略\ninsert or replace into: 如果不存在就插入，存在就更新\n删除表中数据delete  : 删除表中数据，可以指定具体数据（where）\ndrop column&#x2F; drop table :  删除列数据，与delete 不同，drop函数会将数据以及表的结构全部删除。\n**truncate:**仅删除数据，且默认删除所有数据。和delete不同，truncate不能用where进行筛选，但删除速度比delete快\n字符串常见操作函数concat():  将多个字符串连接成一个字符串，连接符用“”包起来\n**concat_ws()**； 将多个字符串连接成一个字符串，在最开始的位置指定连接符（指定一次即可）\ngroup concat():  将group by产生的同一个分组中的值连接起来，返回一个字符串。\nlike():   需要与通配符一起使用（’%’代表任意字符出现任意次数；’_’仅能匹配单个字符）\nsubstr():   用于从字段中提取相应位置的字符。\nregexp() :  正则表达式匹配函数\nin&#x2F;exist 的关系和区别子查询过程中，In和exist函数效率比较：\n当进行连接的两个表大小相似，效率差不多；\n如果子查询的内表更大，则exist的效率更高（exist先查询外表，然后根据外表中的每一个记录，分别执行exist语句判断子查询的内表是否满足条件，满足条件就返回ture）。\n如果子查询的内表小，则in的效率高（in在查询的时候，首先查询子查询的表，然后将内表和外表做一个笛卡尔积 (表中的每一行数据都能够任意组合A表有a行，B表有b行，最后会输出a*b行)，然后按照条件进行筛选。所以相对内表比较小的时候，in的速度较快）。\nExist的原理: 使用exist时，若子查询能够找到匹配的记录，则返回true，外表能够提取查询数据；使用 not exist 时，若子查询找不到匹配记录，则返回true，外表能够提取查询数据。\n笛卡尔积笛卡尔乘积简单来说，就是两个集合中的每一个成员，都与对方集合中的任意一个成员有关联。开发人员在写代码时,往往因为遗漏了join条件,而触发了集合A中的一条数据能与集合B的另一个元素发生关联后呈现出在一行数据,并且无错误的显现出来,形成强制关系;所以查询俩表,要么对联立的俩字段进行严格筛选得出独一值的列项,要么对这俩表的字段的数据进行唯一约束,防止此类情况发生,以避开此类堆积无名义的数据的出现。\nLEFT JOIN和INNER JOIN，FULL JOIN什么区别？\n都是连接查询；\n\ninner join -&gt; 只保留两张表中完全匹配的结果集；\n\nleft join -&gt; 返回左表中所有的行，即使在右表中没有匹配的记录；\n\nright join -&gt; 返回右表中所有的行，即使在左表中没有匹配的记录；\n\nfull join -&gt; 返回左表和右表中所有的行，左表和右表中没有匹配数据各自单独一行。\n\n\nHAVING和WHERE什么区别？\n“Where” 是一个约束声明，使用Where来约束来自数据库的数据，Where是在结果返回之前起作用的，且Where中不能使用聚合函数。\n\n“Having”是一个过滤声明，是在查询返回结果集以后对查询结果进行的过滤操作，在Having中可以使用聚合函数。\n\nHAVING 子句可以让我们筛选成组后的各组数据，WHERE子句在聚合（聚合函数如SUM, COUNT, MAX, AVG等）前先筛选记录．也就是说作用在 GROUP BY 子句和 HAVING 子句前；而  HAVING 子句在聚合后对组记录进行筛选。\n\n结论：\n\n当分组筛选的时候 用having\n\n其它情况用where\n\n\n用having就一定要和group by连用，用group by不一有having （它只是一个筛选条件用的）\n只要条件里面的字段, 不是表里面原先有的字段就需要用having。\nSQL在查询表的时候先把查询的字段放到了内存里，而where查询的时候是从表里面查的，其余需要用having。\n\n\n","tags":["SQL"]},{"title":"SQL-字符串相关","url":"/2023/02/07/SQL%EF%BD%9C%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9B%B8%E5%85%B3/","content":"SQL30 统计每种性别的人数描述题目：现在运营举办了一场比赛，收到了一些参赛申请，表数据记录形式如下所示，现在运营想要统计每个性别的用户分别有多少参赛者，请取出相应结果\n示例：user_submit\n\n\n\ndevice_id\nprofile\nblog_url\n\n\n\n2138\n180cm,75kg,27,male\nhttp:&#x2F;url&#x2F;bigboy777\n\n\n3214\n165cm,45kg,26,female\nhttp:&#x2F;url&#x2F;kittycc\n\n\n6543\n178cm,65kg,25,male\nhttp:&#x2F;url&#x2F;tiger\n\n\n4321\n171cm,55kg,23,female\nhttp:&#x2F;url&#x2F;uhksd\n\n\n2131\n168cm,45kg,22,female\nhttp:&#x2F;urlsydney\n\n\n根据示例，你的查询应返回以下结果：\n\n\n\ngender\nnumber\n\n\n\nmale\n2\n\n\nfemale\n3\n\n\n\nselect substring_index(profile, &#x27;,&#x27;, -1) as gender, count(device_id)from user_submitgroup by gender\n\n\n\nSQL31 提取博客URL中的用户名描述题目：对于申请参与比赛的用户，blog_url字段中url字符后的字符串为用户个人博客的用户名，现在运营想要把用户的个人博客用户字段提取出单独记录为一个新的字段，请取出所需数据。\n示例：user_submit\n\n\n\ndevice_id\nprofile\nblog_url\n\n\n\n2138\n180cm,75kg,27,male\nhttp:&#x2F;ur&#x2F;bisdgboy777\n\n\n3214\n165cm,45kg,26,female\nhttp:&#x2F;url&#x2F;dkittycc\n\n\n6543\n178cm,65kg,25,male\nhttp:&#x2F;ur&#x2F;tigaer\n\n\n4321\n171 cm,55kg,23,female\nhttp:&#x2F;url&#x2F;uhksd\n\n\n2131\n168cm,45kg,22,female\nhttp:&#x2F;url&#x2F;sydney\n\n\n根据示例，你的查询应返回以下结果：\n\n\n\ndevice_id\nuser_name\n\n\n\n2138\nbisdgboy777\n\n\n3214\ndkittycc\n\n\n6543\ntigaer\n\n\n4321\nuhsksd\n\n\n2131\nsydney\n\n\n\n提取某个字符一般有四种做法：\ntrim()\ntrim() 是直接更改相同格式的一列，删除这一列内容中的统一部分，然后重命名：\nselect device_id, trim(&#x27;http:/url/&#x27; from blog_url) as user_namefrom user_submit\n\n​\t\n\nsubstring_index()\nsubstring_index() 是将字符串切割，1表示保留字符串的左边👈，-1表示保留字符串的右边👉：\nselect device_id, substring_index(blog_url, &#x27;/url/&#x27;, -1) as user_namefrom user_submit\n\n还有一个用法是计数：\nSUBSTRING_INDEX(str,delim,count) 返回从字符串str分隔符 delim 在计数发生前的子字符串。如果计数是正的，则返回一切到最终定界符(从左边算起)的左侧。如果count是负数，则返回一切最终定界符(从右边算起)的右侧。SUBSTRING_INDEX() 搜寻在delim时进行区分大小写的匹配。\nSELECT SUBSTRING_INDEX(&#x27;www.somewebsite.com&#x27;,&#x27;.&#x27;,2);\n\nOutput: &#39;www.somewebsite&#39;\n\nsubstr()\nsubstr() 是用具体位置（数字）来表示从哪开始截取的，参数里还包括截取的长度：\nselect device_id, substr(blog_url, 11, length(blog_url)-10) as user_namefrom user_submit\n\n\n\nreplace()\nreplace() 就是替换函数：\nsleect device_id, replace(blog_url, &#x27;http:/url/&#x27;, &#x27;&#x27;) as user_namefrom user_submit\n\nSQL32 截取出年龄描述题目：现在运营举办了一场比赛，收到了一些参赛申请，表数据记录形式如下所示，现在运营想要统计每个年龄的用户分别有多少参赛者，请取出相应结果\n示例：user_submit\n\n\n\ndevice_id\nprofile\nblog_url\n\n\n\n2138\n180cm,75kg,27,male\nhttp:&#x2F;ur&#x2F;bigboy777\n\n\n3214\n165cm,45kg,26,female\nhttp:&#x2F;url&#x2F;kittycc\n\n\n6543\n178cm,65kg,25,male\nhttp:&#x2F;url&#x2F;tiger\n\n\n4321\n171cm,55kg,23,female\nhttp:&#x2F;url&#x2F;uhksd\n\n\n2131\n168cm,45kg,22,female\nhttp:&#x2F;url&#x2F;sydney\n\n\n根据示例，你的查询应返回以下结果：\n\n\n\nage\nnumber\n\n\n\n27\n1\n\n\n26\n1\n\n\n25\n1\n\n\n23\n1\n\n\n22\n1\n\n\nselect substring_index(substring_index(profile, &#x27;,&#x27;, -2), &#x27;,&#x27;, 1) as age, count(device_id)from user_submitgroup by age\n\n","categories":["刷题笔记"],"tags":["SQL","字符串"]},{"title":"SQL｜计算用户留存率","url":"/2023/02/07/SQL%EF%BD%9C%E8%AE%A1%E7%AE%97%E7%94%A8%E6%88%B7%E6%AC%A1%E6%97%A5%E7%95%99%E5%AD%98%E7%8E%87/","content":"计算用户次日留存率如果只是计算用户的次日留存率，那么使用date_sub()函数就够了：\nselect avg(if(b.device_id is not null, 1, 0)) as avg_retfrom(    select distinct device_id, date    from question_practice_detail) aleft join(    select distinct device_id, date_sub(date, interval 1 day) as date    from question_practice_detail) bon a.device_id = b.device_id and a.date = b.date\n\n\ndate_sub() 函数：\n\nSELECT DATE_SUB(‘2010-08-12’, INTERVAL 3 DAY) AS NewDate \n结果： 2010-08-09\n\nSELECT DATE_SUB(‘2010-08-12’, INTERVAL ‘3-2’ YEAR_MONTH) AS NewDate \n结果： 2007-06-12\n\nSELECT DATE_SUB(‘2011-09-14 2:44:36’, INTERVAL ‘2:26’ HOUR_MINUTE) AS NewDate \n结果： 2011-09-14 00:18:36\n\n\n\n\n基于SQL的留存率计算\n转自知乎：基于SQL的留存率计算\n\n一、什么是留存率互联网行业里，留存率是用于反映网站、互联网应用或网络游戏的运营情况的统计指标，其具体含义为在统计周期（周&#x2F;月）内，每日活跃用户数在第N日仍启动该App的用户数占比的平均值。其中N通常取2、3、7、14、30，分别对应次日留存率、三日留存率、周留存率、半月留存率和月留存率。\n留存率常用于反映用户粘性，当N取值越大、留存率越高时，用户粘性越高。\n二、留存率的计算\n留存率 &#x3D; 登陆用户数&#x2F;新增用户数 * 100%\n\n新增用户数：在当前时间段新注册（或新访问）的用户数；\n\n登录用户数：在统计的时间段至少登录过一次的用户数；\n\n次日留存率：在次日至少登录过一次的用户数&#x2F;当天新增的用户数；\n\n❗️3日留存率：在往后3天内至少登录过一次的用户数&#x2F;当天新增的用户数；\n\n❗️7日留存率：在往后7天内至少登录过一次的用户数&#x2F;当天新增的用户数；\n\n❗️15日留存数：当天新增的用户数，在往后7天内至少登录过一次的用户，在往后第8天到第14天内至少再登陆过一次的用户数\n➡️ 3日和7日，至少登陆过一次；15日，7天为一段，在每段内至少登录一次！\n\n\nSQL中计算用户的留存率\n新增用户数\n\n由于数据过大，这截取时间2017.11.26~2017.12.03为例。\n首先计算分母，这里有的算法是用新增用户数，有的算法是用活跃用户数。\n⚠️注意：新增用户数与活跃用户数并不相等，活跃用户数包含新增用户数。活跃用户数，当天的访问人数，也就是UV。\n-- 每位用户的最早登录日期SELECT 用户ID, MIN(日期) AS 最早登录日期FROM userbehaviorWHERE 日期 &gt; &#x27;2017-11-25&#x27;AND 日期 &lt; &#x27;2017-12-04&#x27;GROUP BY 用户ID\n\n\n再从上表中计算出每天的新增人数，❗️算新增人数用的日期是最早登录日期！\nSELECT 最早登录日期 AS 日期, COUNT(DISTINCT 用户ID) AS 新增人数FROM(SELECT 用户ID, MIN(日期) AS 最早登录日期     FROM userbehavior     WHERE 日期 &gt; &#x27;2017-11-25&#x27; AND 日期 &lt; &#x27;2017-12-04&#x27;     GROUP BY 用户ID) AS fGROUP BY 最早登录日期\n\n\n以下是活跃用户数的算法，二者确实数值上并不相等。❗️算每日活跃用户数用的日期就是当天的日期！\n-- 每天活跃用户数=UV 访客数SELECT 日期, COUNT(DISTINCT 用户ID) AS 活跃用户数FROM userbehaviorwhere 日期 &gt;&#x27;2017-11-25&#x27; AND 日期 &lt; &#x27;2017-12-04&#x27;GROUP BY 日期\n\n\n抽取7天的活跃用户数。\n\n次日留存的用户数\n\n\n次日的时间间隔为1，涉及到时间间隔采用自联结。\n\nSELECT a.用户ID, a.`日期` AS atime, b.`日期` AS btimeFROM userbehavior AS a LEFT JOIN userbehavior AS bON a.`用户ID` = b.`用户ID`WHERE a.`日期` &gt; &#x27;2017-11-25&#x27; AND a.`日期` &lt; &#x27;2017-12-04&#x27;\n\n\n将上表存为视图C，\nCREATE VIEW C(用户ID, atime, btime)ASSELECT a.用户ID, a.`日期`, b.`日期` from userbehavior AS a LEFT JOIN userbehavior AS bON a.`用户ID`=b.`用户ID`WHERE a.`日期`&gt;&#x27;2017-11-25&#x27;AND a.`日期` &lt; &#x27;2017-12-04&#x27;;\n\n\n计算时间间隔用timestampdiff函数\n\nSELECT `用户ID`, TIMESTAMPDIFF(DAY, atime, btime)AS 时间间隔FROM (  SELECT a.用户ID, a.日期 as atime, b.日期 as btime  FROM userbehavior as a LEFT JOIN userbehavior as b  ON a.用户ID=b.`用户ID`  WHERE a.`日期`&gt;&#x27;2017-11-25&#x27;AND a.`日期` &lt; &#x27;2017-12-04&#x27;) AS c-- 这里直接设置为表c\n\n\n得到了用户的时间间隔\n3.用case语句筛选出时间间隔为1的数据，并且进行计数\nSELECT *, COUNT(DISTINCT case when 时间间隔 = 1 then `用户ID`\t\t\tELSE NULL\t\t\tEND)AS 次日留存数FROM( SELECT `用户ID`,TIMESTAMPDIFF(DAY,atime,btime)AS 时间间隔\t\t\t FROM (\t\t\t\tSELECT a.用户ID,a.日期 as atime,b.日期 as btime\t\t\t\tFROM userbehavior as a LEFT JOIN userbehavior as b\t\t\t\tON a.用户ID=b.`用户ID`\t\t\t\tWHERE a.`日期`&gt;&#x27;2017-11-25&#x27;AND a.`日期` &lt; &#x27;2017-12-04&#x27;\t\t\t\t) AS c\t\t\t)AS d\n\n\n次日留存率\n\n次日留存率&#x3D;次日留存用户数&#x2F;当日活跃用户数\nSELECT *,COUNT(DISTINCT case when 时间间隔 = 1 then `用户ID`\t\t\tELSE NULL\t\t\tEND) AS 次日留存数/COUNT(DISTINCT 用户ID) AS 次日留存率FROM( SELECT `用户ID`,TIMESTAMPDIFF(DAY,atime,btime)AS 时间间隔\t\t\t FROM (\t\t\t\tSELECT a.用户ID,a.日期 as atime,b.日期 as btime\t\t\t\tFROM userbehavior as a LEFT JOIN userbehavior as b\t\t\t\tON a.用户ID=b.`用户ID`\t\t\t\tWHERE a.`日期`&gt;&#x27;2017-11-25&#x27;AND a.`日期` &lt; &#x27;2017-12-04&#x27;\t\t\t\t) AS c\t\t\t)AS d\n\n\n\n三、三日以及N日留存的计算只需要修改时间间隔&#x3D;N即可。\nSELECT 日期,COUNT(DISTINCT 用户ID AS 活跃用户数,COUNT(DISTINCT case when 时间间隔=1 then `用户ID`\t\t\tELSE NULL\t\t\tEND) AS 次日留存数/COUNT(DISTINCT 用户ID) AS 次日留存率COUNT(DISTINCT case when 时间间隔=3 then `用户ID`\t\t\tELSE NULL\t\t\tEND) AS 次日留存数/COUNT(DISTINCT 用户ID) AS 三日留存率COUNT(DISTINCT case when 时间间隔=7 then `用户ID`\t\t\tELSE NULL\t\t\tEND) AS 次日留存数/COUNT(DISTINCT 用户ID) AS 七日留存率FROM( SELECT `用户ID`,TIMESTAMPDIFF(DAY,atime,btime)AS 时间间隔\t\t\t FROM (\t\t\t\tSELECT a.用户ID,a.日期 as atime,b.日期 as btime\t\t\t\tFROM userbehavior as a LEFT JOIN 每日新增用户数表 as b\t\t\t\tON a.用户ID=b.`用户ID`\t\t\t\tWHERE a.`日期`&gt;&#x27;2017-11-25&#x27;AND a.`日期` &lt; &#x27;2017-12-04&#x27;\t\t\t\t) AS c\t\t\t)AS d\n\n\n\n四、连续登录三天用户数量","categories":["刷题笔记"],"tags":["SQL"]},{"title":"六级｜作文","url":"/2023/03/10/%E5%85%AD%E7%BA%A7%EF%BD%9C%E4%BD%9C%E6%96%87/","content":"✍️ 万能模板 + 写作句型名言警句类\nReading this famous saying, we can naturally perceive its connotation that+名言警句内含的道理\nThis famous saying conveys a universal fact&#x2F;phenomenon that+名言警句内含的道理\n\n漫画类\nIt is vividly&#x2F;clearly depicted in the picture that+图画中的人物、话语或事件\nGiven is a simple&#x2F;ironical but thought-provoking&#x2F;enlightening picture&#x2F;cartoon, in which+图画中的人物、话语或事件\nWhat is clearly described in the drawing above is that+图画中的人物、话语或事件\nThe cartoon subtly and symbolically depicts a thought-provoking scenario in which+图画中的人物、话语或事件\n\n不同观点\nPeople’s views on……vary from person to person. Some hold that……However, others believe that……（人们对……的观点因人而异，有些人认为……然而其他人却认为……\nPeople may have different opinions on……（人们对……可能会持有不同见解）\nAttitudes towards ……vary from person to person.&#x3D;&#x3D;Different people hold different attitudes towards……（人们对待……的态度因人而异）\nThere are different opinions among people as to……（对于……人们的观点大不相同）\n\n建议句\nIt is high time that we put an end to the (trend).（该是我们停止这一趋势的时候了）\nThere is no doubt that enough concern must be paid to the problem of……（毫无疑问，对……问题应予以足够重视）\nObviously ,if we want to do something … it is essential that……（显然，如果我们想要做某事，很重要的是……）\nOnly in this way can we ……（只有这样，我们才能……） \nSpare no effort to + V （不遗余力的）\n\n采取措施\nWe should take some effective measures.我们应该采取有效措施\nWe should try our best to overcome&#x2F;conquer the difficulties.我们应该尽最大努力去克服困难\nWe should do our utmost in doing sth.我们应该尽力去做……\nWe should solve the problems that we are confronted&#x2F;faced with.我们应该解决我们面临的困难\n\n常用英语谚语\nActions speak louder than words.事实胜于雄辩\n\nAll is not gold that glitters.发光的未必都是金子\n\nAll roads lead to Rome.条条大路通罗马\n\nA good beginning is half done.良好的开端是成功的一半\n\nEvery advantage has its disadvantage有利必有弊\n\nA miss is as good as a mile.失之毫厘，差之千里\n\nFailure is the mother of success.失败是成功之母\n\nIndustry is the parent of success.勤奋是成功之母\n\nIt is never too old to learn.活到老，学到老\n\nKnowledge is power.知识就是力量\n\nNothing in the world is difficult for one who sets his mind to it.世上无难事，只怕有心人\n\n\n✍️写作思路技巧\n无论是名言警句还是漫画作文都要坚持「由表及里，由浅入深」的原则，将话题和某一社会现象、问题联系，或者论述某一重要素质的重要性（例如坚强意志力、好奇心等）。\n\n漫画作文首段描述图画，不做论述；二段从原因、利弊、重要性方面论述，并加以具体例证。尾段重申观点，并提出建议措施。\n\n文字形式的作文首段破解文字含义，将抽象的名言或警句具体化。二段是将话题联系现实生活论述相关的社会问题或者能力素质的原因、现象、背景、重要性、利弊等。尾段再次重申观点加上建议措施即可。\n\n\n✍️真题范文实例网络对人际交流的影响&gt;&gt;\nDirections: For this part, you are allowed 30 minutes to write a short essay based on the picture below. You should start your essay with a brief account of the impact of the Internet on the way people communicate and then explain whether electronic communication can replace face-to-face contact. You should write at least 120 words but no more than 180 words.\n首段：图画联系主题&gt;&gt;\nApparently, this cartoon can be naturally associated with the impact of the Internet on the way people communicate: Internet makes our communication convenient, but if individuals intend to maintain close and harmonious relationship with others, it is not advisable for them to chat merely by the Internet.\n二段：现象+危害&gt;&gt;\nIn contemporary society, it has become a trend for a host of youngsters to spend much time in playing PC games, QQ and Wechat. Meanwhile, an increasing number of parents find it rather difficult to have opportunities to chat with teenagers face to face, because of Internet. A case in point is the guy and his parents: he seldom sees his parents, and when his computer crashes, he will come downstairs to see his parents. It is the Internet that does not enable teenagers to spend adequate time in caring about parents and significant things. As a matter of fact, intelligent people in large numbers have come to realize the negative influences of Internet: cold or indifferent relationship.\n尾段：观点+结论&gt;&gt;\nAs a college student, I am convinced that it is of great necessity for youngsters to strengthen our communication in real life. Do bear in mind: electronic communication can never replace face-to-face contact.\n","categories":["六级"],"tags":["英语"]},{"title":"六级｜翻译","url":"/2023/03/04/%E5%85%AD%E7%BA%A7%EF%BD%9C%E7%BF%BB%E8%AF%91/","content":"words &amp; expressions\nthe North China Plain 华北平原\nthe upper&#x2F;middle&#x2F;lower reaches of Yellow River\nBordering on the … in the west\nit covers xx square meters\nalluvial deposits\nflat&#x2F;smooth terrain\nconvenient transportation\nsince ancient times\none of the regions with the densest population&#x2F; one of the most densely populated regions in the world\nthr cradle of Chinese civilization 文明的摇篮\nissue of population 人口问题\ngain a better understanding of 更好地理解\nthe growth of population 人口增长\na coordinated and sustained development 协调和可持续发展\nemphasis should be laid on …\npopulation quality 人口素质\nall-round development of all humanity 全面发展\nessentially\nhealth level 健康水平\ndialect\nthe migration of population\nthe barrier of mountains and rivers\nmutual contacts and influence\nbe manifested in phonetics, vocabulary and grammar\nMandarin 普通话\ninterpersonal communication\npopularized \nindispensible\nbe protected and inherited\nthe whole name of the system that consists …\nlink with each other\narrangemenmts\nsupplements\nthe law of nature\ntake into account\ndavanced empire\nunification\nprosperous\nlong-lasting wars\nunsprakable sufferings\nthe masses\nfall around\nin the solar calendar \noccasion\noffer sacrifice to ancestors 祭祀祖先\nthe departed 逝者&#x2F; the dead\ntomb-sweeping\nswinging 荡秋千\nintangible cultural heritage 非物质文化遗产\npast the couples 贴\nconsist of\n\n2023&#x2F;03华北平原是中国第二大平原，位于黄河下游。华北平原西邻太行山，东至海岸，北起燕山，南接淮河，面积31万平方公里。这里地势低平，多在海拔50米以下。它由黄河、淮河和海河的冲积物形成，也被称为黄河淮海平原。平原地势平坦，河湖众多，交通便利，经济发达，自古即为中国政治、经济、文化中心。\nThe North China Plain is the second largest plain in China, located at the lower reaches of the Yellow River. Bordering on the Taihang Mountains in the west, the coast in the east, Yanshan Mountain in the north and Huaihe River in the south, it covers 310,000 square km. It has a smooth terrain with an elevation of lower than 50 meters. Formed of alluvial deposits from the Yellow, Huaihe and Haihe rivers, it is also known as the Yellow River-Huaihe-Haihe Plain. With its flat terrain, many rivers and lakes, convenient transportation and developed economy, the plain has been the political, economic and cultural center of China since ancient times.\n\n华北平原（The North China Plain）是中国最大的冲积（alluvial）平原。华北平原是世界上人口最密集的区域之一。它的面积约为40.95万平方公里，延绵覆盖着河南、河北和山东省的大部分地区。它是中国重要的农作物产区之一。首都北京坐落在华北平原的东北边缘位置。此外，天津，这所重要的工业城市和商业港口，也临近其东北海岸。传统意义上，华北平原的南部被称之为“中原”，“中原”是中华文明的摇篮。\nThe North China Plain, the largest alluvial plain in China, is one of the regions with the densest population in the world. It covers an area of about 409.5 thousand square kilometers, and it extends over much of Henan, Hebei and Shandong provinces. It is one of China’s most important agricultural regions. The plain is one of the most densely populated regions in the world. Beijing, the national capital, is located on the northeast edge of the plain. In addition, Tianjin, as an important industrial city and commercial port, is near its northeast coast. Its southern part is traditionally referred to as the Central Plain, which formed the cradle of Chinese civilization.\n\n\nCurrently, the whole society is gaining a better understanding of the issue of population. It is agreed that the growth of population is beneficial to a coordinated and sustained development between population and economy, society, resources and environment. To solve the population problem, emphasis should be laid on the improvement of the population quality, health level and quality of life so as to realize the all-round development of all humanity. The issue of population is essentially a problem of development and could only be solved through economic, social and cultural development.\nÒ【翻译热词】\n四六级考场阅卷老师全喜欢的高分短语!\n1.issue of population人口问题\n2.gain a better understanding of更好地理解\n3.the growth of population人口增长\n4.a coordinated and sustained development协调和可持续发展\n5.population quality 人口素质\n6.all-round development全面发展\n7.health level健康水平\n8.cultural development文化发展\n【高频词汇】\n\ncoordinate[kau’5:dinert] v.协同动作;协调(7次)\nsustain[sa’stein] v.维持，保持（14次)\nessentially[I’senJoli] adv.本质上;根本上(11次)\n\n\n翻译题目方言\n方言(dialect)是指只在局部地区使用的语言。形成方言的原因很多，如人口的迁移、山川地理的阻隔、不同语言的相互接触和影响等。方言之间的差异表现在语音(phonetics)、词汇、语法各个方面，语音方面尤为突出。据说中国十大最难懂方言中，温州话排名第一，广东话紧随其后。普通话作为人与人之间交流沟通的工具，普及固然重要，而方言作为地方文化的一种，是民族文化不可缺少的组成部分，也应被保护和传承。\n参考译文\nA dialect is a language spoken only in a local area. There are many reasons for the formation of dialects, such as the migration of population, the barrier of mountains and rivers and the mutual contact and influence of different languages. The differences between dialects are manifested in phonetics, vocabulary and grammar, especially phonetic aspects. It is said that Wenzhou dialect is the most difficult one to understand in China, followed by Cantonese. Mandarin, as a tool of interpersonal communication, is of course important to be popularized, while dialects, as a kind of local culture, are an indispensable part of national culture and should also be protected and inherited.\n\n2023年3月四六级翻译预测| 二十四节气：\n24节气(24 solarterms)是统称，包括 12节气（12 majorsolar terms)和 12中气 (12 minorsolar terms),它们彼此之间相互关联。24节气反映了天气变化，指导农业耕作，也影响着人们的生活。春秋战国时期，人们开始使用节气作为补充历法 (calendar)。公元前104年，24节气最终确立。众所周知，中国是个有着悠久农业发展史的国家。农业生产受自然规律影响极大。在古代，农民根据太阳的运动安排农业生产活动。24节气考虑到了太阳的位置，这就是我们重视它的原因。\n参考译文：\nThe 24 solar terms are the whole name of the system that consists of 12 major solar terms and 12 minor solar terms linked with each other. It reflects climate change, guides agriculture arrangements, and also affects people’s life. In the Spring and Autumn Period and the Warring States Period, people began to use solar terms as the supplementary calendar. It was in 104 B, C. that the 24 solar terms were finally set down. As we all know, China is a country with a long history of agriculture. Agricultural production is largely influenced by the laws of nature. In ancient times, farmers arranged their agricultural activities according to the move of the sun. It is the fact that the 24 solar terms take into account the position of the sun that makes us attach importance to it.\n\n四六级翻译|中国朝代\n中国有4000多年的历史，是世界最古老的文明之一。从公元前21世纪的夏朝开始至清朝结束，中国历史上经历过几十个朝代的变更。每个朝代在政治、经济、文化、科技领域等都有独特的成就。汉朝是当时世界上最先进的帝国。”汉族“（the Han Nationality）这一名称就得名于汉朝。唐朝因统一时间长、国力强盛而被国人铭记，因此在海外的中国人自称为“唐人”（Tang people）。宋朝和明朝是经济、文化、教育与科学高度繁荣的时代。但朝代的更替一般会导致连年战争，给人民大众带来了难以言表的痛苦。\n参考译文：\nWith a history of more than 4,000 years,China is one of the oldest ancient civilizations of the world. From Xia Dynasty in the 21st century BC to Qing Dynasty, China experienced dozens of dynasties in history. Each dynasty achieved unique accomplishments in the fields of politics, economy, culture, science and technology, etc. Han Dynasty was the most advanced empire at that time, which contributes to the formation of the name “the Han Nationality . Tang Dynasty impressed Chinese for its long time unification and powerful national strength, because of which overseas Chinese call themselves “Tang people” abroad. Song Dynasty and Ming Dynasty were periods when economy, culture, education and science were highly prosperous. But the change from one dynasty to another usually led to long-lasting wars, which brought unspeakable suffering for the masses.\n\n2023年3月四六级翻译预测| 清明节\n清明节是中国重要的传统节日，通常在阳历4月5日左右。它始于周朝，有2500多年的历史。清明节是中国人祭祀（offer sacrifices to）祖先的日子。在清明节祭祀逝去的先祖亲人实际上体现了生者对逝者的思念与敬爱，由于清明节与中国另一个传统节日“寒食节”（Cold Food Day）临近，所以吃寒食也成为清明节的习俗之一。除了扫墓，清明节还有荡秋千等风俗活动。如今，清明节已经成为中国重要的非物质文化遗产（intangible cultural heritage）。\n参考译文：\nThe Qing Ming Festival is an important traditional Chinese festival which usually falls around April 5 in the solar calendar. It started from Zhou Dynasty, with a history of over 2,500 years. The Qing Ming Festival is an occasion for Chinese people to offer sacrifices to ancestors. Offering sacrifices to the departed on the Qing Ming festival actually shows that the living miss, respect and love the dead. The Qing Ming Festival is close to another Chinese traditional festival “Cold Food Day”; therefore, eating cold food has turned into one of the customs of the day. Besides tomb-sweeping，there are also other customs and activities like swinging on that day. At present, the Qing Ming Festival has become an important intangible cultural heritage in China.\n2022&#x2F;09贴春 联 (Spring Festival couplets)是中国人欢度春节的一个重要习俗。春联由一对诗句 和四字横 批 (horizontal scroll)组成，诗句和横批用金色或黑色写在红纸上，红色代表幸运， 金色代表财富。春联贴在大门左右两侧和门框上方。春联的诗句体现中国传统诗词的特点， 两句诗的字数相同、内容相关。横批凸显春联的主题，更是锦上添花。春联以简洁的文字 描绘生动的形象，抒发美好的愿望。当家家户户贴春联时，人们就会意识到春节己经正式拉 开序幕。\nPasting the Spring Festival couplets is an important custom for Chinese people to celebrate the Spring Festival. The Spring Festival couplets consist of a pair of poems and a four-character horizontal scroll written in gold or black on red paper, with red representing luck and gold representing wealth. The Spring Festival couplets are pasted on the left and right sides of the gate and above the door frame. The lines of the Spring Festival couplets embody the characteristics of traditional Chinese poetry, with two lines having the same number of characters and related content. The horizontal scroll highlighting the theme of the Spring Festival couplets is even the icing on the cake. People depict vivid images in simple words in the Spring Festival couplets, expressing a beautiful vision. When every household puts up the Spring Festival couplets, people will realize that the Spring Festival has officially kicked off.\n2022&#x2F;09自古以来， 印章在中国就是身份的凭证和权力的象征。 印章不仅具有实用性， 而且也 是一种艺术形式， 是一门集书法与雕刻于一体的古老艺术， 经常被看作与书画并列的独立 艺术品。 印章从材料的选择、制作的工艺到字体的设计， 都具有极其丰富的美学表现。 其 他国家的艺术家通常在其绘画作品上签名， 而中国艺术家则往往在其书画作品上盖上印章 代替签名。 这样， 印章也就成为作品的组成部分， 是体现作品独特性的一种方式。\nFrom ancient times, the seal has been a certification of identity and a symbol of power. The seal is not only practical, bus also a kind of artistic form. It is a kind of time-honored art that mixes caligraph and sculpture, being regarded as an independant artwork that is comparable with painting and caligraphy. The seal has an extremely rich aesthetic performance from the choice of materials, the technique of producing and the design of fonts. Artists from other countries usually sign on their paintings, while Chinese artists always print their seals on their works instead of signing by hand. Therefore, the seal is going to become an intergral part of the works and a way to present the uniqueness of works. \n Since ancient times, the seal has been proof of identity and a symbol of power in China. The seal is not only practical, but also an art form and an ancient art that combines caligraphy and sculpture. It is often seen as an independent work of art alongside caligraphy and painting. The seal is extremely rich in aesthetic expression, from the selection of materials, the craftsmanship to the design of the typeface. Arstists in other countries usually sign their paintings, while Chinese artists often use seals instead of signitures on their aintings and caligraphy. In this way, the seal also becomes an integral part of the work and is a way to reflect its uniqueness. \n\nproof前面没有冠词；symbol前面有冠词\n\nancient 古代的；古老的\n\n书法是calligraphy不是caligraph，雕刻是sculpture\n\ntypeface &amp; font: \n\nA typeface is the underlying visual design that can exist in many different typesetting technologies, and a font is one of these implementations. In other words, a typeface is what you see and a font is what you use.\n\n\nselection &amp; choice: \n\nWhen used as nouns, choice means an option, whereas selection means the process or act of selecting.\n“Do I have a choice of what color to paint it?”\n“The large number of good candiadtes made selection difficult.”\n\n\ncertification &amp; certificate &amp; proof: \n\ncertification强调的是出具证明的动作 act&#x2F;process，为不可数名词；而certificate强调的是一份证明 document&#x2F;paper，为可数名词。\n\nthe medical certification of the cause of death\n为死因出具医学鉴定\n\ncertification of competence\n颁发技能证书\n\na birth certificate\n出生证明\n\na degree certificate\n学位证书\n\na certificate course 认证课程; the certification exam 证书考试\n\n\n\nA certificate is a official document stating that information is true for example a birth or marriage certificate.\n\nProof is evidence&#x2F;a piece of information that shows that something exists or is true.\n\n\n\n\n2022&#x2F;09中央电视台总部大楼位于北京市朝阳区，总建筑面积约55万平方米。主楼由两座塔楼组成，因其独特的造型，成为这座城市的一个热门景点，每天都吸引众多游客前来参观。大楼的创新结构是中外建筑师长期合作的成果，不仅体现了环保意识，而且大大节约了建筑材料。中央电视台总部设有一条穿过大楼的专用通道，向公众展示各个工作室以及中央电视台的历史。在那里，参观者还可以看到故宫和北京其他地方的壮观景色。\nThe CCTV headquarters building is located in Chaoyang district, Beijing and has an area of 550 thousand square metres. The major building consists of two towers that becomes a hot spot in Beijing because of its distinct character, attracting a largr number of tourists to visit everyday. The innovative structure of the building results from the long-term cooperation of  Chinese and foreign architects. It not only refelcts environmental awareness, but slao saves a lot of constructing materials. The CCTV headquarter has a specific access that is used to present history of all kinds of studios and CCTV to the public. There, the visitors can also witness the spectacular sceneries of the Imperial Palace and other places in Beijing. \nChina Central Television (CCTV) headquarters Building is located in Chaoyang District, Beijing, with a toal floor area of about 550,000 square meters. The main building consisting of two towers has become a popular attraction of the city because of its unique shape, attracting many tourists every day. The innovative structure of the building is attributed to the long-term collaboration between Chinese and foreign architects, which not only reflects environmental awareness, but also greatly saves building materials. CCTV headquarters set up a dedicated passage through the building to show the public the various studios anf the history of CCTV. From there, visitors can also enjoy the spectacular views of the Forbidden City and other places in Beijing.\n\ncooperation &amp; collaboration: \ncooperate 艰苦地干活、努力，很多人一起合作共同创造或实现一个目标，不分彼此的合作\ncollaborate（operate）操作、运作，长期的一种关系，单纯的合作&#x2F;配合对方\n\n\n\n2022&#x2F;06卢沟桥位于天安门广场西南 15 公里处，横跨永定河， 是北京现存最古老的多拱石桥。 卢 沟 桥 最 初 建 成 于 1192 年 ， 1698 年重建， 由 281 根柱子支撑。 每根柱子上都有一头石狮。 这些石狮的头、背、腹部或爪子上都藏着更多的狮子。 这些石狮生动逼真、千姿百态， 是 卢沟桥石刻艺术的精品。桥上的石狮不计其数，因而北京地区流传着“卢沟桥上的石狮子——数不清”的说法。\n卢沟桥不仅以其美学特征闻名于世，还被公认为石桥建筑史上的一座丰碑。\nLugou Bridge is 15 kilometers southeastern far from the Tiananmen Square, across the Yongding River and is the present oldest multi-arch stone bridge. Lugou bridge is originally built in 1192 and is reconstructed in 1682, supported by 281 pillars that each has a stone lion on them. More lions are hided on their head, back, belly and claw. These stone lions are very vivid and have a variety of gestures, are miracles of Lugou Bridge’s stone-sculpture art. The stone lions on the bridge are hard to count, hence there is a folk statement that “the lions on the Lugou Bridge - countless”.\nLugou Bridge is not only famous for its aesthetic characteristic, but also regarded as a milestone in the stone bridge history.\nLocated 15 km southwest of Tian’anmen Square, Lugou Bridge stretches over the Yongding River and is the oldest existing multi-arched stone bridge in Beijing. The original construction of the bridge was completed in 1192 and then in 1698 the bridge was reconstructed. The bridge is supported by 281 pillars, and on each pillar stands a stone lion. More lions hide themselves on the head and back, under the belly or on the paws of each lion. The lions are vivd with various postures and differrent expressions, and they are known as the fine work of the stone carving art. As there are numorous stone lions on the bridge, there is a saying in Beijing echoing, “The lions are too numerous to count.”\nLugou Bridge is not only well-known in the world for its aesthetic features, but also well recognized as a monument in the architectural history of stone bridge. \n2022&#x2F;06南京长江大桥是长江上首座由中国设计、采用国产材料建造的铁路、公路两用桥，上层 的 4 车道公路桥长 4589 米， 下层的双轨道铁路桥长 6772 米。铁路桥连接原来的天津一浦口 和上海一南京两条铁路线，使火车过江从过去一个半小时缩短为现在的 2 分钟。 大桥是南北 交通的重要枢纽， 也是南京的著名景点之一。\n南京长江大桥的建成标志着中国桥梁建设的一个飞跃， 大大方便了长江两岸的物资交流 和人员来往， 对促进经济发展和改善人民生活起到了巨大作用。\nNanjing Long River Bridge is the first double-used bridge by both rail road and highway that  is designed by Chinese and constructed with China-made materials. The upper-level four-car road is 4589 meters in length and the lower-level two-rails road is 6772 meters in length. The rail-road beidge connects two rail lines, the previous Tianjin-Pukou and Shanghai-Nanjing, which shortens the time that trains need to pass the river from half an hour to 2 minutes. The bridge is not only an important hinge of transportation between north and south, but also a famous spot in Nanjing.\nThe completion of the construction of Nanjing Long River Road symbolizes a huge leap of Chinese bridge constructing techniques, making the items’ exchange and people’s interaction far more convenient than before, making a huge effect on promoting the development of the economy and people’s quality of life.\n\n\n\n\n2022&#x2F;06赵州桥建于隋朝，公元 605 年左右，长 50.82 米，宽 9.6 米，跨度 37.37 米。天才建筑 师李春设计并监督了桥的建设。赵州桥结构新颖、造型优美。桥有一个大拱，在大拱的两 端有两个小拱，帮助排泄洪水、减轻桥梁重量并节省石材。建成以来，该桥经受了多次洪 水和地震，但其主体结构仍然完好无损，至今仍在使用。\n赵州桥是世界桥梁建筑史上的一次创举，是中国古代文明史上的一项杰出成就。类似 设计的桥梁直到14 世纪才在欧洲出现，比赵州桥晚了 700 多年。\nZhaozhou Bridge was built in Sui Dynasty, about BC 605. It is 50.82 meters long, 9.6 meters wide, crossing over 37.37 meters. The genius architect, Li Chun, designed and supervised the construction of the bridge. Zhaozhou Bridge has an innovative structure and beautiful shape. The bridge has a big arch, with two small arches in both sides of it that can help with discharging flood, reducing the weight og the bridge and saving stone materials. Since the bridge was built, it experienced flood and earthquake for several times, but its main structure is still in good condition and under used.\nZhaozhou Bridge is a great work in the world’s bridge construction history and an outstanding achievement in Chinese history of civilization. Bridges with similar design did not appear until 14 centuries in Europe and were later than Zhaozhou Bridge for mroe than 700 years.\nThe Zhaozhou Bridge, which was built in the Sui Dynasty around 605 AD, is 50.82 metres long and 9.6 metres wide with a span of 37.37 meters. Li Chun,a genius architect, designed and supervised its construction. The bridge boasts a novel structure and a graceful appearance, with a major arch in the middle and two minor ones on its ends which help discharge floods, reduce the weight of the bridge and save stones. Since the completion, the bridge has withstood floods and earthquakes, but remains intact in its main structure and stil available in use. The Zhaozhou Bridge is a pioneering undertaking in the world history of bridge construction and a masterpiece of the Chinese ancient civilization for the simple reason that its similar bridge did not appear in Europe until the 14th century,700 years later than the Zhaozhou Bridge.\n\n公元前 BC（Before Christ 基督前） 公元后 AD（Anno Domini 主后）\n\na pioneering undertaking \n\nremain in use&#x2F; be in use\n\nthe history of the CHinese ancient civilization 文明史\n\n\n2021&#x2F;122021.12英语六级翻译真题(一)\n延安位于陕西省北部，地处黄河中游，是中国革命的圣地。毛泽东等老一辈革命家曾在这里生活战斗了十三个春秋，领导了抗日战争和解放战争，培育了延安精神，为中国革命做出了巨大贡献。延安的革命旧址全国数量最 大、分布最 广、级别最 高。延安是全国爱国主义、革命传统和延安精神教育基地。延安有9个革命纪念馆，珍藏着中共中央和老一辈革命家在延安时期留存下来的大量重要物品，因此享有“中国革命博物馆城”的美誉。\nLocated in the northern part of Shanxi Province and in the middle reaches of the Yellow River，Yan’an is the sacred land of the Chinese Revolution. The old generation of revolutionaries such as Mao Zedong lived and fought here for thirteen years, leading the War of Resistance against Japanese Aggression and the War of Liberation, cultivating the spirit of Yan’an, and making great contribution to the Chinese revolution. With the largest number of revolutionary sites that are distributed widest and have the highest level in the country，Yan’an is a national base for patriotism, revolutionary tradition and spiritual education. There are nine revolutionary memorial halls, which hold a large number of important items left by the Central Committee of the Communist Party of China and the old generation of revolutionaries during the Yan’an period, so it enjoys the reputation of the museum city of Chinese revolution.\n2021.12英语六级翻译真题(二)\n井冈山地处湖南江西两省交界处，因其辉煌的革命历史被誉为“中国革命红色摇篮”。1927年10月，毛泽 东、朱德等老一辈革命家率领中国工农红军来到这里，开展了艰苦卓绝的斗争，创建了第 一个农村革命根据地，点燃了中国革命的星星之火，开辟了“农村包围(besiege)城市，武装夺取政权”这一具有中国特色的革命道路，中国革命从这里迈向胜利。井冈山现有100多处革命日址，成为一个“没有围墙的革命历史博物馆”，是爱国主义和革命传统教育的重要基地。\nJinggangshan is located at the boundary of Hunan Province and Jiangxi Province, which is honored as “the red cradle of Chinese revolution” for its glorious revolutionary history. In October 1927, the old generation like Mao Zedong and Zhu De led the Chinese Workers’ and Peasants’ Army here, where they created the first rural revolutionary base with much extremely hard and bitter struggle and light the sparks of Chinese revolution, breaking a revolutionary path with Chinese characteristic to besiege the city from the countryside and to seize power by armed force. It is here that the revolution moves toward success. There are over 100 revolutionary sites in Jinggangshan, a vital base for patriotism and education of revolutionary traditions, which has become a revolutionary history museum without any walls.\n2021.12英语六级翻译真题(三)\n中国共产党第 一次全国代表大会会址位于上海兴业路76号，是一栋典型的上海式住宅，建于1920年秋。1921年7月23日，中国共产党第 一次全国代表大会在此召开，大会通过了中国共产党的第 一个纲领和第 一个决议，选举产生了中央领导机构，宣告了中国共产党的诞生。1952年9月，中共一大会址修复，立纪念馆并对外开放。纪念馆除了介绍参加一大的代表之外，还介绍党的历史发展进程，现已成为了解党史、缅怀革命先烈的爱国主义教育基地。\nSituated at No.76 Xingye Road, Shanghai, the Site of the First National Congress of the Communist Party of China is a typical Shanghai-style residence built in the fall of 1920. On July 23, 1921, the First National Congress of the CPC was held here, where the first programme and resolution of the CPC were passed, and the collective central leadership was elected, thus announcing the birth of the Communist Party of China. In September 1952, the site was renovated, and a Memorial Hall was established and opened to the public. In addition to introducing the representatives who participated in the First Congress, the Memorial Hall also introduced the historical development of the party, which has become a patriotic education base to know party’s history and commemorate the memory of revolutionary martyrs.\n","categories":["六级"],"tags":["英语"]},{"title":"商业分析｜SaaS","url":"/2023/03/10/%E5%95%86%E4%B8%9A%E5%88%86%E6%9E%90%EF%BD%9CSaaS/","content":"概述SaaS的英文全称是Software as a Service，意思是软件即服务。SaaS的本质是一种软件的交付模型，即不向用户交付最终的软件产品，软件作为用户使用的服务而存在。所以SaaS就相当于软件中的租借模式。\n常见的SaaS代表性产品包括ERP、OA、IM、BI等。我国近两年很多互联网C端巨头开始部署SaaS，其实是因为目前中国市场C端发展日趋饱和，B端发展严重不足。因此搭建SaaS生态对巨头在B端市场的后续发展起着决定性作用，而且会影响各个巨头的公有云市场份额。国外目前已经有一些成熟的SaaS比如Saleforce、微软等。\n从市场的角度看，中国市场环境的特点是需求多样化和支付能力弱，所以所以通过成熟的产品大大降低成本和提升用户体验，建立全家桶化的解决方案应该是中国SaaS采取的主要策略。在面对叮叮这种老牌SaaS以及强连接的企业微信这种竞争对手的情况下，飞书需要通过过硬的产品力来取胜，而且B端的软件持续发展能力非常重要，因为商业逻辑是持续发展而且多样化的，所以SaaS行业中技术创新的能力也是必须的。\n❗️什么是SaaS？\nSaaS的英文全称是Software as a Service，意思是软件即服务。它是一种通过Internet提供集中托管应用程序的方式，是云计算的一种服务模式。\n\nSaaS的本质是一种软件的交付模型，即不向用户交付最终的软件产品，软件作为用户使用的服务而存在。Software as a Service 就相当于软件中的租借模式。\n\nSaaS 用户可以进行软件定制化，但并不拥有软件的所有权。SaaS的软件所有权属于软件提供商，软件提供商需要维护系统的正常运行。\n\n\n🧾SaaS的功能特性\n在统一的地方管理\n\n托管在远程服务器上\n\n可以通过互联网访问\n\n用户不负责硬件或者软件更新\n\n\n✍️Salesforce: SaaS的竞争优势在1999年之前，企业如果想要采购一套软件，通常需要花上数百万美元购买，并用数月时间来进行部署。即便是更简单的民用软件，也需要花费几百元购买一张光碟回家安装（还记得当年装在盒子里面卖的瑞星小狮子吗？）。\nSalesforce 主打了软件即服务这个理念，也带来了巨大的竞争优势：\n\n费用降低，对企业来说支持按月付费，也支持按席位付费。\n部署更快，只需要降低到一两周时间就可以使用，后来的系统更是可以做到打开即用。\n更新更快，以前需要用光碟的形式安装的，现在联网之后可以自动迭代升级。\n\n💻SaaS的代表性产品企业资源计划（ERP）\nEnterprise Resource Planning\n\n没有ERP的时候，如果客户打来了电话表示对库存当前数据有疑问，要求核查数据，业务人员只能拿着合同到处跑，必须将采购部、生产部、销售部调查个遍才能发现问题，搜集数据，解决问题，效率低下。有了ERP后，所有的流程、文档、事务都可以在线上，取代了之前的线下文档，可以直接调取ERP系统中的库存数据与客户及时核对。公司ERP系统贯穿整个业务流程，业务人员再也不用东跑西跑，手机或电脑上就能与各部门数据互联互通。\n\n\n\n\nERP的价值：帮助企业实现信息化。\n\n客户关系管理（CRM）\nCustomer Relationship Management\n\n协同oa（OA）\nOffice Automation\neg. 钉钉，明道，teambition\n\n人力资源管理（HRM）\nHuman Resource Manager\n\n主要功能是招聘、培训、员工关系、绩效考核、薪酬福利、继任管理等。\n\n核心用户是HR。\n\n代表性产品有51社保、薪人薪事、北森等。\n\n\n财务控制（FICO）\nFiance + Controlling\n企业财务咨询、核算、报账、预算控制、财务分析等。 -&gt; 云代记账、费控、差旅报销管理。\n核心用户是财务人员。\n代表性产品有云账房、闪电报销、易快报等。\n\n通信&#x2F;即时通讯（IM）\nInstant Messaging\n用于办公环境下的即时通讯、软电话、邮箱、会议系统、呼叫中心等。主要细分领域为云客服、云视频会议、云呼叫中心。\n核心用户是全员和客服。\n代表性产品有网易七鱼、环信、智齿客服等。\n\n网盘&#x2F;企业内容管理（ECM）\n用于文件的存储、共享、预览、编辑、同步以及写作功能\n代表性产品有联想企业网盘、亿云方、坚果云等。\n\n商业智能（BI）\n用于数据分析、数据可视化，为企业为企业精细化运营和产品优化提供参考。\n核心用户是运营和数据分析人员。\n代表性产品有网易有数、FineBI、DataHunter等。\n\n📈SaaS 市场的需求背景\n云计算技术的成熟和产业链的扩大推动了SaaS服务的快速发展；\n中小型企业发展迅猛，迎来数字化管理变革。企业急需提高管理效率并控制管理的成本，于是提托于云计算和互联网的SaaS服务的出现，帮助企业成功降低了运营成本，提高运营效率。\n企业信息化与网络化程度不断提高，IT产品走向消费化；\nSaaS行业的融资数量与金额呈爆发式增长。\n\n💬业界对SaaS企业的评判\n$优秀的SaaS企业 &#x3D; 低获客成本 + 高续约率$\n\n$客户生命周期价值 &gt;&#x3D; 3*获客成本$\n$客单价 &gt; 获客成本$\n$客户流失率 &lt; 5%$\n\n\n除了以上三个原则，SaaS企业自身还应该注重产品研发 + 运维服务 + 产品销售 -&gt; 提升服务，了解客户特性，来做好客户流失预警机制。\n\n目前我国SaaS公司的业务收入和增长速度和国际水平仍差距较大。目前SaaS行业超过1亿收入的公司只有四五家，但是占领了业界领头羊的地位。\n\n\n❓为什么巨头科技企业都在布局SaaS生态？\n近两年，中国ToB产业从无人问津逐步走向繁荣，而繁荣之下最令人关注的，无疑是阿里、腾讯、华为、字节跳动等C端互联网巨头对SaaS生态的重视。\n不管是腾讯提出的SaaS千帆计划，还是阿里所谓的“被集成”，再到华为打造的“耕云”计划，字节跳动高调推出飞书，都被认为是近一年中国SaaS市场最重要的事情。\n尤其是经过疫情洗礼，钉钉、企业微信、飞书、华为WeLink用户量激增，在此基础上，阿里提出“云钉一体”全面发力SaaS市场；腾讯宣布将投入100亿资源打造SaaS生态；华为云紧随其后推出SaaS应用扶持计划；飞书也一直在招兵买马……\n· 为什么巨头都在布局SaaS生态？\n· 中国SaaS生态又与国外有哪些不同？\n· 构建成熟的SaaS生态，中国市场还存在哪些问题呢？\n\n❓巨头布局SaaS生态的原因\n当前中国企业市场面临：C端的发展日趋饱和，B端的发展严重不足。因此搭建SaaS生态对巨头在B端市场的后续发展起着决定性作用。\n首先，SaaS生态会直接影响各个巨头的公有云☁️市场份额。未来共有云市场发展的关键就是看谁能先建立起成熟的SaaS生态。\n多数B端企业不会也不能直接使用公有云。企业需要一个整体的系统，将SaaS和公有云打包📦才能真正服务于B端企业。\n\n\n\n✈️国外SaaS生态分析\nSalesforce（围绕市场和销售，CRM）\n\n\n个性化功能扩展支撑，拓展模块市场\nAI 支撑，预测销售线索和机会转化，类似客户群体分析\n并购Tableau，Mulesoft，Heroku，Linkedin\n\n\nSlack（围绕协同办公）\n\n自己的应用市场\n链接外部API，不同SaaS企业之间通过API接口实现互联互通\n\n\n微软\n\n把自己的优势产品转移到云上\n实现自己的内部产品数据互通\n\n\n其他：Oracle，SAP收购云公司\n\n总结：\n\nB端巨头围绕自己的优势产品建立生态，主要方式就是让自己的优势产品上云或者并购相关企业。\n\n而Salesforce在CRM领域之所以能击败微软、SAP等传统巨头，就是因为它向用户提供一个全家桶式的集成化解决方案，同时优化自己的UI和易用性。Salesforce更为用户考虑，价格也更亲民。\n\n微软因为自己的产品线独立并且存在竞争，导致自己内部产品都存在信息孤岛问题；SAP最大问\t题是过于自信，用世界上最复杂的用户界面“恐吓”其用户并忽视了用户对其的讨厌程度。\n\n\n\n\n\t\n🚄国内SaaS生态分析\n阿里、腾讯、飞书、华为的SaaS生态与国外的B端企业建立SaaS生态不同，国内SaaS生态多是由C端的互联网巨头发起的。（当然，传统B端企业金蝶和用友也在向云端发展，华为也通过WeLink进入SaaS生态竞争，但阿里和腾讯建立生态的声音更大些。）\n这主要是因为阿里云和腾讯云的市场份额最大、实力最强。华为虽然实力也非常强，但更加擅长的是硬件通信部分，上层软件能力偏弱，而且云市场发力也比较晚。\n财务软件方面，腾讯拉金蝶加入，阿里拉用友加入，其它方向也是各自对标：OA，建站服务，aPaaS平台，项目管理等。\n\n\n从整体看来，入选两个巨头加速器的SaaS厂商，通用型和无行业属性的的占绝大多数，垂直行业SaaS还非常非常少。除此之外，二者还依托微信小程序、支付宝小程序搭建生态。比如，利用小程序可以使用各类共享文档、健康码等产品。但相比之下微信小程序因为微信的社交属性更加容易传播，所以小程序方面，腾讯占优势。其实，微信小程序生态是一个繁荣的生态，企业使用的还是比较多的，但只是局限于前端销售和营销，后端需要对接ERP等线下系统，是一个非常松散的生态。相比阿里和腾讯，头条正在依托飞书建立自己生态，吸纳SaaS厂商进入飞书的ISV。\n从这些巨头的市场应用和精选应用来看（主要是阿里、腾讯），绝大多数偏向通用化解决方案和多样化需求相对少的领域，在我看来这离成熟的生态的建立还差得很远。\n中国的市场环境和美国差异非常非常大，如果单纯模仿美国市场依靠通用化SaaS厂商，根本解决不了中国市场比美国更复杂的多样化需求。中国走美国的路线只能是死路一条，因为中国的多样化需求比美国多10倍。\n国内SaaS生态要解决的困难：\n国内的生态多是弱关联生态，除了技术问题，还要关心厂商站队、标准太多怎么建立、厂商的忠诚度等人心问题；\n国内的生态内企业和生态外企业竞争问题，国内的SaaS企业盈利能力太弱，很难实现产业集中；\n中国SaaS私有化部署价格太高，市场最终还是看企业的产品力；\n人才技术问题。中国阿里、腾讯、字节这些互联网巨头的成功多是在C端，需要充分吸纳有丰富B端实战经验的一线技术老兵；（因为B端就是做好千千万万的小细节，没有长期一线积累是很难具备这些经验的，不深入一线了解客户的真正需求，就做不好B端产品）\n国内SaaS生态的发展思路不能过度借鉴国外。中国市场环境特点是需求多样化和支付能力弱，除了不差钱的超大型企业以外，绝大多数企业还是看重实效的。SaaS没有真正带来效果，是很难让企业持续付费的。SaaS企业必须去关注用户的感受，否则无法成功。Zoom在同质化严重的视频会议行业还能脱颖而出，就是因为创始人善于发现和关注用户感受。\n提升生态内SaaS企业的技术创新能力是必须的，以低成本满足客户多样化的需求，通过成熟的产品化大大降低成本和提升用户体验，建立集成化的全家桶解决方案，通过真正的产品实力打败生态外的群狼竞争对手，中国SaaS厂商、SaaS生态才有出路。\nB端软件是一个技术密集型和靠持续行业技术积累的行业，和C端完全不同。所以企业的技术创新能力其实比模式创新、市场开拓能力更重要些。\n任何行业如果长期不能产生爆发，一定存在着技术门槛。C端的大爆发，是因为谷歌和开源社区解决了大数据问题，否则今天辉煌的一定是IBM和Oracle这些提供算力的公司。而B端软件持续发展能力非常重要，因为商业逻辑是持续发展而且多样化的。\n\n\n\n🤔一个有趣的回答：怎样向小白解释什么是SaaS？团队正在研发一款SaaS软件。\n项目启动，最痛苦的事情莫过于“起个名字”了。能自然想得到的名字基本上都已经被别人注册商标了。又想不出“饿了么”这样别致的、一般人想不到的名字。\n名字至今还是没有，不过在想名字的过程中，我倒是正儿八经地想了下“什么是SaaS”这个问题。\nSaaS，Software as a service，软件即服务。\n软件很好理解，可是软件为什么是服务呢？如果说“软件即工具”，我倒是很能理解。微信是通讯工具、朋友圈是社交工具、钉钉是企业内协同工具、淘宝是做生意的工具、当年的陌陌是XX的工具。明明是个工具，怎么可能是服务呢？\n服务可以大体分为两种。一种是餐厅服务生提供的这类服务，是由于社会化分工导致的“专业技能输出服务”。澡堂大叔给你搓澡、技师给你按摩、医生给你看病，都属于这类服务。另一种服务是“经验知识传授服务”。这类服务在个人场景上比较少，在企业上比较多。各类咨询公司就在向企业提供这种服务。企业挖角同行大牛，其实也是希望这些人能够将自己积累起来的各种经验用在自己的企业上，帮助企业解决问题。\n软件即服务，这里的服务指的就是上述的第二类服务。\n假设，现在有一对夫妻开了一家中式快餐厅，暂且叫做“麦当鸡”吧。由于用料扎实、口味考究，很快积攒了大量的人气。半年后，餐厅收回成本，夫妻两考虑再开一家。但是，现在的餐厅赚钱是因为夫妻两花费了自己全部的精力，用心在做。如果再开一家店，那么就要分一半的精力到新店上，该如何保证两家店的餐品品质不变样呢？另外，原来两个人管理一家店，原材料自己去采购就好了。开了新店以后，自己采购忙不过来，必然要让员工来做，怎样保证原材料质量和采购方案合理呢？明年再开第三家、第四家店，这些问题会被不断放大，怎么办。\n夫妻两想到，村里老赵家的屎蛋，据说长大毕业以后去了大企业“肯德劳”，现在听说都已经是区域经理了。不如找屎蛋咨询一下，看看怎么办，没准屎蛋愿意加入进来一起干呢。\n趁着假期屎蛋回老家，夫妻两找屎蛋聊了聊，说了下自己的境遇。屎蛋说，自己现在正是事业上升期，而且也还想在大企业里面深入学习更多的东西，暂时不考虑换环境。不过，屎蛋给夫妻俩推荐了一款叫做“连锁通”的软件系统。屎蛋说，他们肯德劳也都是借助软件系统来进行一系列运营管理的。只要跟着软件的步骤去走，基本上日常经营的各个方面都能够通过软件系统进行管理。借助软件系统，员工也能明确的知道自己什么时间该做什么。可以说，这个软件系统基本上就相当于一个非常有经验的区域经理了。事实上，这个软件系统比一个区域经理还要厉害，因为它是大量的行业内专家一起参与设计出来的系统。\n夫妻俩第一次听说软件这么厉害。用一个软件，毫无连锁店管理经验的他们也能把多家店铺管理好。将信将疑，他们使用了屎蛋推荐的这套“连锁通”系统。系统厂家派出了业务员到他们的餐厅对他们进行了两天的培训他们就基本上手了。\n在上面这个场景中，“连锁通”软件不再仅仅是工具，它扮演了一个领域专家的角色。夫妻俩在使用“连锁通”的过程中，就像已经雇佣了屎蛋一样。每一步操作，夫妻俩就像是在问屎蛋：屎蛋，今天，我的各个门店各应该采购哪些原材料，各采购多少？屎蛋，为了减少用户等餐的时间，我是需要再雇一名后厨帮手还是需要再雇一名传菜员？屎蛋，新推出的菜品是否受到了用户的欢迎，需要如何改进？屎蛋，今天的营业额是多少，翻桌率是多少？每个问题，夫妻俩都能得到细致的解答。\n陌陌是工具，一个用户不会因为使用了陌陌而成为XX高手。朋友圈是工具，每个人都用朋友圈，但并不是每个人都成为了社交达人。而上面这个假想的“连锁通”并不是工具，而是服务。夫妻俩因为使用了这个服务而成为了连锁店管理专家。\n从这个角度发散。SaaS的概念其实自古就有。本质上，SaaS源自古时候的JaaS。\n啥叫JaaS？\nJing as a service。经书即服务。\n武侠小说里，如果想成为绝世高手，并不需要请一个多厉害的师傅。你只要得到一本九阴真经就可以了。\n西游记里，唐三藏也并不需要留在西天学习个一年半载的。他只需要取得真经，便可以得道为高僧，进而成佛。\n\n2020-4-28补充。\n喜欢我这个回答的人越来越多，这也让我思考我之前的回答是不是还有片面的地方。\n之前是从价值的角度，说了软件是工具和软件是服务的区别。\n最近我又在想，从商业的角度来说，如果软件不是服务，那软件还能是什么呢？\n或者说，SaaS概念提出来之前的时代里面，软件是什么呢？\n是商品。\n之前的时代里，软件制造商把软件当成工业产品在售卖。\n比如微软把Office办公套件软件刻录到光盘里面，多少钱一份往外卖。所有人都在卖软件的拷贝。\n这时候的软件产业是属于第二产业，是工业的范畴。\n而SaaS是属于第三产业，是服务业的范畴。\n啥是工业，生产出来电视机放到商场里，3000块钱一台你买走，用坏了为止。\n啥是服务业呢，你去做足底按摩，按一次给一次钱。技师给你按舒服了，你下次还去找他。你觉着这个技师不行，那大不了也就上这一次当，下次就翻别的牌子去了。\n所以，SaaS就像足疗。\n你不用花二十万去给公司上一套ERP系统，再每年花几万块钱去维护、修补、升级。\n你只需要花几千块钱年费订阅一个类似功能的SaaS软件，用好了明年再续费一年。感觉用的不舒服，明年再找别家的软件来用。而且很多SaaS产品都可以免费试用一段时间呢。\n如果你是客户，你会选择哪种方式呢？\n在大佬们都把软件当成商品在做一锤子买卖的时候，突然有个聪明蛋想到了可以把软件当成服务业来做，按次收费。\n于是软件行业的大佬们醍醐灌顶，惊呼，原来软件不一定TMD非得当成商品来卖。\n软件还可以是服务。。\n软件是服务。。\n软件即服务。。\nSaaS。。\n嗯。于是就有了这个单词。\n于是，微软推出了Office365 ，Saleforce股价逆天，SAP开始转型之路，国内众软件厂商如获至宝，喜迎SaaS春天。\n也许，这个回答才是SaaS之所以叫SaaS的真正原因。\n但是，我还是更喜欢我的上一个回答。\n因为那才是真正有价值SaaS。\n参考\nSaaS的行业概述及发展现状\n\n为什么巨头科技企业都在布局SaaS生态？\n\n既然大家都在聊ToB，那到底什么是ToB？\n\nToB与ToC\n\n\n","tags":["商业分析"]},{"title":"商业分析｜业务模型","url":"/2023/03/13/%E5%95%86%E4%B8%9A%E5%88%86%E6%9E%90%EF%BD%9C%E4%B8%9A%E5%8A%A1%E6%A8%A1%E5%9E%8B/","content":"精通互联网世界中的各种业务模型（如AARRR模型、UE模型、RMF模型、转化漏斗模型、帕累托法则、生命周期理论、营销渠道归因模型）。\nAARRR模型漏斗模型参考\n数据分析商业逻辑模型简介（一）：AARRR模型、漏斗模型\n\n"},{"title":"商业分析｜数字化和数字化转型","url":"/2023/03/10/%E5%95%86%E4%B8%9A%E5%88%86%E6%9E%90%EF%BD%9C%E6%95%B0%E5%AD%97%E5%8C%96%E5%92%8C%E6%95%B0%E5%AD%97%E5%8C%96%E8%BD%AC%E5%9E%8B/","content":"假设你叫屎蛋，是一个大学生，你生活在2015年，你是一个天才，常常会有一些能赚钱的小点子。暑假有一天，你跟朋友去饭店吃饭，手机没电了。你翻了翻自己的包，发现自己的充电宝也忘记带了。于是你想，要是现在有人能借一个充电宝给自己用，哪怕付给他2块钱或3块钱，只要能让你充半个小时你都愿意。在这一瞬间，这一个小小的想法让你产生了灵感，既然你作为一个普通人有这个需求，那说明还有很多跟你一样的人也会有这个需求。这是一个很好的创业项目啊！\n换成大部分普通人可能想想就算了。可你毕竟不是普通人。你决定立刻动手干。\n首先，你得找一个做生意的地方。你想起来你二大爷开了个火锅店，生意听说还挺火爆的，于是你找二大爷商量，能不能在他的店里做租充电宝的生意。二大爷人很好，夸了句“屎蛋从小就聪明”，就这样同意了。\n你买了10个充电宝，又设计了一个闪闪发光的小牌子，牌子上写着“借充电宝，1元&#x2F;小时”。你把小牌子和充电宝放在了门口的收银台上，这样生意就算开张了。\n你算了笔账，一个充电宝成本是50元，如果每天能借出去3小时，每天就能收入3元，一个月30天就能收入90元，怎么算一个月都肯定回本啊。从第二个月开始，每个充电宝都能给你带来接近100块的收入，10个就是1000块，而成本就是每天给充电宝充满电的电费，几乎可以忽略不计。这只是10个充电宝，如果你买1000个充电宝，在全县多找点饭店都做租充电宝的生意，那一个月的收入就是10万元了。如果再能铺到全国，那还了得！你越想越兴奋。伴着这股兴奋劲，你站到了收银台后面，开始了第一天的尝试。\n陆陆续续开始有人进饭店吃饭，很多人进门时都扫了一眼你立在收银台上的小牌子。你心想，宣传效果算是达到了。不一会儿，果然有人来找你借充电宝了。你在小本子上记下了每一个借充电宝的人吃饭的座位号和开始借用的时间，你告诉他们记得及时还过来，如果超过了一个小时是要收两块钱的。你扫视着每一个借了充电宝的人，心里计算着他们已经借了多久了，一会儿要付你多少钱。同时，你也盯着他们怕他们有心的或无意的把你的充电宝带走了不还给你了。\n墙上时钟的分针在一圈一圈地转着，饭店里吃饭的客人来了一波又一波，你的收银台小摊位前也是不同的客人来来回回，有借有还，倒也热闹。不知不觉，已经晚上十二点了，饭店里面几乎没有客人了，是时候盘点一下今天第一次尝试的战绩了。10个充电宝都还回来了，有5个被借了3次，有3个被借了2次，有2个被借了1次，总共收入了23元。结果比预想的差一点，但也还算不错啊。你觉得这个事可以坚持做下去。\n接下来几天，你还像第一天那样继续站在柜台后面借充电宝给饭店的顾客。每天的收入相对比较平均，饭店生意好的时候，你的借充电宝的生意也会跟着好一点，饭店生意差的时候，你的生意也跟着差一点。这样看来，借充电宝这个需求还是相对普遍的，第一天收入的23元并非是偶然现象。\n这个结果让你胆子肥了起来，你决定涨价。一开始你想要涨成一小时两块钱或者一小时一块五，但你却怕顾客觉得贵。后来聪明的你灵机一动，你要让顾客感觉还是一块钱一次，但是改成每半小时一块钱。真鸡贼。\n涨价以后，屎蛋你继续在二大爷的店里测试效果。又经过了几天的测试，你发现借充电宝的人并没有比以前变少，与此同时收入却有了小幅度的增长。你对自己制定的涨价策略非常满意。\n在过去不到两个星期的时间里，二大爷店里的十个充电宝已经给你带来了300多元的收入，眼看着再用不了几天，你就能收回前期投资的500元了。再往后，每个月一千多元的收入就几乎都是你的纯利润了。此刻，你决定扩大生意规模。\n头疼的事情来了。你一个人只能看着二大爷店里的充电宝生意。如果你再谈好一家饭店愿意放上你的充电宝，谁来帮你看着充电宝不丢，谁来帮你收钱呢。你想到了雇佣一个人，但一个饭店一个月借充电宝的收入也不过1000多元，你自己是因为闲着也是闲着才愿意做这个生意的，这点钱哪里够雇一个人的呢？\n聪明如你，很快就想到了解决方案。二大爷店里有那么多的服务员，而且收银员本来就会一直呆在前台。如果跟二大爷谈一下，把每个月收入的一千多元分一半给二大爷，让二大爷要求店里的员工帮你看着充电宝和帮你收钱，这样你不就不用雇人了嘛。而且这个模式到每个饭店都可以复制了。于是下午二大爷不忙的时候，你就找他谈了。二大爷人很好，依然夸了一句“屎蛋从小就聪明”，就这样又同意了。\n二大爷这边的问题已经解决了，你开始跑其他陌生的饭店，找老板谈合作了。你以为会很顺利呢，可没想到刚开始谈第一家饭店就遇到了困难。人家老板跟你说，我们平时挺忙的，实在没空帮你照看充电宝；就算我们有空帮你照看，你每个月分我这几百块钱，对我们饭店来说实在太少了；退一万步讲，就算我们愿意做这个事情，那我们为什么不自己去买几个充电宝来借给客人呢？\n你觉得老板说的很对呀，你也回答不了老板这些问题。但是好在你是一个很有韧性的人，你不愿意就此放弃，所以你又用了两天时间继续跑了附近几条街上的几十家饭店。也算是功夫不负有心人，又有四家饭店的老板被你说动了，同意试试看。你又买了几十个充电宝提供给了这些饭店。到此为止，已经有五家店同时在帮你运营的借充电宝的生意了。如果还是能达到之前你二大爷店里的收入水平的话，你一个月也会有三千多块钱入账了。这笔钱对于你这样一个大学生来说，算是一笔不少的钱了，每个月是花不完的。\n就在你正开心着的时候，二大爷的店里传来了不好的消息，充电宝丢了一个。二大爷倒也没有显得很抱歉，只是微笑着跟你说店里忙起来的时候实在是看不过来，可能有的客人自己也忘了还了，带回家了，于是就丢了。你的心里也没有怪二大爷，你在想靠人来这么看着的确是看不过来。如果不想个办法，别的饭店的充电宝可能也会陆陆续续开始丢。\n聪明如你，再次灵机一动，想到了收押金。一个充电宝收顾客五十块钱的押金，顾客还充电宝的时候再把押金还给顾客。于是你跟二大爷和其他四个饭店的老板沟通了一下，有两个老板很不开心，觉得又给自己增添了麻烦，但是最后也勉强接受了。\n就这样，你的充电宝生意就继续运转起来了。你每天会到放了充电宝的饭店里面转一转，看看情况。每周你会找饭店老板结账。结账的时候，你发现有的饭店的收入总是会比别的饭店低很多。你怀疑是饭店老板给你报的账目有问题，但是你实在是没有证据，而且你也不想为了这点钱撕破脸皮，也就算了。但是对于这个问题，哪怕聪明如你，也始终没有想到更好的解决办法。这也是你没有尝试把生意扩张到更多的饭店的原因。\n很快暑假就要结束了，你要回学校了。你算了算账，几十个充电宝的本钱基本上快要收回来了。你想着，回学校以后，家里这些饭店的充电宝就让他们继续运营着。你也不会再像之前一样有很多时间去巡店了，每周饭店老板愿意给你算多少收入就多少收入吧。就当个不亏本的小生意这么做着吧，哪怕到最后有的饭店不愿意再跟你合作了，这些饭店的充电宝你还可以再拿回来在二手市场低价处理掉。\n回到学校后，你仔细复盘了一下这个生意。用户的需求是真实存在的，你的解决方案也能满足用户的需求。唯一的不足就是这个生意似乎很难复制，很难扩大规模去做。你自己可以跑几十家店甚至几百家店，但如果要把这个生意做到别的城市做到全国呢？谁去跑饭店呢？如果招销售去跑，那一个销售一个月好几千块钱的底薪，要借多少充电宝才能赚回来啊。而且，这些充电宝放到饭店以后还得有自己的人去巡店看着，不然根本没办法解决饭店老板不出力或做假账的问题。因此，这个项目一旦扩大以后，风险太高了，只能当个小生意来做。\n此后，你就把重心放到了学校的事情上面，充电宝这个事情你就没有多想。\n时间来到了2016年夏天，还有半个月你就要毕业了。一天，你跟同学们到学校附近的饭店聚餐，你突然发现饭店门口的柜台上放了一个叫做“随心充”的小箱子，里面似乎插满了充电宝。你向老板打听了一下，老板说这个共享充电宝是别的公司放在这里的，用手机扫码以后就会弹出来一个充电宝给你拿走用。这是你第一次听到“共享充电宝”这个词，你当时兴奋极了。一方面你觉得找到了知音，另一方面你又在懊悔自己当年怎么没想到这个项目还可以这么玩。\n充电宝有了外面的这个小箱子，当年困扰你的问题全都迎刃而解了。所有的充电宝不再需要人来看着了，也不用担心饭店老板报假账了。箱子里面的每个充电宝，谁借的，借了多久，系统里面都会有记录。用户付的钱也直接通过线上支付到公司的账户了。有了这么个小箱子，共享充电宝这个生意一下子变得可复制、可无限扩大规模了。\n聚餐饭局上，你显得心不在焉。你好奇到底是什么样的公司，什么样的创始人想到了这样的解决方案。同时，你也觉得这个项目一定能做的非常大。带着好奇和对未来的憧憬，聚餐还没结束你就已经决定，毕业后要到这家运营“随心充”的公司应聘。\n你顺利的应聘上了这家公司的销售员岗位。这时你才知道，给充电宝套上小箱子只是这家公司“黑科技”的冰山一角。公司有一支几百人的软硬件研发团队，研发出的“黑科技”很多。就拿你们销售岗位来说，公司研发了一款APP给你们每一个销售员使用。在这个APP上，你能看到你所负责的区域是哪一片，在这片区域里有哪些饭店还没有部署你们的充电宝，这些饭店就是你的潜在客户了；你也可以看到你已经签约的饭店的充电宝使用情况，包括用户扫码支付的每一笔订单，用户当前使用的时长，每个饭店的借充电宝的销售额排名等；你也能够看到你负责的饭店的总销售额在你的部门的排名，甚至是在全公司的排名；你还可以在APP上远程修改任何一台充电宝机器的单价，对于生意好，充电宝供不应求的饭店，你可以在APP上把单价调整地更高。\n总结来说，通过一个APP，你就能掌控你所负责的所有充电宝机器的运营。你在想，作为一个普通的销售员尚且有这么强大的运营工具，那你的销售主管、公司的销售总监、公司的运营部门、公司的董事会，他们的运营工具得强大多少倍啊。应该说，全公司的业务运营都是被复杂的系统监控和协调起来的，公司各级人员都可以在线实时查看自己权限范围内的各个维度的业务数据。每个人都能根据这些业务数据做出及时的业务决策。比如从你一个普通销售员的角度来说，你可以及时发现哪家店的销售额总是垫底，继而重点研究这家店的情况，是饭店老板把充电宝放在了比较偏僻的角落，还是充电宝硬件有故障，根据具体原因你就可以给出对应的调整策略。销售主管也可以及时发现手下的哪个销售总是业绩不佳，继而对他重点帮扶。销售总监则可以盯着各个城市的大盘数据，去看每个城市销售额的增长曲线，哪个城市增长乏力，哪个城市已经饱和且稳定，这些都通过屏幕尽收眼底。公司最顶层领导每天晨会也会通过系统来盯数据，今天的数据环比是增了还是减了，增和减的原因是什么，充电箱的故障率是否维持在健康水平，用户的平均租借时长是否稳定等等。你惊叹于公司软件系统的强大。\n在公司呆久了，你慢慢知道这样的运营方式也并非你们公司的独创。这种运营方式有一个名称叫做：数字化。公司通过软硬件相结合的技术手段，把有价值的业务数据及时地采集、计算、呈现。每一级的业务负责人都有了自己的数字驾驶舱，可以实时掌握多维度的业务数据、随时分析数据发现问题、尽早介入异常环节；而如果业务数据一切正常，各级负责人则可以放心让业务继续运转，自己则把精力放到与竞争对手竞争策略的调整、新人的培养、新市场的开拓、新业务的创新上面。\n联想到自己一年前完全靠人工来经营充电宝的生意，只经营了5家饭店都困难重重。而现在自己所在的公司通过数字化的方式来运营同样的生意，却每个星期都在开辟新的城市，很快就能占领全国市场。再看看现在公司上下，从CEO到一线销售员，大家全部都数字导向，用数字说话，很少的主观臆断。公司技术部门不断研发更强大的数字化管理系统。这短短一年多的两段经历不断在你的脑海里闪过，你似乎一下子就明白了数字化的含义、数字化的意义。\n","tags":["商业分析"]},{"title":"商业分析｜管理模型","url":"/2023/03/13/%E5%95%86%E4%B8%9A%E5%88%86%E6%9E%90%EF%BD%9C%E7%AE%A1%E7%90%86%E6%A8%A1%E5%9E%8B/","content":"知晓基本的管理模型（如PEST、4P、4C、SWOT、五力矩阵、波士顿矩阵、GE矩阵、价值链模型、GE、战略钟、SPACE模型、SCP、STP等）。\n"},{"title":"商业分析｜超市分析","url":"/2023/03/12/%E5%95%86%E4%B8%9A%E5%88%86%E6%9E%90%EF%BD%9C%E8%B6%85%E5%B8%82%E5%88%86%E6%9E%90/","content":"如果你是超市老板，发现业绩下滑怎么分析？5W1H法。\n![指标下降分析 （5W1H法）](&#x2F;Users&#x2F;xiaoyu&#x2F;Library&#x2F;Mobile Documents&#x2F;iCloudnetxmind~brownieapp&#x2F;Documents&#x2F;指标下降分析 （5W1H法）.png)\n你会用哪三个指标来评估超市？1、销售数量——客户消费的商品的数量。销售数代表顾客的支持情况。\n2、销售额——客户购买商品所支付的金额。\n3、周转率——周转率和统计的时间段有关。周转率&#x3D;（销售吊牌额&#x2F;库存金额）×100%。科学的库存管理控制商品库存，使得既不全因库存太多而积压资金，增加营运成本，也不会因缺货而损失销售机会，究竟一家店要有多少商品库存量才算适当呢？一般的方法就是先求出商品的周转率，所谓商品周转率是指库存商品在单位时间里卖出的比率，也就是在一年中库存的商品，可以周转多少次而返回现金。\n\n如何提高商品的周转率？\n\n充分利用电脑资料，运用销售资料的统计方法，可获知畅销品、滞销品及销售正常的商品数据，加强滞销商品的销售或处理滞销品为重点工作之一。\n\n有效利用促销活动的力量，增加销售额，来提升商品的周转率。\n\n季节性的商品必须加强陈列，此类商品毛利虽低，但业绩多，周转快。\n\n\n\n4、周转天数——周转天数&#x3D;库存金额&#x2F;销售吊牌额。周转天数越长，表示经营效率越低或存货管理越差； 周转天数越短，表示经营效率越高或存货管理。\n5、退货率——退货率&#x3D;退货金额&#x2F;进货金额（一段时间） ，例：在一段时间内，客户的退货率。公司的退 货率\n6、售罄率——售罄率&#x3D;销售数量&#x2F;进货数量。\n7、库销比——库销比&#x3D;期末库存金额&#x2F;（本期销售牌价额&#x2F;销售天数*30） 。 （只有在单款 SKU 计算中可用 数量替代金额。整体的必须还是看金额）\n8、连带率——连带率&#x3D;销售件数&#x2F;交易次数。 （也叫连单率）\n9、客单价——客户在一次交易中支付的金额总和称为客单价。 客单价&#x3D;销售额&#x2F;交易次数。10、平均单价——平均单价&#x3D;销售金额&#x2F;销售件数。\n11、平均折扣——平均折扣&#x3D;销售金额&#x2F;销售吊牌额。\n12、SKU（深度与宽度）——英文全称为 stock keeping unit, 简称 SKU，定义为保存库存控制的最小 可用单位。\n13、坪效（重点）——就是指终端卖场 1 平米的效率，一般是作为评估卖场实力的一个重要标准，它反映的是卖场的有效利用程度。坪效 &#x3D;销售金额&#x2F;门店营业面积（不包含仓库面积） 。\n14、促销商品——指促销活动期间指定的商品，其价格低于市场同类的商品。不包含正常降价。基本指 公司活动仓货品。\n15、毛利——毛利&#x3D;实际销售额－成本。\n16、净利——净利&#x3D;去税销售额－去税成本。\n17、毛利率——销售毛利率是毛利占销售收入的百分比，也简称为毛利率，其中毛利是销售收入与销售 成本的差。毛利率&#x3D;（毛利&#x2F;实际销售额）×100%。\n18、促销次数——促销次数有宏观概念上的，也有微观概念上的。微观层面上，是表示一个单品在一段 时间内参与促销的次数。\n19、交易次数——客户支付一笔交易记录作为一次交易。\n20、期货——所谓期货，一般指期货合约，就是指由期货交易所统一制定的、规定在将来 某一特定的 时间和地点交割一定数量标的物的标准化合约 。服装行业上具体指订货会上所订购且分期交付的货\n","tags":["商业分析"]},{"title":"商业分析｜飞书","url":"/2023/03/10/%E5%95%86%E4%B8%9A%E5%88%86%E6%9E%90%EF%BD%9C%E9%A3%9E%E4%B9%A6/","content":"❓竞品分析：飞书 &amp; 叮叮 &amp; 企业微信背景钉钉卖的是“云钉一体”的生态，背后有阿里云做撑腰；企微背靠的是微信的强连接能力，在对外连接层面一直有较强的说服力；而“后发者”飞书，只能靠输出“先进管理”的理念和出色的产品力来取胜。\n竞品分析\n\n总结&amp;建议\n1、细分行业切入：通过分析，可以看出钉钉在国内市场中拿下了大部分的中小企业，并且功能齐全，飞书刚刚入局，策略上应该避免正面与钉钉碰撞。字节跳动在内容产品上具备行业领先地位，自媒体背后的组织，可以作为飞书入局的切入点，在一个行业先做深，打造爆点；\n2、应用平台建设：基础功能的补全，从海外市场到国内市场，一些习惯需要随着用户改变，在功能上，应该增加补全企业管理类功能，加速应用开放平台建设，吸引ISV（Independent Software Vendors，独立软件开发商）入驻，这里应该给创业型的ISV更多支持；\n3、由内到外：字节跳动是近几年国内发展最快速的互联网公司，其公司内部优秀的管理方案和协同办公方案，应该随着飞书的扩展推向市场，推出解决方案的同时输出自身的管理理念。\n飞书 VS 叮叮\n从两个ToB工具的理念，不妨看出来，钉钉坚持的事是“服务老板、服务企业”，坚持的观念也是“老板在哪里、员工在哪里”，也就是说管理理念是自上而下的。\n而飞书的理念是提高所有人的效率，打工人用也是帮你提高效率，早点完活儿，多点时间思mou考yu，老板用也抓紧时间处理工作，看到大家都干什么呢？老板也放心。透着些许的“前进”的味道，打工人没有蹭公司流量，老板也看到大家都有产出，而解决这些问题的载体就是【飞书】，并且飞书上面的特色功能。迭代本地文档的在线文档，迭代老式会议的飞阅会，帮出输出价值的飞书妙计。本质上都是在创新和引领，用先进更好的，能够真的解决很多问题的方式，变成工具，让大家用工具，顺便解决了很多大家已经不以为然的诟病。因为我们在工作中，有多少次都觉得会议低效，缺只能说一句“都这样”而浪费了一天的宝贵时间呢？\n👩🏻‍💼HR SaaS：飞书招聘\n据公开资料，尽管遭遇疫情，字节跳动在2020年依然由6万人迅速扩张到近10万人规模，尤其值得注意的是，90%的人都是通过飞书招聘线上面试完成。\n\n打破招聘“伪线上，真线下”飞书招聘和其他招聘工具最大不同在于彻底走向了线上化与智能化，并实现了在统一系统下的无缝体验。遵循奥卡姆剃刀原则，飞书招聘去掉了传统招聘中存在的诸多干扰因素（如线下面试的交通时间），将需求复杂的企业人力资源需求体系化，简化了过去繁琐的管理模块，并通过直接调用飞书内的视频功能进行视频面试。\n\n一方面是到面率的大幅提升。线下面试，往往需要候选人腾出3个小时的时间，但其中很大部分是花在路上的时间，而通过飞书视频面试，省去了三分之二的时间，也解决了因为不可控原因造成了迟到问题。\n\n另一方面，围绕沟通中的不同环节提供数字化服务。飞书招聘一个重要功能在于通过视频录制和语音转文字技术，将面试数据更好以数字化形式沉淀下来，不仅能帮助企业分析面试过程和面试问题，提高面试质量和面试官水平；也能在发生面试争议的时候找到确凿的记录。另一个功能是在面试中通过数据库为面试官提供参考的面试问题，进一步提升双方的沟通效率。\n\n\n飞书招聘是有“根”的，它根植于飞书这一办公协作体系之上，在打通飞书日历、视频、群聊天、搜索功能之后，飞书招聘作为“非主流”的面试方式有了主流平台的硬底子，这是企业管理者希望看到的，因为这不但实现了企业办公、招聘的全面线上化，也降低了跨平台使用HR SaaS服务的难度。\n顺趋势而行：智能化、轻量化飞书招聘的一大优势在于使用智能化的数据处理方式，提高了企业制定人才发展战略的效率。通过AI技术，飞书招聘不仅能自动对简历进行标准化处理，提供一套可以快速查阅的标签标注系统，让HR在招聘时一眼便知应聘者的多种信息。同时，飞书还能自动对应聘者的企业和学校信息进行补充，从而减轻HR和用人部门的查询调研成本。\n此外，为了优化人才选拔环节，飞书招聘还打造了一个“聪明”的人才库，这也让传统招聘望尘莫及。这个人才库能够快速解析求职者简历，并自动生成企业所需要的标准简历，即便应聘者没有进入最终环节，也会进入企业历史人才库，并在之后企业有用人需求时进行智能匹配，对于企业来说，这样的可持续人才战略是最能帮助其快速发展的方式。\n另外，面试时的一些细节也让企业在线上招聘时更加灵活，比如飞书招聘能将面试官可用面试时间进行智能推荐，让候选人直接自助选择面试时间，而这将进一步释放HR面试邀约的工作量。\n随着时间推移，我们看到当前国内HR SaaS逐渐细化为三类不同服务：\n\n第一类提供综合类的HCM（人力资源管理系统），主要面向大企业；\n第二类以轻量级HR SaaS为切入，功能覆盖人事管理、考勤、OA等功能；\n第三类是介入薪资计算、灵活用工、聚合招聘、智能排班的人力资源管理机构。\n\n尽管相较于海外，中国在这三类服务中都还处在发展早期，但不少投资人都认定，其中都有望诞生SaaS行业的独角兽企业，飞书招聘成长时间不长，但其依托飞书平台进行的轻量化服务显然正在改变SaaS行业生态。\n疫情之后，远程办公成为常态，而求职者越来越年轻化，互联网原住民越来越多，时间正在证明线上招聘的价值，而飞书招聘的存在，在帮助企业更快适应这种变化。\n一切回归招聘本质\n传统招聘平台：简历等资料虽然集中在线上，但面试、反馈、内部沟通等依然通过线下进行，这造成了招聘效率较低，并且无论对面试官或者是应聘者，面对临时出现的情况并不能灵活进行调整，因此沟通成本也很高。\n飞书招聘能够深入招聘的每一个细微环节，为面试官进行优化，这不仅让管理者有了更好的产品体验，也为企业节省不少用人成本。如今看来，能够为企业节省用人成本的HR SaaS服务越来越受到资本青睐，去年8月，Moka完成B+轮过亿元人民币融资，今年5月，大型一体化HR SaaS及人才管理平台北森更是完成2.6亿美元规模的F轮融资，成为国内HR SaaS领域最大一笔股权融资。\n\n而这些HR SaaS服务的崛起，也开始影响越来越多求职者的求职方式。如今，中国有超1.38亿人通过互联网寻找就业机会，互联网招聘行业的增长红利仍在释放中。这种情况下，企业如何吸引和留住顶尖人才愈发重要，正如国际猎头顾问协会总裁兼首席执行官Karen Greenbaum所说，企业“应重视数字转型，即需要改变商业模式以适应数字化发展。”\n飞书招聘的出现印证了这种变化，在融合移动端与PC端，努力提升效率以及面试体验的同时，招聘成为飞书的一个支撑点，并延伸出飞书绩效这样的产品，以便打通员工从进入公司开始的整个职业生涯，将其工作数据全面数字化。\n而数字化则是许多企业期望实现标准化管理的重点，据了解，目前飞书已经收获了包括理想汽车、元气森林、华住酒店、安克创新等企业客户，这些企业对于HR SaaS服务也有着极大需求，飞书招聘的出现，其实正在影响越来越多这样的企业，并有助于其提升企业竞争力，正如字节跳动副总裁谢欣所说：\n“飞书不仅在于提升效率，更是为提升组织而打造的工具，在知识经济时代，飞书将帮助企业成为更有竞争力的组织。”\n参考\n飞书要不要做生态？剖析第一家 All in 飞书的独立 SaaS 案例 \n飞书招聘，站在人力资源与SaaS的十字路口\n你所不知道的飞书，飞书竞品分析报告\n如何看待大量公司用钉钉不用飞书?\n\n","tags":["商业分析"]},{"title":"数据分析面试题｜字节","url":"/2023/03/11/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BD%9C%E5%AD%97%E8%8A%82/","content":"字节商业化战略分析日常实习生【一面】\n\n经历面：框架+做什么+结果&#x2F;收获\n抖音和快手的差异？\n估算抖音电商的GMV？\n抖音和快手电商谁会赢？\n如何判断&#x2F;分析用户对平台的价值？\n抖音做电商的首要考量？要怎么做？\n类似访谈记录，考速记：读一段文字， 记录并整理成文稿，10-15min后提交\n\n总结：\n一定要对自己的经历非常熟悉，能够结构化地表述同时清楚细节\n需要对平台和行业有一定的了解和思考，尤其是主要的竞品比较\n结合JD可以想象一下工作内容，可能会针对这些能力做测试，这次的访谈记录整理就是我之前没有太训练且忽视了的……\n【二面】\n\n经历面：主要深挖细节，自己做的部分\n\n认为直播电商商家成长的痛点在哪\n\n头部化对平台来说是好是坏（回答是坏）\n\n怎样去头部化\n\n\n总结：和第一位面试官完全不同的风格，深挖简历，问题会更加具体灵活，会被追问和反问，穿插着小问题，回答问题的分析逻辑和分析结果同样重要\n【三面】HR面，但自己感觉压力最大\n只问了经历，把抠经历细节做到了极致，一定要非常非常熟悉自己的经历，在描述的时候加上相应的具体数据，不要用一些模糊的词……\n字节商业分析实习\nTimeline：\n4.13投递，当晚收到面试邀请——4.14一二面——4.15三面——4.16HR面，30分钟左右拿到OC\n\n‼️一面（25分钟）\n\n自我介绍\n\n介绍一下你做过的和数据分析相关的大项目\n\n如果你是超市老板，发现业绩下滑怎么分析？\n\n接3. 你会用哪三个指标来评估超市？\n\n你用过SQL吗？\n\n接5. LEFT JOIN和INNER JOIN，FULL JOIN什么区别？\n\n都是连接查询；\n\ninner join -&gt; 只保留两张表中完全匹配的结果集；\n\nleft join -&gt; 返回左表中所有的行，即使在右表中没有匹配的记录；\n\nright join -&gt; 返回右表中所有的行，即使在左表中没有匹配的记录；\n\nfull join -&gt; 返回左表和右表中所有的行，左表和右表中没有匹配数据各自单独一行。\n\n\n\n接6. HAVING和WHERE什么区别？\n\n“Where” 是一个约束声明，使用Where来约束来自数据库的数据，Where是在结果返回之前起作用的，且Where中不能使用聚合函数。\n\n“Having”是一个过滤声明，是在查询返回结果集以后对查询结果进行的过滤操作，在Having中可以使用聚合函数。\n\nHAVING 子句可以让我们筛选成组后的各组数据，WHERE子句在聚合（聚合函数如SUM, COUNT, MAX, AVG等）前先筛选记录．也就是说作用在 GROUP BY 子句和 HAVING 子句前；而  HAVING 子句在聚合后对组记录进行筛选。\n\n结论：\n\n当分组筛选的时候 用having\n\n其它情况用where\n\n\n用having就一定要和group by连用，用group by不一有having （它只是一个筛选条件用的）\n只要条件里面的字段, 不是表里面原先有的字段就需要用having。\nSQL在查询表的时候先把查询的字段放到了内存里，而where查询的时候是从表里面查的，其余需要用having。\n\n\n\n接7. 你会窗口函数吗？你能解释一下ROW_NUMBER 和RANK_NUMBER的区别吗？\n\n你本科经济学，为什么转商业分析？\n\n你这段时间怎么安排，什么时候开学？一周实习几天？\n\n反问环节\n\n\n‼️二面 （45分钟）\n\n自我介绍\n在过去的经历中，哪个经历给你印象最深刻，简单介绍一下？（我选了ML课程项目）\n接2. 详细问了项目里用的逻辑回归原理，适用性？\n接3. 你用python中的什么包来做逻辑回归？（具体到sklearn里的细节，包括评价指标）\n接4. 你可以举一个逻辑回归作为分类器可行的数据吗？可以用你自己项目中的数据\n接5. 询问项目中用到的平衡数据集的SMOTE方法。\n继续SQL，和一面问的差不多就不详细说了\n你怎么评价淘宝这个平台的好坏？（业务题）—选择指标\n如果淘宝业绩下滑你觉得是什么原因，怎么分析？\n你了解商业分析岗位吗？能仔细和我说说吗？它和数据分析的差别在哪？\n什么契机让你选择商业分析？\n你这段时间怎么安排？（和一面10.差不多）\n反问环节。（这里反复追问你还有什么问题吗让我很慌）\n\n‼️三面（20分钟）\n\n自我介绍\n选一个你觉得印象最深刻的项目来介绍？\n你本科经济，为什么硕士读数据分析？之前没有相关经历，为什么转岗？\n你怎么评价自己？\n你的职业规划？\n是哪里人？\n你的兴趣爱好？（因为兴趣爱好很独特被追问了几个问题）\n你有什么想问的？（当时问了怎么评价我，他说不会在这个环节评价应聘者）\n\n参考\n超市营运指标分析，七个方法任你采用！ \n\n\n"},{"title":"数据分析面试题｜小米","url":"/2023/03/08/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BD%9C%E5%B0%8F%E7%B1%B3/","content":"小米\n关于视频app（比如爱奇艺）首页推荐的推荐顺序，你会考虑哪些指标？（小米）\n\n推荐类问题有四类指标，分别是用户的行为数据，用户的属性数据，推荐产品的属性数据，上下文数据。\n（1）用户行为数据：浏览、点击、播放、搜索、收藏、点赞、转发、滑动、在某个位置的停留时长、快进等等一切操作行为；\n（2）用户属性数据：年龄、性别、地域、学历、家庭组成、职业等；\n（3）视频属性数据：评分、播放量、评论数、出品方、导演、主演、国别、年代、语言、是否获奖、剧情等；\n（4）上下文数据：用户最近观看历史记录、最近偏好的演员明星、最近常看的视频类型等。\n\n有20000人的就餐需求，现建了一个新食堂，如何规划食堂的座位数？（小米）\n\n类似费米问题，这里注意时间。\n假设食堂就餐时间为2h，则每小时需要为10000人提供就餐服务；假设每人就餐时间为15min，且人员到达食堂的时间点分布均匀，则1h可以服务4批就餐人员，平均每批2500人，意味着将会有这么多人同时就餐，就可以按照上述数据进行座位规划。\n\nboss直聘的投递量较低，你会如何提高？从前期调研、方案策划到推广复盘等过程说明一下（小米）\n\n对于这种问题，大步骤有三个，首先进行市场调研，分析其他竞品的状况，从多个维度进行比较分析；然后是针对目标问题设计方案，例如如果用户少，那么就想如何提升客户数量；最后就是AB测试。\n1） 前期调研\n进行竟品分析，通过调研了解当前各招聘App的现状。从获客、活跃、投递及转化率多维度进行评估比较，了解boss直聘在各维度的能力水平。\n2） 方案策划\n根据待加强的环节制定相应的方案。如果是当前boss直聘的规模小导致投递量较低，那应该多从获客端思考，增加丰富获客渠道或提升各渠道的获客能力。如果其规模已经非常大，但是活跃用户非常少，那应该积极采取营销活动以促活，提升最终的投递量。若规模和留存率已经足够高，问题大概率存在产品上，应充分充分思考漏斗中的每一个环节产生漏损的原因，从用户旅程出发，优化用户体验，提升每一个环节的转化率，最终达到提升投递量的目的。\n3） 推广复盘\n根据策划的方案，进行小规模的测试，在复盘后发现该策略能够有效提升投递量，则可以进行推广。\n","tags":["数据分析"]},{"title":"数据分析｜AB实验","url":"/2023/03/08/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%EF%BD%9CAB%E5%AE%9E%E9%AA%8C/","content":"\n面试官:“你有没有想过用AB实验来优化项目？”\n​    瑟瑟发抖的我：“不好意思，我在做项目的时候想过用AB实验，但由于XXXX的原因无法落实。不过我自己构思了比较完整的实验思路……（此处省略若干字），如果有机会让我实施AB实验，我相信能够让项目表现更好。”\n​    其实这是一个很加分的回答。在面试官看来，眼前的候选人虽然没有参与AB实验，但自己琢磨思考了项目优化方案，应该有不错的自我学习和自我驱动能力 （给自己鼓掌撒花ing）。\n作者：阿狸和小兔链接：https://www.jianshu.com/p/0b54dc8b0880来源：简书著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n\n什么是A&#x2F;B测试简单来讲，A&#x2F;B测试是一种比较手段：通过分析同一总体下，由于某些不同的策略导致样本数据表现出的差异，来推断某些策略的效果。\n\n几个核心概念：同一总体，不同策略，不同样本，差异及效果\n本质上来说，A&#x2F;B测试就是假设检验理论的一个实际应用而已，所以想了解A&#x2F;B测试的理论，只需要了解假设检验的理论即可。\nA&#x2F;B测试流程一个完整的A&#x2F;B test主要包括如下几部分：\n1、分析现状，建立假设：分析业务，确定最高优先级的改进点，作出假设，提出优化建议。\n2、设定指标：设置主要指标来衡量版本的优劣；设置辅助指标来评估其他影响。\n3、设计与开发：设计优化版本的原型并完成开发。\n4、确定测试时长：确定测试进行的时长。\n5、确定分流方案：确定每个测试版本的分流比例及其他分流细节。\n6、采集并分析数据：收集实验数据，进行有效性和效果判断。\n7、给出结论：①确定发布新版本；②调整分流比例继续测试；③优化迭代方案重新开发，回到步骤1。\n注意点：1. 测试时长：测试的时长不宜过短，否则参与试验的用户几乎都是产品的高频用户。\n2. 分流（或者说抽样）：应该保证同时性、同质性、唯一性、均匀性。\n①同时性：分流应该是同时的，测试的进行也应该是同时的。\n②同质性：也可以说是相似性，是要求分出的用户群，在各维度的特征都相似。可以基于用户的设备特征（例如手机机型、操作系统版本号、手机语言等）和用户的其他标签（例如性别、年龄、新老用户、会员等级等）进行分群，每一个A&#x2F;B测试试验都可以选定特定的用户群进行试验。\n思考：如何判断是不是真的同质？可以采用AAB测试。抽出两份流量进行A版本的测试，进行AA测试，并分别与B版本进行AB测试。通过考察A1和A2组是否存在显著性差异，就可以确定试验的分流是否同质了。\n③唯一性：即要求用户不被重复计入测试。\n④均匀性：要求各组流量是均匀的。Hash算法。现在一般由专用的A&#x2F;B测试工具负责。也有看到一篇文章写了python实现，大体的思路是对用户id添加Salt值，对其散列，并据此算出一个0-1之间的浮点数，同设定好的阈值比大小，从而分组。有兴趣的可以看看，该作者的思路很清晰： 随机分配里的Why and How。（统计学原理上，我没有找到均匀性这一要求的依据，其实双样本的假设检验并不要求两个样本的数量相等或相近。当然从直观上是可以理解，希望分出的用户组越相近越好，包括人数的相近。）\n3. A&#x2F;B测试只能有两个版本么？\nA&#x2F;B test不是只能A方案和B方案，实际上一个测试可以包含A&#x2F;B&#x2F;C&#x2F;D&#x2F;E&#x2F;……多个版本，但是要保证单变量，比如按钮的颜色赤&#x2F;橙&#x2F;黄&#x2F;绿&#x2F;青&#x2F;蓝&#x2F;紫，那么这七个方案是可以做A&#x2F;B测试的；但如果某方案在旁边新增了另一个按钮，即便实验结果产生了显著差异，我们也无法判断这种差异的成因究竟是谁。\n4. 同一段时间内可以做不同的A&#x2F;B测试么？\n比如一个test抽取总体20%的流量做按钮颜色的实验，另一个test也抽取总体20%的流量做布局样式的实验。是否可行？\n我认为是可行的。但要求多个方案并行测试，同层互斥。如果从总体里，先后两次随机抽取20%流量，则很有可能会有重叠的用户，既无法满足控制单变量，又影响了用户的使用体验。\n\n同层指的是在同一流量层中创建实验，在此层中创建的实验共享此层中的100%流量。\n互斥指的是在此层中，一个设备有且只能分配到此层多个实验中的某一个实验。\n\nA&#x2F;B测试原理：假设检验\n参考：https://zhuanlan.zhihu.com/p/68019926\n\n\n\n参考：https://www.jianshu.com/p/0b54dc8b0880\n\nAB实验是数据分析、产品运营、算法开发在工作中都时常接触到的工作。按钮颜色、广告算法、标签排序，这些互联网产品里常见的功能与展示都是在一次次AB实验中得到优化。\n   在实习中，并不是每一个实习生都能接触到AB实验，这也让很多没有相关经历的人误认为AB实验是一项高大上的工作任务。但其实——\n   许多公司搭建了可(sha)视(gua)化的AB实验平台，业务、运营以及产品都一眼看出AB实验的结果……不过，由于企业搭建的AB实验平台在权限、监控上有诸多限制，加上很多Leader出于实习生实习期短、留用概率小的顾虑，大部分实习生都不会参与完整的AB项目。\n​    可是——\n​    尽管在实习中没有接触过AB实验，在简历中也没提到丝毫，这不代表在面试中就能逃过一劫……\n\n\n​    我在实习中就没有接触过AB实验，但面试官仍然对我抛出来的项目分析过程饶有兴趣，也会问我有没有使用AB实验作出优化。得益于面试前全方位的准备，我的面试回（tao）答（lu）往往是:\n​    面试官:“你有没有想过用AB实验来优化项目？”\n​    瑟瑟发抖的我：“不好意思，我在做项目的时候想过用AB实验，但由于XXXX的原因无法落实。不过我自己构思了比较完整的实验思路……（此处省略若干字），如果有机会让我实施AB实验，我相信能够让项目表现更好。”\n​    其实这是一个很加分的回答。在面试官看来，眼前的候选人虽然没有参与AB实验，但自己琢磨思考了项目优化方案，应该有不错的自我学习和自我驱动能力 （给自己鼓掌撒花ing）。\n   引申一步，当你对自己的项目足够熟悉时，哪怕没有机会开展AB实验，仍然可以和我一样，在回答项目相关问题时，代入自己对AB实验的思考。\n   好了，言归正传，进入今天的正题。\n01 我们先介绍统计检验\n​    在统计学中，想要证明一个命题是正确的，只能通过证明其否命题是错误的来达到目的。假设检验是用统计数据来判断命题真伪的方式。我们常常会假设两个命题：\n​    H0：备受质疑的命题\n​    H1：有待验证的问题\n   那如何来证明H0和H1孰对孰错呢？这时候我们需要用到P值。\n   P值是什么？P值就是在H0假设成立的情况下，得到样本观察结果或更极端的观察结果出现的概率。\n   这句话好绕口，我们可以简单的理解成P代表了对H0命题的支持程度。所以P值越小，H0命题正确的概率就越小，H1命题正确的概率越大。我们有常常会指定显著性水平α&#x3D;0.05，当P&lt;α时，H0命题成立的概率&lt;0.05，这是一个受到统计学支持的假命题。\n   在学习统计学时，我们接触了一大堆显著性水平，显著区间的概念；在考完统计学后，统统还给了大学老师……如果是面试数据分析相关的岗位，强烈建议复习一下，再总结成方便自己记忆的文字，存入面试文档（插播一句，后台好多人私信我面试文档里准备了哪些内容……按当前进度，一只伪装加班狗表示写到这一块预计应该要4月了吧emmmm）。\n   若是有面试官问我：“置信区间和置信度你了解吗？”\n   根据准备在面试文档中的内容，我能够脱口而出：“在假设检验的过程中，我们往往采用样本数据特征来估计整体的数据特征。在中心极限定理里，我们知道从总体中进行N次样本抽取，N次样本的均值会围绕总体均值上下波动。因此，置信区间就是为总体的均值提供了一个可波动的范围，置信区间与置信度是相对应的。例如，在95%的置信度下，置信区间为【a,b】，也就是说，抽取100次样本，其中有95次样本的均值能够落在【a,b】范围内。”\n   可惜我做了充分的准备，并没有面试官问我这个问题（哭）\n   也有人问，面试中面试官会以什么形式来问假设检验的知识点呢？举一个栗子 ：\n   面试VIVO的时候面试官随口提问：“你会怎么证明中医的有效性？”\n   我当时的回答是：\n   “我会用假设检验来做证明。\n   第一步，提出两个命题。H0命题是中医无效；H1命题是中医有效。在这里，H0命题是我希望被推翻的命题，而H1命题是我希望被证实的命题。\n   第二步，随机选择两组生理特征、疾病状况一致的人。一组人不给予治疗；另一组人给予中药治疗，持续观测两拨人生理状况。\n   第三步，对两组人的生理数据进行独立样本t检验，观测统计结果P值。\n   第四步：设定显著性水平α&#x3D;0.05，如果统计结果P≤0.05，则推翻了H0假设，证明在该显著性水平下，中医是有效的。”\n  所以我们简化一下，回答假设检验相关题目的时候，遵循“提出命题-选择实验对象-检验-输出结论”的流程即可。只是有一点，建议多使用“第一第二第三”、“首先其次最后”这些次序词，用以展示相对流畅的思考逻辑。\n   不知道我讲清楚了没有……如果没有，建议结合《商务经济统计》再继续理解几遍，自我感觉以上内容应该可以应付绝大多数面试过程中的假设检验问题。\n   好了……不管了，我要强行进入第二个话题了……\n02 工作中的AB实验是如何开展的？\n   再举一个简单的栗子。过去在对首页产品进行排序时，往往是运营人员结合自己工作经验进行人工排序，现在算法小哥更新了产品排序的逻辑，希望通过AB实验证明自己的算法优于运营人工推荐，提高转化效果。\n   算法小哥和开发沟通好上线AB实验，用转化率(CR)来评估不同排序方式的效果，并设定显著性水平α&#x3D;0.05。在这场AB实验中，用到的两个假设分别是：\n   H0：运营的人工排序效果好（备受质疑、希望被推翻的命题）\n   H1：算法的推荐算法效果好（有待验证，希望被证实的命题）\n   在AB平台观察今天的实验效果，数据结果显示P&#x3D;0.003，可以理解成数据统计结果对H0的支持力度只有0.003，小于显著性水平0.05，这时候H1命题成立，相比运营的手工排序，算法工程师的推荐算法取得了更好的效果。\n   那在这个实验里，有什么要注意的点吗？\n  ——嗯，AB实验有很多需要注意的问题。\n （1）AB组是否真的只有一个变量\n   这场AB实验的变量是产品排序的逻辑，但大家都想开展AB实验，在首页上同期开展的AB实验有几十个，UI想测试筛选框的颜色、产品想测试标签的文案……。这种背景下，我们AB实验里被划分为A群体和B群体的用户往往同时参与了N多实验，不能绝对保证变量的唯一性。一般而言认为流量足够大，其AB实验和我们观测的AB实验没有直接交集，可以忽略其影响。\n（2）新策略是否真的上线了\n   因为研发每天都有很多AB实验，而且AB实验平台出错也是常有的事情。所以我们要在别人告诉我们AB实验上线了以后，自己验证实验策略是否真的上线了。\n（3）在实验前确定评估指标\n   我们的实验评估指标是CR转化率。这一点在实验上线前就要沟通好。\n（4）多观察几天数据\n   很多AB实验上线后前几天数据表现是不稳定的，最好持续观察半个月再给出结论。\n（5）存档AB测试的结果\n   对于数据分析师来说，每一个项目、每一个分析都需要做复盘和存档。比如AB实验项目，可以用一个标准化的模板来记录测试内容，为什么测试，测试对接人，测试效果等等，在年终的时候可以更好的汇报和复盘。\n   在大半年的工作中，终于有机会接触到诸多的AB实验，慢慢感知到各种AB实验原来殊途同归。但不可置否，它仍然是互联网产品迭代的利器，仍然是分析师证明自身价值的手段之一。想来这也是为什么诸多的面试官喜欢在面试中询问AB实验、假设检验的原因。\n作者：阿狸和小兔链接：https://www.jianshu.com/p/0b54dc8b0880来源：简书著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n","tags":["数据分析"]},{"title":"数据分析｜BI搭建","url":"/2023/03/08/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%EF%BD%9CBI%E6%90%AD%E5%BB%BA/","content":"BI搭建流程\n此阶段不可小觑，做好项目规划才能站在项目的高处掌控项目全局。在此阶段需要组建项目团队、确定项目目标以及项目里程碑。项目目标是项目的魂，后续工作都需要围绕目标展开，为工作指明方向，防止在项目执行过程中迷失。此阶段需要进行的工作内容是项目资料的交接与收集、组建项目团队以及组织项目启动会。\n1.方案阶段：方案设计\nBI项目都是由企业需求驱动的，项目方案也只有和企业的需求契合才能产生价值。所以在方案输出之前，要摸清楚需求、背景、客观条件、可投入资源等，最好要具体到业务、数据、技术等层面的需求，这关乎项目的落地和项目交付验收，同时也支撑BI项目工具选型。\n从启动阶段确认好项目何时开始后，便可以进入项目方案阶段，此阶段的目标为：调研相关需求内容及期望；收敛需求范围，统一交付目标；确认项目实施&amp;研发计划；确认项目解决方案。方案阶段主要是确认“做多少”以及“怎么做”，所以这一阶段主要的工作为：业务需求调研，项目需求说明书，原型设计、方案输出及确认。\n2.实施阶段：系统建设\n搭建一个合理的BI系统是BI项目成功的关键。在项目实施阶段，主要工作内容为监督项目成员按BI项目计划及解决方案内容，准时保质保量开发完成各项功能，并可以交付使用。BI项目实施可用三步曲进行概括。\n第一步：环境搭建。根据企业的实际使用人数、并发人数等指标，来确定正式环境服务器配置、带宽配置、是否需要集群部署以及数据库、中间件类型等，然后制定环境搭建方案。\n第二步：数仓建设。数仓建设是数据分析及应用的基础，我们可以采取从上至下的搭建方法，根据已经确定的BI分析主题构建合适的数仓模型，从而逐步整合企业的业务数据。此种搭建方式针对性强，目标明确，聚焦于所需的源数据整理，缩小数据整理的范围，有效地避免了资源浪费。\n第三步：BI开发。此阶段主要完成前端可视化的工作，可采取代码开发，也可以借助成熟的可视化工具进行开发。一般包含常规报表、可视化图表、分析报告、大屏展示、移动应用这几种展现形式。\n3.上线阶段：上线与验收\n到了上线阶段，可先在小范围试运行系统，从业务满足性方面检验BI系统试运行效果，重点是业务流程满足度和业务场景满足度。同时要做好用户操作培训和运维培训，保障BI系统后续独立使用。\n此阶段所要做的事归结起来就是一个词——“查漏补缺”，主要的工作内容有：核查并完成未完成事项、 用户操作培训、系统运维培训、交付文档整理、项目总结与验收。\n4.优化阶段：升级迭代\n一个好的BI项目要注重持续建设，不断完善与扩展。在实际使用中，通过用户的反馈不断的打磨和完善系统，让BI系统更加贴合实际使用场景。\n二、法 · 如何快速落地BI建设\n现在有很多企业不断尝试落地BI系统，那么如何高效地并有价值地建设BI系统呢？\n首先要选择一个合适的建设路径，有两种方法：一个是按KPI驱动，另外一个是按角色和场景搭建体系模型。\n1、从KPI管控出发，监控问题的角度，提炼KPI库\n每个企业的侧重KPI不一样，我们要结合各个主题，提炼适合客户的运营KPI。对它进行提炼、分析、预警，以及后续采取动作，并根据一些核心指标进行驱动和预警。通过KPI来驱动企业人员，调用企业所有人员一起共同建设BI平台，助力BI平台快速落地。\n2、以不同角色的视角、场景化搭建\n不同的角色关注的分析指标会不同，看指标的维度也会不同，比如高层领导对所负责的整体业务、运营情况要有宏观的掌控，需要满足其日常管理、经营分析、专项业务分析的需要。部门经理除了关注部门的核心绩效指标之外，还需要深入探究现象发生的原因，沿着数据的脉络去找寻问题，解决问题。所以我们需要结合不同角色视角，按照日常管理的场景合理化搭建BI平台，这样BI平台才能快速的落地。\n再者，我们还可以借鉴行业应用模板，快速导入复用。现在各行业更新换代特别快，产品周期短，可以借鉴一些成型的模板快速导入。\n除此之外，工具的灵活应用，也能很好加快平台建设，大大提高搭建效率，减少人力成本的投入。接下来小编来告诉大家如何挑选BI工具。\n三、器 · BI工具哪家强\n工欲善其事，必先利其器。BI工具是BI项目的核心，选对工具，BI项目就成功了一半。面对市场上鱼龙混杂的BI工具，不少企业眼花缭乱，无从下手。如果将需求和产品功能进行匹配和梳理，总结下来，无非四大方面：\n\nBI不断地迭代，亿信华辰就有这样一款功能全面而又可靠的工具。深耕大数据领域15年，连续多年荣登商务智能应用榜首，在成千上万个项目中不断打磨产品和服务，形成从数据填报、ETL数据处理、数据建模到数据分析、数据可视化、移动应用等一整套企业级商业智能产品方案——亿信ABI，实现多维度的数据分析应用，让数据发挥价值，驱动业务运营。\n\n\n你可以把它当作数据处理工具，通过拖拽式的流程设计，实现数据的抽取、清洗、转换、装载与调度，面向业务分析构建数据仓库，实现数据融合，提升数据分析效率。\n你可以把它视作报表工具，因为它能接入各种ERP、OA、CRM等系统数据，不写代码不写SQL就能批量化做报表。\n你也可以把它当作可视化工具，因为它自带上百种可视化图表以及动态效果，拖拽即可生成，制作领导驾驶舱、大屏可视化不在话下，更是结合全景3D建模和数据分析引擎实现酷炫3D效果。\n你还可以把它看作数据分析工具，因为从数据采集、数据处理、数据应用全流程完整覆盖，一个工具搞定数据生命周期的各个环节，实现数据填报、处理、分析一体化。\n\n结语：BI项目的建设是一个不断的实践、循环迭代的过程。多年项目经验总结了八个字：明道、优法、利器、践行。当然，选择合适且强大的“利器”，可让你在工作中变得更加的从容，亿信ABI提供一站式数据分析服务，助你达成所愿。\n","tags":["数据分析"]},{"title":"数据分析|DAU下降分析","url":"/2023/03/08/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%EF%BD%9CDAU%E4%B8%8B%E9%99%8D%E5%88%86%E6%9E%90/","content":"产品日活(DAU)下降，该如何分析\n案例：例如网易新闻APP日活突然下降5%，需要尽快排查一下数据下跌的原因。\n\n分析框架和逻辑思维![image-20230308082432891](&#x2F;Users&#x2F;xiaoyu&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230308082432891.png)\n可以分为五个步骤。\n第一，结合以往经验及各种信息，对数据的异常作出假设。比如假期效应、热点事件、活动影响、政策影响和统计口径变化等。\n第二，确认数据的真实性。可以将时间轴拉长至3个月，做同比和环比，看是近期异常还是历史异常；还需要看与该指标关联的其他指标是否异常，并找关键人员比如产品和研发确认数据的真实性。\n第三，对数据从不同的维度进行拆分来验证假设。比如从新用户&#x2F;老用户、新版本&#x2F;老版本、登录渠道和入口等维度。\n第四，分析外部原因和内部原因。外部原因考虑政治、经济和社会因素，比如政策、竞品APP数据和社会事件影响；内部影响从产品、研发和运营入手，并注意统计口径是发生了变化，比如业务逻辑的改变和指标计算方式的变化。\n第五，需要将当前的结论文档化，并持续跟踪后期的数据是否再次异常。确认无误之后给相关人员发邮件输出影响范围和分析的结论等等。\n1. 对数据异常原因做出假设，利用数据验证影响DAU因素较多，对所有维度直接拆解耗时耗力。所以需要结合以往经验及各种信息，对数据异常的原因做出假设，然后对数据从不同维度拆分来验证假设。可能随着之前的假设的验证不断进行新的假设，直到定位原因。\n\n2. 确认数据真实性\n将时间轴拉长(3个月)，做同比和环比，看近期异常还是历史异常；\n查看与该指标关联的其他指标是否异常；\n找数据流相关产品和研发确实数据真实性。\n\n\n3. 常见拆分维度\n根据以上维度拆分之后，每项数据都需要和历史数据做对比，计算影响系数。\n影响系数&#x3D;(今日数据−昨日数据)&#x2F;(今日总量−昨日总量)\n影响系数越大，说明此处为主要原因所在。\n通过上述维度进行初步拆分，可以大致定位数据异常范围。\n4. 外部原因分析外部：外部原因分析可以根据PEST（政治、经济、社会、技术）模型进行分析。\n\n5. 内部原因分析通过初步分析定位范围之后，需要进行进一步的排查，一般从三个维度来分析：产品、技术、运营；可以和这几个人一起拉一个会讨论一下。同时应注意数据统计口径是否发生变化。\n\n6. 总结所以我们整个的分析流程大致为：\n先结合以往数据异常进行假设 —— 在一个假设得到验证之后 —— 从不同维度进行拆解，确定异常范围 —— 从产品、运营、技术侧逐一排查，最终找到原因。\n以上分析框架不仅局限于DAU波动，对于数据异常类问题即可根据以上模型进行分析。\n","tags":["数据分析"]},{"title":"数据分析｜DAU预测","url":"/2023/03/08/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%EF%BD%9CDAU%E9%A2%84%E6%B5%8B/","content":"日活会受到很多因素的影响，产品迭代，运营活动，推广的变化等等都会影响到日活。当然这些因素中，有的影响较小，有的暂时无法预估。因此在预测的过程中，我们可以将一些影响不大的因素，剔除出去，从而简化得到一个可计算的状态。（这个简化到可计算的过程中，其实就叫数学建模。）\n因此为了计算，我们首先构建日活的一个简单数学模型。\n建立日活的数学模型影响日活的因素中，最本质的其实是两个，一个是每日新增用户数，一个是新增用户的留存率。\n某一天的日活，我们可以看作是，当天的新增，加上前一天的新增的次日留存用户，再加上大前天的新增的二日留存用户……\n以此类推，我们可以认为日活是“当天的新增用户和此前每一天新增用户在当天的留存用户之和”，基于此，我们可以用一个很简单的公式表达日活。\n$DAU(n)&#x3D;A(n)+A(n-1)R(1)+A(n-2)R(2)+… …+A(1)R(n-1)$\n其中，DAU(n)为第n天的日活，A(n)为第n天的新增，R(n-1)为新增用户在第n-1天后的留存率。如果我们假设，每日用户的新增是一个固定的数值A，则公式可简写为：\n$DAU(n)&#x3D;A(1+R(1)+R(2)+… …+R(n-1))$\n上述公式可以看成是日活的一个简单的数学模型。从这个模型中，我们可以看出，新增A是一个较为确定的数值，另一部分：\n$1+R(1)+R(2)+… …+R(n-1)$\n留存之和的确定稍微有些麻烦。可以用下述的方法，预估留存。\n如何预估留存留存率是一个产品最为核心的指标了，下图是一个产品的留存率衰减曲线：\n\n（1-30日留存率衰减曲线）\n由图中，我们可以看出：留存率的衰减曲线，非常类似幂函数的曲线，其实，在业内绝大部分产品的留存衰减曲线，基本都是符合幂函数曲线。\n基于此，我们可以通过幂函数来近似拟合留存率的衰减曲线，也就可以顺利的预估出日活模型中需要的留存之和。\n一般在预估一个产品的留存之前，我们会有一些先验的数据基础，如果你的产品已经上线来一段时间，可以使用历史数据作为基础。如果产品还未上线，没有历史的数据，因为不同类型产品的留存和衰减速度都不太一样，因此可以用业内同类型的产品的大概留存数据作为拟合预测的参考。\n因此，留存曲线拟合基本会遇到两种情况：\n\n已经知道了若干天的留存，预估后续的留存？\n不知道具体每天的留存，只知道次留，周留，月留存等数据，预估每一天的留存。\n\n这两个情况本质上属于同一个问题，这里以第二种情况为例，简单说下如何操作。曲线拟合的方法有很多，这里我介绍一个最为简单的方式，就是利用excel来做一个简单的拟合计算，具体步骤如下：\nstep1假设我们知道了一个产品次日留存，7日留存，30留存如下：\n\n（某产品若干日留存）\nstep2在excel中按照对应留存天数，写出留存率，并画出散点图：\n\n（留存散点图）\nstep3在excel图表对上述散点添加趋势线，并在趋势线选项中，选择幂函数，并选择显示幂函数公式\n\n（基于散点拟合曲线）\n得到的幂函数为：\n$y&#x3D;0.4861*x^(-0.435)$，其中x为对应的天数，y为对应天数的留存率。\nstep4基于得到的幂函数公式，可以求的所有对应天数的留存率。\n计算得到预估的日活基于得到的幂函数，算出对应的留存率之后，就可以简单求和得到，带入日活公式中：\n$DAU(n)&#x3D;A(1+R(1)+R(2)+… …+R(n-1))$\n这样就可以通过预估的每日新增，得到在未来第n天日活所处的水平。\n总结&amp;后记以上通过简化日活模型，仅考虑新增和留存对于日活的影响（其它影响，也都是通过新增和留存间接对日活产生影响的），可以粗略的估算出未来一段时间的产品日活规模。\n进而通过日活的规模，再去估算一些潜在收益，以及运营成本等等数据。上述计算一定存在误差，并且不能满足所有的场景，但整体的思路可以作为参考，应该能搞解决大部分相关问题了。\n","tags":["数据分析"]},{"title":"数据分析｜Kaggle|房价预测","url":"/2023/02/28/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%EF%BD%9CHousePricing2/","content":"NotesProfileReport [1]import ydata_profiling as ppfimport pandas as pddf_train = pd.read_csv(&#x27;train.csv&#x27;)ppf.ProfileReport(df_train)\n\n👧🏻 ydata_profiling 和 pandas_profiling?\n👧🏻 ProfileReport() 运行卡顿？\n🤖 这可能与不同浏览器对于 Jupyter Notebook 的支持和性能优化有关。Jupyter Notebook 是一个基于 Web 的应用程序，它的性能和稳定性可能会受到不同浏览器的影响。\nSafari 浏览器在运行 Jupyter Notebook 时可能会更加流畅，这可能是因为 Safari 浏览器具有更好的 Web 技术支持和性能优化。同时，Safari 浏览器在 Mac OS X 系统中是默认的浏览器，可能与操作系统之间的兼容性更好。\n另一方面，Chrome 浏览器在运行 Jupyter Notebook 时可能会出现卡顿问题，这可能是因为 Chrome 浏览器具有更高的系统资源占用率，以及更多的插件和扩展功能，导致其在运行 Jupyter Notebook 时更容易出现性能问题。\n如果你在使用 Chrome 浏览器时遇到了性能问题，你可以尝试优化浏览器的设置或减少浏览器插件和扩展的使用，或者使用其他浏览器来运行 Jupyter Notebook，例如 Safari、Firefox 等等。同时，你也可以考虑在本地使用 Jupyter Notebook，而不是在浏览器中运行 Jupyter Notebook，这可以提供更好的性能和稳定性。\nEncoding\n数据预处理阶段，object类的特征会根据类别使用不同的编码方式处理（label encoding和One-hot encoding）\n\nLabel encodingOne-hot encodingReference[1] kaggle案例-Python实现房价预测-完整分析流程\n[2] [Kaggle竞赛丨房价预测（House Prices）][https://zhuanlan.zhihu.com/p/137076292]\n[3] \n","categories":["刷题笔记"],"tags":["Python","kaggle","data prediction"]},{"title":"数据分析｜Data Science R Basic","url":"/2023/02/09/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%EF%BD%9CData-Science-R-Basic/","content":"Words &amp; Expressions\nin a nested way 嵌套\n\nconcatenate 连接 c() -&gt; all items in ‘()’ to a vector\n\n\nWhy use ‘[[’ instead of ‘[’ to access variables?We extract the population like this:\np &lt;- murders$population\n\nIf you instead try to access a column with just one bracket,\nmurders[&quot;population&quot;]\n\nR returns a subset of the original data frame containing just this column. This new object will be of class data.frame rather than a vector. To access the column itself you need to use either the $ accessor or the double square brackets [[:\nmurders[[&quot;population&quot;]]\n\n\n\nR- sorting functions\nsort()\n# sort()排序，排序结果不可逆转# 默认是升序# decreasing为TRUE，表示降序# decreasing为FALSE，表示升序#排序后并不会修改原对象的值#示例如下：&gt; a &lt;- c(3,9,16,6,7,4,22,5,10,13)&gt; #sort()默认为从小到大（升序）排序，等同于decreasing=FALSE&gt; sort(a) [1]  3  4  5  6  7  9 10 13 16 22&gt; sort(a,decreasing = F) [1]  3  4  5  6  7  9 10 13 16 22&gt; #decreasing=TRUE,为从大到小（降序）排序&gt; sort(a,decreasing = T) [1] 22 16 13 10  9  7  6  5  4  3#排序并不会修改原对象的值，a仍为原来未排序的a&gt; a [1]  3  9 16  6  7  4 22  5 10 13\n\n\n\nrank()\n用法：rank(a)函数说明：指出当前向量中各元素大小的排名，默认升序函数还有其他的参数：rank(x &#x3D; data, na.last &#x3D; TRUE)x 表示待排序的向量na.last 表示是否排序时是否将NA放在最后面，默认忽略NA\n&gt; a &lt;- c(3,9,16,6,7,4,22,5,10,13)&gt; order(a) [1]  1  6  8  4  5  2  9 10  3  7#说明：在向量a中，3是第一小的数，位置下标为1；4是第二小的数，位置下标为6；最大的数是22，位置下标为7#a[order(a)] 等同于sort(a)&gt; a[order(a)]  [1]  3  4  5  6  7  9 10 13 16 22\n\n\n\norder()\n说明：返回的值表示位置，默认是升序，依次对应的是向量的最小值、次小值、第三小值…最大值\n用法：order(a), a为要排序的向量order(… &#x3D; data, na.last &#x3D; TRUE,decreasing &#x3D; TRUE)… 表示待排序向量na.last 表示时候将NA值放在最后面（默认排序忽略NA）decreasing 表示是否按照降序排序，默认升序。\n&gt; a [1]  3  9 16  6  7  4 22  5 10 13&gt; sort(a) [1]  3  4  5  6  7  9 10 13 16 22&gt; rank(a) [1]  1  6  9  4  5  2 10  3  7  8 #说明：向量a中的第一个数为3，是最小的，故排名为1；第二个数是9，是第六小的数，排名为6\n\n\n\n比较\n&gt; a &lt;- c(3,9,16,6,7,4,22,5,10,13)&gt; a [1]  3  9 16  6  7  4 22  5 10 13&gt; sort(a) #将a**从小到大排序并列出** [1]  3  4  5  6  7  9 10 13 16 22&gt; order(a) #返回从小到大的数的**位置下标**，a[order(a)]=sort(a) [1]  1  6  8  4  5  2  9 10  3  7&gt; rank(a) #返回a中**每个数的排名（从小到大）** [1]  1  6  9  4  5  2 10  3  7  8&gt; a [1]  3  9 16  6  7  4 22  5 10 13#注意：经过sort()、order()、rank()排序后，a不改变\n\norder和rank的区别在于一个返回的是index，一个是rank，index不一定是数字。\n\n\n","categories":["刷题笔记"],"tags":["R"]},{"title":"数据分析｜Kaggle|House Pricing|Comprehensive data exploration with python","url":"/2023/02/23/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%EF%BD%9CHousePricing/","content":"\nFrom kaggle: Comprehensive data exploration with python\n\nNotes偏度(skewness)和峰度(kurtosis）\nskewness 衡量数据分布的非对称程度\n正态分布 skewness &#x3D; 0\n右偏分布 skewness &gt; 0\n左偏分布 skewness &lt; 0\n\n\n\n\n\n\nkurtosis 表示概率密度曲线的峰值高低（峰的尖度）\n\n正态分布（&#x3D; 3）\n厚尾（&gt; 3）最低\n瘦尾（&lt; 3）最尖\n\n\n\n\nheaptmap怎么看相关性中间对角线永远是最相关的\n标准化from sklearn.preprocessing import StandardScaler\n🤖️ 当进行单个变量的标准化处理时，我们通常需要将其转换为一个二维数组。这是因为，对于单个变量来说，它只有一个维度，而进行标准化处理时需要在某个轴上进行运算，因此需要将其转换为一个具有多个维度的数组，以便进行运算。\n可以使用 print() 函数输出 area_2d 的值，例如:\nimport numpy as np# create a 1D numpy array with 5 valuesarea = np.array([1000, 1500, 1200, 1800, 2000])# reshape the 1D array to a 2D array with 5 rows and 1 columnarea_2d = area.reshape(-1, 1)print(area_2d)\n\n输出结果应该是：\n[[1000] [1500] [1200] [1800] [2000]]\n\n可以看到，这个二维数组包含5行1列，每一行代表一个样本，每一列代表一个特征（在这个例子中，只有一个特征）。\n如何解释probplot的结果红色线条表示正态分布，蓝色线条表示样本数据，蓝色越接近红色参考线，说明越符合预期分布（正态分布）。这个图通常与sns.distplot直方图与连续概率密度估计图一起使用。![image-20230224124152190](&#x2F;Users&#x2F;xiaoyu&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230224124152190.png)\n禁止日志信息from matplotlib.axes._axes import _log as matplotlib_axes_loggermatplotlib_axes_logger.setLevel(&#x27;ERROR&#x27;)\n\n这段代码的作用是禁止 matplotlib 输出一些不必要的日志信息，这些信息可能会干扰我们的结果。在这段代码中，我们将 matplotlib.axes._axes 模块的日志级别设置为 ERROR，这样 matplotlib 就不会输出该模块的日志信息了。具体来说，该代码会禁止 matplotlib 输出一些与对数轴有关的警告信息，这些信息通常在我们对数据进行可视化时出现。\n图像输出前空白from matplotlib.axes._axes import _log as matplotlib_axes_loggermatplotlib_axes_logger.setLevel(&#x27;ERROR&#x27;)var = &#x27;GrLivArea&#x27;data = pd.concat([df_train[&#x27;SalePrice&#x27;], df_train[var]], axis = 1)data.plot.scatter(x = var, y = &#x27;SalePrice&#x27;, ylim = (0,800000))\n\n👧🏻 为什么我运行完这一段代码之后在图像输出之前会有一大段空白，并且显示&lt;AxesSubplot:xlabel=&#39;GrLivArea&#39;\tylabel=&#39;SalePrice&#39;&gt; No results.呢？\n🤖️ 这段代码的输出包括两个部分：第一部分是图像，第二部分是输出的对象类型和空结果。输出对象类型的信息是因为 data.plot.scatter() 函数返回了一个 AxesSubplot 对象，而空结果是因为在代码的最后没有加上 plt.show() 函数。\n因此，你可以将代码修改为如下形式来避免输出空结果：\nfrom matplotlib.axes._axes import _log as matplotlib_axes_loggermatplotlib_axes_logger.setLevel(&#x27;ERROR&#x27;)var = &#x27;GrLivArea&#x27;data = pd.concat([df_train[&#x27;SalePrice&#x27;], df_train[var]], axis = 1)ax = data.plot.scatter(x=var, y=&#x27;SalePrice&#x27;, ylim=(0, 800000))plt.show()\n\n在这里，我们使用了 plt.show() 函数来显示图像，并且将 data.plot.scatter() 的输出赋值给了一个变量 ax，以便我们可以对图像进行更多的操作。\ncorrcoef() + 转置cm = np.corrcoef(df_train[cols].values.T)\n🤖️ 在Numpy中，corrcoef函数用于计算两个或多个变量之间的相关系数矩阵，该矩阵中的每个元素代表两个变量之间的相关性。如果有两个变量，那么corrcoef返回一个2x2的矩阵，其中第(i,j)个元素为第i个变量和第j个变量之间的相关系数。如果有多个变量，则返回一个n×n的矩阵，其中n为变量的个数。corrcoef函数的参数是需要计算相关系数的变量矩阵或数组，这些变量可以存储在Numpy数组或者Pandas的DataFrame或Series中。其中，参数rowvar默认为True，表示对每一行进行变量之间的相关性计算，参数bias默认为False，表示无偏估计。\n示例代码：\nimport numpy as npx = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])corr_matrix = np.corrcoef(x)print(corr_matrix)\n\n输出结果为：\n[[1. 1. 1.] [1. 1. 1.] [1. 1. 1.]]\n\n上述代码中，x是一个3x3的矩阵，表示三个变量之间的相关系数矩阵。corr_matrix为corrcoef函数计算出的相关系数矩阵，由于每个变量与自身的相关性系数都为1，因此返回的结果为一个由1组成的矩阵。\n🤖️ df_train[cols]表示在DataFrame对象df_train中挑选出相关性最高的10个变量对应的列，其中cols是一个包含这些列名的列表。values将这些列转换为一个二维数组，其每一行代表一个样本，每一列代表一个变量。.T表示对这个二维数组进行转置，即将行与列交换，变成每一行代表一个变量，每一列代表一个样本的形式。这样的结果是一个10行n列的二维数组，其中n是训练数据集中的样本数。\n例如，如果有以下数据集：\n#scatterplotsns.set()cols = [&#x27;SalePrice&#x27;, &#x27;OverallQual&#x27;, &#x27;GrLivArea&#x27;, &#x27;GarageCars&#x27;, &#x27;TotalBsmtSF&#x27;, &#x27;FullBath&#x27;, &#x27;YearBuilt&#x27;]sns.pairplot(df_train[cols], size = 2.5)plt.show();\n\n如果选择相关性最高的3个变量’A’, ‘B’, ‘C’，则df_train[cols]将返回一个包含3个列的DataFrame对象，即：\n    A   B   C0   1   4   71   2   5   82   3   6   9\n\n通过.values转换成Numpy数组，即为：\narray([[1, 4, 7],       [2, 5, 8],       [3, 6, 9]])\n\n在此基础上进行.T操作，将得到一个3行的二维数组，即：\narray([[1, 2, 3],       [4, 5, 6],       [7, 8, 9]])\n\n这个二维数组包含了3个变量的取值，每一行代表一个变量，每一列代表一个样本。这个数组可用于计算相关系数矩阵。\n❗️ 🤖️不转置也可以生成相关系数矩阵和相关性热图，但是在数据集较大的情况下，由于相关系数矩阵是一个方阵，如果样本数很多，则相关系数矩阵的大小将非常大，计算量也会变得很大，因此运行速度会变慢。\n&#x3D;&#x3D;而转置操作可以将变量数作为矩阵的行数，这样就避免了矩阵非常大的问题，提高了计算效率，所以在处理大型数据集时，进行转置操作是一种有效的优化方式，可以加快计算速度。同时，转置后的热图可以更直观地展示变量之间的相关性，更便于观察和分析。&#x3D;&#x3D;\nheaatmap 绘制#correlation matrixcorrmat = df_train.corr()f, ax = plt.subplots(figsize=(12, 9))sns.heatmap(corrmat, vmax=.8, square=True);\n\n👧🏻 f和ax代表什么？\n🤖️ 在代码 f, ax = plt.subplots(figsize=(12, 9)) 中，f 和 ax 是两个变量名，分别表示图形画布和图形轴对象。\n具体来说，plt.subplots() 函数返回了一个包含画布和轴对象的元组 (fig, ax)，其中 fig 表示整个图形画布对象，而 ax 表示坐标轴对象。这个元组可以通过 Python 的解构赋值语法来拆分成单独的变量。\n在这段代码中，通过设置 figsize=(12, 9) 参数，指定画布大小为 12x9，然后将返回的元组分配给变量 f 和 ax，以便在后续代码中使用它们来绘制热力图。\n👧🏻 vmax &#x3D; .8是什么意思？\n🤖️ vmax = .8 是指在绘制热力图时，将数据映射到颜色图谱的最大值为 0.8。具体来说，这个参数用于设置热力图中颜色的亮度范围，最大值为 0.8 表示数据中最大值对应的颜色在颜色图谱中的亮度为 0.8，而其他值对应的颜色亮度将根据数据的分布情况自动调整。\n通过设置 vmax 参数，可以在热力图中强调数据中的极端值和重要特征。如果不设置这个参数，颜色图谱的最大值将自动匹配数据中的最大值，这可能会导致颜色映射范围太大或太小，影响热力图的可读性。\n删除原来dataframe中的某些行（2种方式）🤖️ 这种情况下直接drop，必须写inplace = True才会修改原数据框：\ntop_2_index = df_train.sort_values(by=&#x27;GrLivArea&#x27;, ascending=False)[:2].indexdf_train.drop(top_2_index, inplace=True)\n\n🤖 也可以不使用 inplace=True 参数来修改 df_train，而是将 drop() 函数的返回值赋给一个新的 DataFrame：\ndf_train = df_train.drop(df_train[df_train[&#x27;Id&#x27;] == 1299].index)\n\n这样，将删除 Id 为 1299 的行之后的 DataFrame 赋值给了 df_train。需要注意的是，这种方法会返回一个修改后的副本，而不会直接修改原始 DataFrame。\n👧🏻 修改后的副本和原来的dataframe不是都叫df_train吗？这样跟直接修改原来的dataframe有什么区别呢？\n🤖️ 确实，修改后的副本和原始的 DataFrame 都叫做 df_train，它们的名称是一样的，但它们的内存地址不同，它们是两个不同的对象。当你执行 df_train = df_train.drop(df_train[df_train[&#39;Id&#39;] == 1299].index) 时，drop() 函数返回一个新的 DataFrame 对象，然后将这个新的对象赋值给原始的 df_train，因此这个语句会改变原始的 df_train。而如果你在 drop() 函数中使用 inplace=True 参数，就会直接修改原始的 DataFrame，不会返回新的对象。这两种方法的最终效果是一样的，但是修改副本和直接修改原始 DataFrame 的方式可能对代码的可读性和维护性有一定的影响。\n🤖 如果使用了赋值操作符 “&#x3D;”，将原始数据框赋值给副本，那么它们的变量名会相同，很容易让人混淆。为了避免混淆，可以在变量名上添加后缀或前缀以示区别，例如在副本的变量名中加入”_copy”或”_modified”等后缀。在实际应用中，需要根据具体情况决定如何命名变量以便更好地区分它们。\n四种assumptions最终得出结果要看因变量是否符合多变量分析中的假设。\n\nNormality 正态分布：用 histogram + normal probability plot\nRemember that &#x3D;&#x3D;univariate normality doesn’t ensure multivariate normality&#x3D;&#x3D;.\nIn big samples (&gt;200 observations) normality is not such an issue. However, if we solve normality, we avoid a lot of other problems (e.g. heteroscedacity) so that’s the main reason why we are doing this analysis.\n异质性就是说研究的样本的重要属性上存在差异，比如人和人之间的消费习惯可能大相径庭，这样你记录1000个人10年的月消费数据，即便他们收入流和资产完全相同，消费流也可能截然不同。在统计性质上，这种不同表现为异方差。所以在计量模型上，横截面数据和面板数据经常出现，也可以说总会存在异质性问题。\n\n\n\n\nHomoscedasticity 同方差性：用 graphically\nHomoscedasticity refers to the ‘assumption that dependent variable(s) exhibit equal levels of variance across the range of predictor variable(s)’ (Hair et al., 2013). \nHomoscedasticity is desirable because we want the error term to be the same across all values of the independent variables.\n\n\nLinearity 线性\nThe most common way to assess linearity is to &#x3D;&#x3D;examine scatter plots and search for linear patterns&#x3D;&#x3D;. If patterns are not linear, it would be worthwhile to explore data transformations.\n\n\nAbsence of correlated errors 无相关错误\nCorrelated errors, like the definition suggests, happen when one error is correlated to another. For instance, if one positive error makes a negative error systematically, it means that there’s a relationship between these variables. This occurs often in time series, where some patterns are &#x3D;&#x3D;time related&#x3D;&#x3D;. We’ll also not get into this. \nHowever, &#x3D;&#x3D;if you detect something, try to add a variable that can explain the effect you’re getting&#x3D;&#x3D;. That’s the most common solution for correlated errors.\n\n\n\npyplot和matplotlib的关系🤖 pyplot 是 Matplotlib 库中的一个模块，用于创建图形和图表。在 Matplotlib 中，&#x3D;&#x3D;pyplot 模块被用作绘图工具的接口&#x3D;&#x3D;，提供了一些方便的函数和方法来创建和操作图形、轴、图例和注释等元素。\nMatplotlib 是一个数据可视化库，提供了各种各样的绘图函数和工具，可以用于创建折线图、散点图、柱状图、饼图等各种类型的图表。而 pyplot 模块则是 Matplotlib 中最常用的绘图工具之一，它提供了很多方便的函数和方法，使得绘制各种类型的图表变得更加简单易用。因此，pyplot 可以被认为是 Matplotlib 库中最主要的一个模块。\n同方差性(Homoskedasticity)和异方差性(Heteroskedasticity)👦 写一个通俗的解释：比如说 $income&#x3D;b*education+e$ 这个计量模型,描述了教育水平与收入的关系，e为残差，OLS等传统计量框架要求残差e不与任何变量相关,即: $E(e|x)&#x3D;0$。\n一种常见的残差e与x相关的方式是: 残差e的方差与变量x相关，这时候，残差e的方差会随着x变动而变动，因此方差是异质性的. 这被称为异方差问题。\n异方差问题会导致什么?\n拿上边那个教育-工资的例子来看，一般来说，受教育水平越高的人群收入变动越大，而教育水平较低的人群收入相差不会太大 (比如说，有最低工资法)，这时就出现异方差问题了, 因为e的方差会随着教育水平x的增大而增大。\n\n异方差存在的时候,大多数情况下,OLS估计出的方差会比实际的方差要小(当然, 小部分情况下估计值会比实际的大)，&#x3D;&#x3D;因此会过高地估计系数b的显著性&#x3D;&#x3D; (因为, 系数的t值&#x3D;系数&#x2F;标准差)，**&#x3D;&#x3D;而不会影响系数估计值的大小&#x3D;&#x3D;**(考虑异方差影响系数大小的问题是近几年的焦点和难点，略过不提)。\n👨 同方差性是我们对OLS回归残差的一个要求，即 &#x3D;&#x3D;$\\epsilon \\sim N(0, \\sigma^2)$&#x3D;&#x3D; 。简单的说就是残差必须是随机的，这个分布是我们用来描述随机分布的一种方法 – 均值为0，方差为sigma方。\n异方差则说明残差不满足这个正态分布。\n概括而言，同方差说明回归的残差项是随机的，异方差说明残差项不随机，你的回归设置或者变量的选取有问题，需要修正。\nget_dummies()#convert categorical variable into dummydf_train = pd.get_dummies(df_train)\n\n🤖 这段代码使用了get_dummies()函数将数据框中的分类变量转换成了虚拟变量（dummy variable）。\n虚拟变量是指将一个分类变量拆分成多个二元变量的过程。例如，如果有一个名为color的分类变量，其中包括红色、蓝色和绿色三个类别，那么将color转换成虚拟变量的过程就是创建三个新的二元变量，分别代表红色、蓝色和绿色，如果样本属于红色类别，则对应的红色虚拟变量值为1，其余两个虚拟变量的值为0，以此类推。\nget_dummies()函数会自动识别出所有的分类变量，并将它们转换成虚拟变量。它还有一些其他的参数，例如drop_first可以指定是否要删除每个变量的第一个虚拟变量，以避免多重共线性问题。\nProcedure“理解问题 -&gt; 单变量分析 -&gt; 多变量分析 -&gt; 数据清洗 -&gt; 验证假设”\n1⃣️ Understand the problem. We’ll look at each variable and do a philosophical analysis about their meaning and importance for this problem.\n\n观察 columns\n\n2⃣️ Univariable study. We’ll just focus on the dependent variable (‘SalePrice’) and try to know a little bit more about it.\n\n使用 describe\n使用直方图\n分析偏度和峰度\n使用散点图和箱图观察目标变量和其他变量之间的关系\n\n3⃣️ Multivariate study. We’ll try to understand how the dependent variable and independent variables relate.\n\n热图看所有变量之间的关系\n热图看跟目标变量最相关的变量之间的关系\nscatterplot 看目标变量及最相关的变量之间的关系\n\n4⃣️ Basic cleaning. We’ll clean the dataset and handle the missing data, outliers and categorical variables.\n\n缺失值\n\n看所有的变量中缺失值占比\n\n剔除缺失变量：对因变量不重要的可以直接剔除整个变量；有替代变量的可以直接剔除整个变量；不剔除整个变量的可以仅将包含缺失值的单个样本剔除\n\n检查无缺失值\n\n\n\n离群值\n\n[数据标准化][4]，设置一个阈值来判断离群值，输出过高&#x2F;过低的离群值\n使用散点图观察某个自变量和因变量的关系，有了上一步得到的离群值，我们可以在散点图中一眼看出离群值在哪\n保留遵循趋势的离群值，删除违背趋势的离群值\n\n\n\n5⃣️ Test assumptions. We’ll check if our data meets the assumptions required by most multivariate techniques.\n\n正态分布\n看histogram：偏度和峰度\n看常态机率图：数据分布应紧跟代表正态分布的对角线\n\n\n异方差性\n散点图可视化，一头紧凑一头分散，或中间紧凑两头分散，或中间分散两头紧凑\n\n\n虚拟化变量\n\nStep1: Understand our data#check the decorationdf_train.columns\n\n\n Look as each variable and try to understand their meaning and relvance to this problem. Although it’s time-comsuming, it gives us the flavour of our dataset.\n\n\nWe should focus 5 aspects. Create an Excel spreadsheet with following columns:\n\nVariable\nType -&gt; ‘numerical’ or ‘categorical’\nSegment -&gt; Define the segments of all variables then identify them. (eg. building&#x2F; space &#x2F;location)\nExpectation -&gt; the variable infulence on the dependent variable. (high&#x2F; medium&#x2F; low)\nConclusion -&gt; the importance of the variable \nComments -&gt; any general comments that occured to us\n\n\nExpectation will give us ‘sixth sense’. In order to fill it, we should read the description of all the variables one by one, ask ourselves:\n\nDo we care this variable when we are buying a house?\nHow important would this variable is?\nIs this information already decribed in any other variable?\n\n\nFocus the variables with ‘high’ expectation. Generate some scatter plots between those variables and the dependant variable(SalePrice), filling the conclusion column which is the correction of our expectations.\n\nYou may give up some of your expecting variables after vasualizing them.\n\n\n\nStep2: Univariable analysis: ‘SalePrice’\ndescribe()\nhistogram- normal distribution? (positive) skewness? peakedness?\n[skewness and kurtosis][1]\n\n#data#descriptive statistics summarydf_train[&#x27;SalePrice&#x27;].describe()#graph#histogramsns.distplot(df_train[&#x27;SalePrice&#x27;]);#data#skewness and kurtosisprint(&quot;Skewness: %f&quot; % df_train[&#x27;SalePrice&#x27;].skew())print(&quot;Kurtosis: %f&quot; % df_train[&#x27;SalePrice&#x27;].kurt())\n\nRelationship with numerical variables\nscatter plots - if there is a linear (exponential) reaction\n\n#graph#scatter plot grlivarea/salepricevar = &#x27;GrLivArea&#x27;data = pd.concat([df_train[&#x27;SalePrice&#x27;], df_train[var]], axis=1)data.plot.scatter(x=var, y=&#x27;SalePrice&#x27;, ylim=(0,800000));#scatter plot totalbsmtsf/salepricevar = &#x27;TotalBsmtSF&#x27;data = pd.concat([df_train[&#x27;SalePrice&#x27;], df_train[var]], axis=1)data.plot.scatter(x=var, y=&#x27;SalePrice&#x27;, ylim=(0,800000));\n\nRelationship with categorical fratures\nbox plots\n\n#box plot overallqual/salepricevar = &#x27;OverallQual&#x27;data = pd.concat([df_train[&#x27;SalePrice&#x27;], df_train[var]], axis=1)f, ax = plt.subplots(figsize=(8, 6))fig = sns.boxplot(x=var, y=&quot;SalePrice&quot;, data=data)fig.axis(ymin=0, ymax=800000);var = &#x27;YearBuilt&#x27;data = pd.concat([df_train[&#x27;SalePrice&#x27;], df_train[var]], axis=1)f, ax = plt.subplots(figsize=(16, 8))fig = sns.boxplot(x=var, y=&quot;SalePrice&quot;, data=data)fig.axis(ymin=0, ymax=800000);plt.xticks(rotation=90);\n\n🤖️ 这段代码使用了Python中的Pandas和Seaborn库，用于绘制房价数据集中整体质量（OverallQual）与房价（SalePrice）之间的箱型图。具体解释如下：\n\nvar = &#39;OverallQual&#39;：将变量名OverallQual赋值给变量var，表示要绘制的x轴变量是整体质量。\ndata = pd.concat([df_train[&#39;SalePrice&#39;], df_train[var]], axis=1)：将训练数据集df_train中的SalePrice和OverallQual列拼接在一起，并存储在名为data的变量中。这里使用了Pandas库中的concat函数。\nf, ax = plt.subplots(figsize=(8, 6))：创建一个8x6英寸大小的绘图对象，并将其存储在名为f的变量中，将其轴对象存储在名为ax的变量中。这里使用了Matplotlib库。\nfig = sns.boxplot(x=var, y=&quot;SalePrice&quot;, data=data)：使用Seaborn库中的boxplot函数绘制箱型图，x轴为OverallQual，y轴为SalePrice，数据来源为data。将绘制结果存储在名为fig的变量中。\nfig.axis(ymin=0, ymax=800000)：将y轴的范围设定为0到800000，使得箱型图的纵坐标范围更加合适。这里使用了Matplotlib库中的axis函数。\n\nStep3: Multivariable analysis\n[heatmap][2] style - from a universla perspective\n\n#correlation matrixcorrmat = df_train.corr()f, ax = plt.subplots(figsize=(12, 9))sns.heatmap(corrmat, vmax=.8, square=True);\n\n🤖️ 这段代码用于绘制数据集中的相关性矩阵的热力图。以下是每一行的解释：\n\ncorrmat = df_train.corr(): 计算数据集 df_train 中所有数值型变量之间的相关性矩阵，其中 corr() 是 pandas 库中计算相关系数的函数。\nf, ax = plt.subplots(figsize=(12, 9)): 创建一个大小为 12x9 的图形画布，并将其保存在变量 f 和 ax 中，用于绘制相关性矩阵的热力图。这里用到了 matplotlib 库中的 subplots() 函数。\nsns.heatmap(corrmat, vmax=.8, square=True): 使用 seaborn 库中的 heatmap() 函数将相关性矩阵绘制成热力图，其中 corrmat 是相关性矩阵的数据，vmax 是热力图中颜色的最大值，square 参数用于指定热力图的形状是否为正方形。\n\n通过绘制相关性矩阵的热力图，可以更直观地了解数据集中各个变量之间的相关性，以便进行数据分析和建模。\n&#x3D;&#x3D;❗️Notice if some of the independent variables have a similar color distribution in the heat map! This proves that they play a similar role in the overall model, and perhaps it is possible to keep only the one variable with the least missing values in the cleaning.&#x3D;&#x3D;\n#saleprice correlation matrixk = 10 #number of variables for heatmapcols = corrmat.nlargest(k, &#x27;SalePrice&#x27;)[&#x27;SalePrice&#x27;].indexcm = np.corrcoef(df_train[cols].values.T)sns.set(font_scale=1.25)hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt=&#x27;.2f&#x27;, annot_kws=&#123;&#x27;size&#x27;: 10&#125;, yticklabels=cols.values, xticklabels=cols.values)plt.show()\n\n🤖️ 这段代码使用了Python中的Numpy、Pandas和Seaborn库，用于绘制房价数据集中各变量之间的相关系数热图。具体解释如下：\n\nk = 10：将热图中展示的相关系数最高的10个变量挑选出来。\ncols = corrmat.nlargest(k, &#39;SalePrice&#39;)[&#39;SalePrice&#39;].index：从相关系数矩阵corrmat中选择SalePrice列与其他列的相关系数最高的10个变量，将其索引存储在cols变量中。\ncm = np.corrcoef(df_train[cols].values.T)：从训练数据集df_train中挑选出相关系数最高的10个变量，计算其相关系数矩阵，并将其存储在cm变量中。这里使用了Numpy库中的[corrcoef函数][3]。\nsns.set(font_scale=1.25)：设置Seaborn库中的字体大小。\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt=&#39;.2f&#39;, annot_kws=&#123;&#39;size&#39;: 10&#125;, yticklabels=cols.values, xticklabels=cols.values)：绘制热图。其中，参数cm是一个相关系数矩阵，参数cbar表示是否显示颜色条，参数annot表示是否显示每个格子中的数值，参数square表示是否将每个格子设置为正方形，参数fmt表示显示数值时保留两位小数，参数annot_kws表示注释的参数，这里设置字体大小为10，yticklabels和xticklabels表示行和列的标签名，这里都为cols.values。将绘制结果存储在名为hm的变量中。\nplt.show()：显示绘制出的热图。这里使用了Matplotlib库中的show函数。\n\nsns.set()cols = corrmat.nlargest(k, &#x27;SalePrice&#x27;)[&#x27;SalePrice&#x27;].index.tolist()sns.pairplot(df_train[cols], height = 2.5)plt.show()\n\n\n\nStep4: Missing dataMissing data#missing datatotal = df_train.isnull().sum().sort_values(ascending=False)percent = (df_train.isnull().sum()/df_train.isnull().count()).sort_values(ascending=False)missing_data = pd.concat([total, percent], axis=1, keys=[&#x27;Total&#x27;, &#x27;Percent&#x27;])missing_data.head(20)\n\n🤖️\n\ndf_train.isnull()：判断数据集 df_train 中每个元素是否为缺失值，返回一个与 df_train 大小相同的布尔矩阵，内容是True&#x2F;False。\ndf_train.isnull().sum()：将布尔矩阵中每列（变量）中的缺失值数量相加，得到每列缺失值的总数。\ndf_train.isnull().count()：将布尔矩阵中每列（变量）中的元素（无论是否缺失）数量相加，得到每列元素的总数。\n\n#dealing with missing datadf_train = df_train.drop((missing_data[missing_data[&#x27;Total&#x27;] &gt; 1]).index, axis = 1)df_train = df_train.drop(df_train.loc[df_train[&#x27;Electrical&#x27;].isnull()].index)df_train.isnull().sum().max() #just checking that there&#x27;s no missing data missing...\n\nOutliers#standardizing datafrom sklearn.preprocessing import StandardScalersaleprice_scaled = StandardScaler().fit_transform(np.array(df_train[&#x27;SalePrice&#x27;])[:, np.newaxis]);low_range = saleprice_scaled[saleprice_scaled[:, 0].argsort()][:10]high_range = saleprice_scaled[saleprice_scaled[:, 0].argsort()][-10:]print(&#x27;outer range (low) of the distrubution:&#x27;)print(low_range)print(&#x27;\\n outer range (high) of the distribution:&#x27;)print(high_range)\n\n\n\nStep5: Getting hard coreNormality: histogram + normal probability plot#histogram and normal probability plotfrom scipy.stats import normsns.distplot(df_train[&#x27;SalePrice&#x27;], kde = True,fit = norm);fig = plt.figure()res = stats.probplot(df_train[&#x27;SalePrice&#x27;], plot = plt)\n\n\n 🤖️ histplot不支持直接显示拟合的正态分布曲线。如果要同时显示正态分布曲线，可以使用displot。\n\n&#x3D;&#x3D;In case of positive skewness, log transformations usually works well.&#x3D;&#x3D;\ndef dist_probplot(x):    sns.distplot(df_train[x], fit = norm)    fig = plt.figure()    res = stats.probplot(df_train[x], plot = plt)\n\n\n#applying log transformationdf_train[&#x27;SalePrice&#x27;] = np.log(df_train[&#x27;SalePrice&#x27;])dist_probplot(&#x27;SalePrice&#x27;)\n\n\ndist_probplot(&#x27;TotalBsmtSF&#x27;)\n\n\n\nOk, now we are dealing with the big boss. What do we have here?\n\nSomething that, in general, presents skewness.\nA significant number of observations with value zero (houses without basement).\nA big problem because the value zero doesn’t allow us to do log transformations.\n\n\n处理方法：将非零值做对数转换，零值还是零，但是若执行：\n![image-20230228093921098](&#x2F;Users&#x2F;xiaoyu&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230228093921098.png)\n会出现以上报错。\n🤖️ 出现RuntimeWarning: divide by zero encountered in log的原因是在对数变换时遇到了 0，因为 log(0) 是没有定义的，所以会产生警告。可以将值为 0 的观测在变换前用一个极小的数代替，比如可以用 1e-6 代替 0。\n👧🏻 但是这段代码不是说只有不等于0时才会进行对数变换吗？为什么还会遇到log(0)的情况呢？\n🤖️ 这是由于浮点数的精度问题导致的。可能有一些值在处理之后非常接近0，但实际上并不等于0，因此在进行np.log()函数计算时，会返回一个非常大的负无穷值，比如-log(1e-15)&#x3D;-34.538776394910684。这也就是报错中提到的“divide by zero encountered in log”错误，其实并非是真正意义上的除零操作，而是一个数学上的约定。\n🤖️ 为了解决这个问题，一种常见的方法是在对数变换前，先对数据中的所有非零值加上一个极小的常数，比如1e-8，避免出现log(0)的情况，同时由于这个常数值非常小，对整体数据的统计特征影响也非常小。因此可以将代码修改为：\nepsilon = 1e-8  # 定义一个极小值df_train.loc[df_train[&#x27;TotalBsmtSF&#x27;] &gt; 0, &#x27;TotalBsmtSF&#x27;] = np.log(df_train.loc[df_train[&#x27;TotalBsmtSF&#x27;] &gt; 0, &#x27;TotalBsmtSF&#x27;] + epsilon)\n\n👧🏻 所以其实应该是这样：\n#transform datadf_train.loc[df_train[&#x27;TotalBsmtSF&#x27;] &gt; 0, &#x27;TotalBsmtSF&#x27;] = np.log(df_train.loc[df_train[&#x27;TotalBsmtSF&#x27;] &gt; 0, &#x27;TotalBsmtSF&#x27;])\n\n#histogram and normal probability plotsns.distplot(df_train[df_train[&#x27;TotalBsmtSF&#x27;] &gt; 0][&#x27;TotalBsmtSF&#x27;], fit = norm)fig = plt.figure()res = stats.probplot(df_train[df_train[&#x27;TotalBsmtSF&#x27;] &gt; 0][&#x27;TotalBsmtSF&#x27;], plot = plt)\n\n👧🏻 plot &#x3D; plt是什么意思？\n🤖 plot=plt是将&#x3D;&#x3D;Matplotlib库的当前pyplot对象&#x3D;&#x3D;传递给probplot函数中的参数plot。这样做是为了让probplot函数能够在当前的Matplotlib图形对象中绘制概率图。通常，我们在创建一个新的Matplotlib图形对象时会使用plt.figure()函数，并为其指定一个新的名称或编号。但是，如果我们已经有了一个现有的图形对象，我们可以将其传递给plot参数，使得probplot函数在该对象中绘制图形。\n👧🏻 我应该怎么获取Matplotlib库的当前pyplot对象？\n🤖 你可以使用matplotlib.pyplot.gcf()函数来获取当前图形对象。gcf()代表“get current figure”，它将返回最近创建的Figure对象（如果没有现有Figure，则会创建一个新的）。\nHomoscedasticity: graphically\nDepartures from an equal dispersion are shown by such shapes as &#x3D;&#x3D;cones (small dispersion at one side of the graph, large dispersion at the opposite side)&#x3D;&#x3D; or &#x3D;&#x3D;diamonds (a large number of points at the center of the distribution)&#x3D;&#x3D;.\n\n#scatter plotplt.scatter(df_train[&#x27;GrLivArea&#x27;], df_train[&#x27;SalePrice&#x27;]);\n\n#scatter plotplt.scatter(df_train[df_train[&#x27;TotalBsmtSF&#x27;]&gt;0][&#x27;TotalBsmtSF&#x27;], df_train[df_train[&#x27;TotalBsmtSF&#x27;]&gt;0][&#x27;SalePrice&#x27;]);\n\n\n\nDummy variables#convert categorical variable into dummydf_train = pd.get_dummies(df_train)\n\n","categories":["刷题笔记"],"tags":["Python","kaggle","data exploration"]},{"title":"数据分析｜指标体系搭建","url":"/2023/03/08/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%EF%BD%9C%E6%8C%87%E6%A0%87%E4%BD%93%E7%B3%BB%E6%90%AD%E5%BB%BA/","content":"什么是指标体系当我们把多个不同的指标有规律，有体系的组织在一起共同去量化人口现状时，它们就成了一套指标体系。\n指标体系是指标与体系的结合体，是一套从多个维度拆解业务现状并有系统有规律的组合起来的多个指标。也就是说单个指标只能叫指标，多个有一定规律，内部有一定关联的指标的组合才能叫做指标体系。\n指标体系的作用指标体系的功能大致可以分为三点，监控-效率-应急\n第一，指标体系是一套标准化的衡量指标，可以监控业务的发展情况；\n第二，指标体系可以形成标准化的体系模版，并且可以固化下来以减少重复的工作；\n第三，如果业务出现问题，我们可以通过指标拆解，迅速定位业务问题，给出业务优化方向。\n\n构建一套指标体系需要注意的问题（1）数据提前埋点\n对于互联网公司而言，数据产生于用户行为，用户行为都是通过埋点促发而记录，所以要获得相应的用户数据就得先埋好点。\n（2）统一指标口径\n统一指标计算口径也是很重要的步骤，统一的计算口径可以使得业务具有横向和纵向的可比性，所以需要在统一整套指标体系的最小计算单位，不同的计算口径计算出的数据也会略有差异。\n（3）指标穷尽且相互独立，遵循MCEC原则\n对于某一块业务我们需要下钻和拆解，下钻维度和拆解维度需要相互穷尽且完全独立，也就是麦肯锡提出的MCEC原则，样才能更好的暴露业务存在问题。MCEC原则也会在指标体系构建方法中详细介绍。\n如何构建一套指标体系数据指标体系建设的方法可以总结为三个步骤，即明确业务目标，梳理产品生命周期及用户行为路径以及指标分层治理，在这三个步骤当中又涉及到 OSM(Object,Strategy,Measure), AARRR(Acquisition,Activation,Retention,Revenue,Referral), UJM(User, Journey, Map), MECE (Mutually Exclusive, Collectively Exhaustive) 四个模型，这四个模型是指导我们构建完整而清晰的指标体系的方法论。\n明确业务目标：OSM模型OSM模型是 Object, Strategy, Measure的缩写。\n1. 在建立数据指标体系之前，一定要清晰的了解业务目标，也就是模型中的O,Object。换句话说，业务的目标也就是业务的核心KPI，了解业务的核心KPI能够帮助我们快速理清指标体系的方向。\n2. 了解业务目标方向之后，就需要制定相应的行动策略，也就是模型中的S,Strategy。行动策略的制定可以根据产品生命周期或者用户行为路径进行拆解，也就是把业务的核心KPI拆解到产品生命周期(AARRR)或者用户行为路径(UJM)当中，在整条链路当中分析可以提升核心KPI的点。\n3. 最后，就需要制定较细的评估指标，也就是模型中的M,Measure。评估指标的制定是将产品链路或者行为路径中的各个核心KPI进行下钻细分，这里用到的方法就是麦肯锡著名的MECE模型，需保证每个细分指标是完全独立且相互穷尽的。\n总结一下OSM模型的内容及其与AARRR,UJM,MECE模型之间的关系，OSM模型是指标体系建设的指导思想，理解业务KPI是OSM模型的核心；制定行动策略是实现业务KPI的手段，而AARRR和UJM模型是实现策略制定的方法论；制定细分指标是评估业务策略优劣的方法，而MECE模型制定细分指标的方法论。\n\n清理产品生命周期及用户行为路径：AARRR&#x2F;UJMAARRR和UJM模型都是路径模型，二者原理相似，只是它们出发的角度不一样。AARRR模型是从产品角度出发，揭示产品的整个生命周期；而UJM模型是从用户出发，揭示用户的行为路径。\nAARRR模型是基于产品角度，简单地来说就是拉新，促活，留存，付费，推广。对于一款产品来说，我们首先要从各个渠道获取用户；其次需要激活这些用户并让他们留存下来；对于留存下来的用户引导他们付费以及推广产品。\nUJM模型则是从用户角度出发，描述了用户进入产品的整个路径流程，即注册，登陆，加购，购买，复购链路流程。\n无论是产品角度还是用户角度进行链路流程，核心KPI都可以下钻到相应的节点，这样我们就在整条链路流程当中拆解了业务的核心KPI。这样的好处是，我们可以从更多的角度和维度监控和分析业务问题。\n\n指标体系分层治理：MECE前面两个步骤，首先我们明确了业务核心目标；其次，我们将业务核心的KPI下钻到产品生命周期或者用户路径行为中；接下来我们需要对这些核心KPI向下进行三到五层的拆解，这个过程我们称为指标体系分级治理，用到的模型是MECE模型。\nMECE模型的指导思想是完全独立，相互穷尽，根据这个原则拆分可以暴露业务最本质的问题，帮助数据分析师们快速地定位业务问题。例如，客户总成交额GMV进行以及拆解可以是付费用户数与平均客单价的乘积。\n\n以GMV为例，用三个步骤，四个模型教会你搭建指标体系的方法\n如果你的老板给出你一个很大的业务问题，他说，“我们现在做一套GMV相关的指标体系，你出一个方案吧！”面对这么大的一个命题，我们就需要对命题进行分解，将其分解成若干个子问题并找到各个子问题之间的联系，做成一套业务监控指标体系，帮助数据分析师快速定义业务问题。在这里，我们就通过上面提到的三个步骤，四个模型去搭建GMV相关的指标体系。\n\n\n第一步，根据OSM模型构建整体框架，明确业务目标。\n为什么业务会关注GMV？当然这是业务的核心KPI，关系到自己的饭碗，GMV当然越高越年终奖越高。所以，作为数据分析师我们提炼出业务目标——提升用户总成交量GMV。\n第二步，根据AARRR或UJM模型拆解用户达成GMV的路径，将业务目标转换为提升用户路径转化率。\n用户达成GMV需要通过六个步骤，即注册-登录-曝光-点击-加购-成交。到目前为止，我们已经将提升GMV这个目标转换为提升用户付费路径的转化率，只要我们提升用户每一步的基数，使得每一步的转化率变高就可以达成提高GMV的目标。\n将提升GMV转化为提高用户达成GMV路径转化率还有另外一个好处，即通过路径拆解能够暴露业务更多的问题，同时，分析师可以根据暴露的业务问题提出相应的建议方案，这也是数据分析师的价值所在。\n第三步，根据MECE模型对GMV达成路径的每一个指标进行拆解，实现指标分级治理。\n有了GMV达成路径之后，我们就可以将这个路径的核心步骤抽象成GMV的分级指标并进行回溯下钻。同时，找出影响每一个步骤的关键因素作为二级指标，每一个关键因素之间需要完全独立，相互穷尽。\n我们先根据公式1：\n$GMV&#x3D;成交用户数*平均客单价$\n\n\n这里将核心KPI用户总成交量GMV进行了一级拆解。\n又有公式2：\n$成交用户数&#x3D;点击UV*访购率$\n将公式2带入公式1得到：\n$GMV&#x3D;点击UV访购率平均客单价$\n\n\n又有公式3：\n$点击UV&#x3D;曝光UV*转化率$\n将公式3带入公式1得到：\n$GMV&#x3D;曝光UV转化率访购率*平均客单价$\n\n\n到这里呢，我们已经将核心KPI用户总成交量GMV进行三级回溯拆解，形成了分级治理的指标体系。到这里并没有结束，像曝光UV等着指标还可以继续向下拆解，例如，谷歌渠道曝光UV，华为渠道曝光UV等等，可以根据具体的工作场景进行适当的调整和向下拆解。\n讲到这里你可能会有几个问题。\n问题1：指标分级治理拆这么细有什么用？\n正向作用：分解核心KPI，明确每一个步骤的行动计算和每个行动考核指标。\n例如，老板让你估算明年GMV，就可以根据历史数据运用这套指标体系对明年的GMV进行估算。\n再例如，老板让你下个月做到1个亿的GMV，让你出个方案。这是就可以再对曝光UV进行细分，把量拆解到每一个渠道上去。\n反向作用：当业务出现问题，可以通过指标体系反向排查业务问题。\n例如，这个月的GMV下降了10%，老板让你排查下问题在哪里。这时候就可以根据这套指标体系逐一排查问题，定位到是哪个步骤，哪个环节出现问题，并提出相应的解决策略。\n问题2：在运用MECE模型进行指标体系分级治理时，是不是拆的越细越好，越全越好？\n当然不是，在进行MECE拆解时，需要找到与核心指标有重要关联关系的子集进行拆解分类，这样才能保证指套指标体系能够指导业务进行决策分析，帮助数分定位业务问题！\n","tags":["数据分析"]},{"title":"数据分析｜数据埋点设计","url":"/2023/03/08/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%EF%BD%9C%E6%95%B0%E6%8D%AE%E5%9F%8B%E7%82%B9%E8%AE%BE%E8%AE%A1/","content":"六个步骤实现数据埋点设计1.确认事件与变量\n这里的事件指产品中的功能或者用户的操作，而变量是指描述事件的属性或者关键指标。确认事件与变量可以通过AARRR模型或者UJM模型进行逐步拆解，理清用户生命周期和行为路径，抽象出每一个步骤的关键指标。\nTips：AARRR模型和UJM模型会在之前的文章中有讲过，点击阅读原文即可跳转。\n\nAARRR 模型\n\nUJM 模型\n\n\n2.明确事件的触发时机\n不同的触发时机代表不同的计算口径，因此触发时机是影响数据准确的重要因素。以用户付款为例，是以用户点击付款界面作为触发条件，还是以付款成功作为触发条件进行埋点呢？二者口径不同，数据肯定会有一定差异，因此明确事件触发条件非常重要。\n而在用户付款这个例子中，我们建议使用两个字段记录用户付款行为，一个字段记录点击付款界面这个行为，另一个字段记录是否付款成功。\n3.明确事件的上报机制\n不同的上报机制也是数据准确性的重要影响因素之一，客户端上报数据可能会由于网络原因出现丢包的情况，前面章节已经详细介绍过，这里就不在赘述上报机制之间的异同。而作为数据分析师，在完成埋点工作的时候也需要确定数据是实时上报还是异步上报，以确定埋点是否合理，并及时调整数据埋点方案。\n4.设计数据表结构\n统一的数据表结构，方便团队内部进行数据的管理和复用，建议团队内部形成一套统一的数据结构规范。例如，将表分为不同的层级，第一层记录用户的基础信息，包括id,地区,昵称等；第二层记录玩家行为信息。\n5.统一字段命名规范\n有了统一的数据表结构档案还是不够的，统一数据命名规范数据埋点工作的重要一环。确保同一变量在所有的数据表当中都用统一的字段，比如消费金额这个字段，我们希望所有的表只要出现消费金额都用Amount字段，不要出现money,pay等其他字段。\n建立公司内部或者团队内部的命名规范是非常必要的，可以采用「动词+名词」或者「名词+动词」的规则来命名，比如「加入购物车」事件，就可以命名为：addToCart。\n6.明确优先级\n数据埋点都是为数据应用做铺排，埋点之后分析师可能面临着搭建指标体系和数据报表体系的工作，可以根据报表的优先级、埋点的技术实现成本以及资源有限性为数据埋点确定优先级。\n以电商购物成交转化为例实现数据埋点设计\n（1）通过UJM模型拆分用户购买商品的路径：将用户购买路径拆解为注册-登录-商品曝光-商品点击-浏览页面详情-加入购物车-生成订单-订单支付步骤，根据产品或策划提的数据需求，确定每一个步骤学要看哪些字段才能实现数据需求。\n（2）确认触发机制：明确是在点击按钮时记录行为还是在用户完成该步骤时记录行为。\n（3）确认上报机制：明确数据上报机制，是实时上报还是异步上报，不同的上报机制采集到的字段可能不一样，或者说需要将字段拆分到不同表进行记录。\n（4）统一字段名：业务内同一变量在所有的数据表当中都用统一的字段，例如，用户编号用account_id,用户所属国家用region,用户所属地区用ip_region等等。\n（5）统一表层级结构：我们这里采用两层数据表结构，第一层存放用户基信息，第二层存放用户行为信息。这个根据团队内部的数据接入规范进行调整，只要是统一的结构，对于数据分析师的分析都是有利的。\n（6）明确数据优先级：根据埋点需求的紧急程度，给每一个买埋点任务标上优先级。\n根据上面的六个步骤，将每一个步骤需要记录的字段按照标准格式汇总到文档，即可完成初步的埋点设计。当然完成初版埋点设计之后，还需要与产品、策划、程序一遍一遍过文档内容，不断修改完善，直至三方会谈达成统一意见。\n\n","tags":["数据分析"]},{"title":"数据分析｜数据看板","url":"/2023/03/08/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%EF%BD%9C%E6%95%B0%E6%8D%AE%E7%9C%8B%E6%9D%BF/","content":"什么是数据看板数据看板一般用作后台系统的首页，主要呈现公司当前业务相关或运营管理相关数据和图表，方便公司内部人员实时了解公司内情，掌握业务发展情况，并能够对数据变化做出业务决策。\n谁使用\n数据看板的应用场景\n应用场景 1：监控\n\n监控是数据看板主流的应用场景。通过看板大屏，公司可以实时获取数据，了解商业进程，洞察发展趋势，甚至发布业务预警。\n\n应用场景 2：分析\n\n数据看板需要具备下沉细节的能力，在实际数据与项目预期不一致时，帮助业务部门分析导致异常的细节点、直击核心问题。\n\n应用场景 3：协作\n\n在发现数据问题、找到数据原因后，公司需要采取行动解决问题。\n数据看板的搭建（4）主要分为以下四步：\n第一步，明确需求。搭建看板有三问：一问使用者的业务需求是什么？二问业务目标是什么？三问如何达到业务目标？\n清楚问题答案后，才能明确看板需求，聚焦具体的商业问题。无论是自建看板还是为他人搭建看板，首先需要明确需求。\n第二步，需求分析。在这一步，我们需要拆解业务需求目标，选择合适的维度将其抽象为数据指标体系，确定看板基础内容。\n第三步，可视化。可视化是创建过程的核心环节。可视化图表需要准确表达数据信息，并通过有序组合排列清晰传递业务事实。这里建议采用议论文的写作方法：重要信息在前，佐证数据在后。\n第四步，评估效果。完成基础搭建工作后，我们需要关注如下问题：\n\n看板是否只有一屏幕（最多不超过 1.5 个屏幕）？\n看板使用者能否通过看板完整讲述业务故事？\n创建的看板能否帮助使用者迅速发现趋势、规律和异常？\n\n","tags":["数据分析"]},{"title":"数据分析｜数据指标口径不统一","url":"/2023/03/08/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%EF%BD%9C%E6%95%B0%E6%8D%AE%E6%8C%87%E6%A0%87%E5%8F%A3%E5%BE%84%E4%B8%8D%E7%BB%9F%E4%B8%80/","content":"\nCase1: 统一指标在不同系统之间标口径不一致改进方方案是将各个系统都需要用的复合指标，统一由数据中台进行加工，并统一向外提供消费，同时数据中台需要确保指标的准确性、及时性，最好能提供自我质量检查机制，无需消费者自己再检查。\nCase2: 中间表的建立和维护\n目的：依托于基础的埋点表&#x2F;业务明细表&#x2F;用户明细表等，来提高数据提取与输出的效率。\n作用：在[dws层 (data warehouse service，汇总层，按照业务划分来提供后续的业务查询、数据分发等) ][https://blog.csdn.net/pmdream/article/details/113601956]，将**基础事实层**的数据，通过**与产品人员既定的规则**编写，用”case when”或syscode系统码表来将业务口径标签化，将数据固定在对应主题域中，方便日常的汇报或者用户分析使用。\n\n\n引自：https://zhuanlan.zhihu.com/p/145226500\n\n供给端创建一张中间表，将所有功能数据存储，对于有关需求可以随取随用。\n\n消耗端运营人员除了关注整体的文章阅读外，还会关注各个入口的转化情况，数据如下：\n\n与产品&#x2F;运营人员，开会商议，确定每个来源入口的规则，对埋点表进行处理，用case when使不同的来源入口标签化：\n\n总结通过建立中间表，确实可以提高数据的输出效率，但是光建立是远远不够的，后期的维护也同样重要。\n由于规则是与产品&#x2F;运营商定的，必须形成规范的数据字典文档，存储在公共平台上（wiki、SVN等），有改动或者新增，需及时调整。\n有新增的业务时，也要在发版之后，添加至中间表中，避免数据遗漏或者重跑。\nCase3: 可以彻底解决数据指标口径不统一的问题吗？\n参考：https://coffee.pmcaff.com/article/3203006749265024?newwindow=1#:~:text=指标口径不统一的,的把数据用起来%E3%80%82\n\nCase4: 如何在公司内部统一数据指标口径第一，规范数据埋点，先统一数据埋点的最小维度记录方式等，做好这一步是统一数据口径的基础，会为之后口径的统一提供极大便利；其次是，构建数据字典，定义每一个指标的最小维度和统计口径；然后就是通过数据指标体系等进行数据指标的展示。\n当然这只是数据层面的，对口径的统一还需要和各方沟通达成统一的认知。\n制定数据埋点规范","tags":["数据分析"]},{"title":"数据分析｜统计学","url":"/2023/03/12/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%EF%BD%9C%E7%BB%9F%E8%AE%A1%E5%AD%A6/","content":"\n有1000个样本，如何计算总体方差？\n“样本方差的期望等于总体方差。”在这些样本里再进行多次重复抽样，用多次得出的方差来估计总体方差。\n\n\n\n","tags":["数据分析"]},{"title":"数据分析｜计算月环比 月同比","url":"/2023/03/12/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%EF%BD%9C%E8%AE%A1%E7%AE%97%E6%9C%88%E7%8E%AF%E6%AF%94-%E6%9C%88%E5%90%8C%E6%AF%94/","content":"SQL计算月环比、月同比准备数据数据：日期，订单金额\n假设数据是精确到天的\n\n计算月环比：和上个月做比较-- 月环比select substr(a.d, 1, 7) as month, a.d, a.orderpay, b.dd, b.originalday, b.orderpay, (a.orderpay-b.orderpay)/b.orderpay as month_ratefrom(  select date_format(datetime, &#x27;%Y-%m-%d&#x27;) as d, orderpay\tfrom ordertable\t\t) as aleft join(  select date_add(date_format(datetiem, &#x27;%Y-%m-%d&#x27;), interval 1 month), \t\tdate_format(datetime, &#x27;&amp;Y-%m-%d&#x27;) as originalday, orderpay  from ordertable\t) as bon a.d = b.dd-- 如果是精确到月的数据，就要把 datetime 变成 concat(datetime, &#x27;-01&#x27;)select substr(a.d, 1, 7) as month, a.d, a.orderpay, b.dd, b.originalday, b.orderpay, (a.orderpay-b.orderpay)/b.orderpay as month_rate from   (select DATE_FORMAT(CONCAT(datetime,&#x27;-01&#x27;),&#x27;%Y-%m-%d&#x27;) as d ,orderpay  from ordertable) a  left join   (select DATE_ADD(DATE_FORMAT(CONCAT(datetime,&#x27;-01&#x27;),&#x27;%Y-%m-%d&#x27;),INTERVAL 1 month )as dd   ,DATE_FORMAT(CONCAT(datetime,&#x27;-01&#x27;),&#x27;%Y-%m-%d&#x27;)as originalday,orderpay from ordertable) bon a.d=b.dd\n\n从结果可以看到，月环比的计算逻辑：在原有的时间加上一个月与原表连接即可得到本月与上个月的信息。结果有几个月份是null，原因是我造的数据没有11月份的，所以才没有计算，这个可忽略。\n月同比：和去年的这个月做比较-- 月同比select substr(a.d, 1, 7) as month, a.d, a.orderpay, b.dd, b.originalday, b.orderpay, (a.orderpay-b.orderpay)/b.orderpay as month_ratefrom(\tselect date_format(date, &#x27;%Y-%m-%d&#x27;) as d, orderpay  from ordertable\t) as aleft join(\tselect date_add(date_format(date, &#x27;%Y-%m-%d&#x27;), interval 1 year) as dd, date_format(date, &#x27;%Y-%m-%d&#x27;) as originalday, orderpay  from ordertable\t) as bon a.d = b.dd-- 如果是精确到月的数据，还是要把 datetime 变成 concat(datetime, &#x27;-01&#x27;)\n\n\nPython\n用python中的pandas模块。\n\nimport pandas as pdimport numpy as npmonths = pd.date_range(*start*=&#x27;2010-01-01&#x27;, *end*=&#x27;2020-12-31&#x27;, *freq*=&#x27;M&#x27;)df = pd.DataFrame(&#123;&#x27;month&#x27;: months, &#x27;v&#x27;: 100*np.random.rand(months.shape[0], 1).reshape(months.shape[0])&#125;)df\n\n\n\n\n\nmonth\nv\n\n\n\n0\n2010-01-31\n99.934812\n\n\n1\n2010-02-28\n60.736689\n\n\n2\n2010-03-31\n6.801932\n\n\n3\n2010-04-30\n47.324930\n\n\n4\n2010-05-31\n3.845547\n\n\n…\n…\n…\n\n\n127\n2020-08-31\n19.881904\n\n\n128\n2020-09-30\n28.072124\n\n\n129\n2020-10-31\n18.861094\n\n\n130\n2020-11-30\n27.030143\n\n\n131\n2020-12-31\n60.719457\n\n\n132 rows × 2 columns\n# 环比计算# 方法1df[&#x27;v_last&#x27;] = df[&#x27;v&#x27;].shift(1)# shift()表示将这列数据整个后移一位df[&#x27;month_earlier_1&#x27;] = df[&#x27;v&#x27;]/df[&#x27;v_last&#x27;]-1df\n\n\n\n\nmonth\nv\nv_last\nmonth_earlier_1\n\n\n\n\n0\n2010-01-31\n99.934812\nNaN\nNaN\n\n\n1\n2010-02-28\n60.736689\n99.934812\n-0.392237\n\n\n2\n2010-03-31\n6.801932\n60.736689\n-0.888010\n\n\n3\n2010-04-30\n47.324930\n6.801932\n5.957572\n\n\n4\n2010-05-31\n3.845547\n47.324930\n-0.918742\n\n\n…\n…\n…\n…\n…\n\n\n127\n2020-08-31\n19.881904\n68.391408\n-0.709292\n\n\n128\n2020-09-30\n28.072124\n19.881904\n0.411943\n\n\n129\n2020-10-31\n18.861094\n28.072124\n-0.328120\n\n\n130\n2020-11-30\n27.030143\n18.861094\n0.433116\n\n\n131\n2020-12-31\n60.719457\n27.030143\n1.246361\n\n\n132 rows × 4 columns\n# 方法2df[&#x27;m_m_diff&#x27;] = df[&#x27;v&#x27;].diff()# diff()用于计算相邻两个值的差值df[&#x27;month_earlier_2&#x27;] = df[&#x27;m_m_diff&#x27;]/df[&#x27;v&#x27;].shift(1)df\n\n\n\n\nmonth\nv\nv_last\nmonth_earlier_1\nm_m_diff\nmonth_earlier_2\n\n\n\n\n0\n2010-01-31\n99.934812\nNaN\nNaN\nNaN\nNaN\n\n\n1\n2010-02-28\n60.736689\n99.934812\n-0.392237\n-39.198123\n-0.392237\n\n\n2\n2010-03-31\n6.801932\n60.736689\n-0.888010\n-53.934757\n-0.888010\n\n\n3\n2010-04-30\n47.324930\n6.801932\n5.957572\n40.522998\n5.957572\n\n\n4\n2010-05-31\n3.845547\n47.324930\n-0.918742\n-43.479383\n-0.918742\n\n\n…\n…\n…\n…\n…\n…\n…\n\n\n127\n2020-08-31\n19.881904\n68.391408\n-0.709292\n-48.509504\n-0.709292\n\n\n128\n2020-09-30\n28.072124\n19.881904\n0.411943\n8.190221\n0.411943\n\n\n129\n2020-10-31\n18.861094\n28.072124\n-0.328120\n-9.211030\n-0.328120\n\n\n130\n2020-11-30\n27.030143\n18.861094\n0.433116\n8.169049\n0.433116\n\n\n131\n2020-12-31\n60.719457\n27.030143\n1.246361\n33.689314\n1.246361\n\n\n132 rows × 6 columns\n# 方法3df[&#x27;month_earlier_3&#x27;] = df[&#x27;v&#x27;].pct_change()# df中的pct_change()表示当前元素与先前元素相差的百分比df\n\n\n\n\nmonth\nv\nv_last\nmonth_earlier_1\nm_m_diff\nmonth_earlier_2\nmonth_earlier_3\n\n\n\n\n0\n2010-01-31\n99.934812\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\n2010-02-28\n60.736689\n99.934812\n-0.392237\n-39.198123\n-0.392237\n-0.392237\n\n\n2\n2010-03-31\n6.801932\n60.736689\n-0.888010\n-53.934757\n-0.888010\n-0.888010\n\n\n3\n2010-04-30\n47.324930\n6.801932\n5.957572\n40.522998\n5.957572\n5.957572\n\n\n4\n2010-05-31\n3.845547\n47.324930\n-0.918742\n-43.479383\n-0.918742\n-0.918742\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n\n\n127\n2020-08-31\n19.881904\n68.391408\n-0.709292\n-48.509504\n-0.709292\n-0.709292\n\n\n128\n2020-09-30\n28.072124\n19.881904\n0.411943\n8.190221\n0.411943\n0.411943\n\n\n129\n2020-10-31\n18.861094\n28.072124\n-0.328120\n-9.211030\n-0.328120\n-0.328120\n\n\n130\n2020-11-30\n27.030143\n18.861094\n0.433116\n8.169049\n0.433116\n0.433116\n\n\n131\n2020-12-31\n60.719457\n27.030143\n1.246361\n33.689314\n1.246361\n1.246361\n\n\n132 rows × 7 columns\ndf.drop(columns=&#123;&#x27;v_last&#x27;, &#x27;month_earlier_1&#x27;, &#x27;month_earlier_2&#x27;,&#x27;month_earlier_3&#x27;,&#x27;m_m_diff&#x27;&#125;, inplace=True)# 同比计算# 方法1df[&#x27;last_year_v&#x27;] = df[&#x27;v&#x27;].shift(12)df[&#x27;year_earlier_1&#x27;] = df[&#x27;v&#x27;]/df[&#x27;last_year_v&#x27;]-1df\n\n\n\n\nmonth\nv\nlast_year_v\nyear_earlier_1\n\n\n\n\n0\n2010-01-31\n99.934812\nNaN\nNaN\n\n\n1\n2010-02-28\n60.736689\nNaN\nNaN\n\n\n2\n2010-03-31\n6.801932\nNaN\nNaN\n\n\n3\n2010-04-30\n47.324930\nNaN\nNaN\n\n\n4\n2010-05-31\n3.845547\nNaN\nNaN\n\n\n…\n…\n…\n…\n…\n\n\n127\n2020-08-31\n19.881904\n61.175829\n-0.675004\n\n\n128\n2020-09-30\n28.072124\n26.545938\n0.057492\n\n\n129\n2020-10-31\n18.861094\n64.892849\n-0.709350\n\n\n130\n2020-11-30\n27.030143\n87.248627\n-0.690194\n\n\n131\n2020-12-31\n60.719457\n91.586339\n-0.337025\n\n\n132 rows × 4 columns\ndf[&#x27;year_diff&#x27;] = df[&#x27;v&#x27;].diff(12)df[&#x27;year_diff&#x27;].fillna(0, inplace=True)df[&#x27;year_earlier_2&#x27;] = df[&#x27;year_diff&#x27;]/(df[&#x27;v&#x27;]-df[&#x27;year_diff&#x27;])# (df[&#x27;v&#x27;]-df[&#x27;year_diff&#x27;])计算的是去年同期的值df\n\n\n\n\nmonth\nv\nlast_year_v\nyear_earlier_1\nyear_diff\nyear_earlier_2\n\n\n\n\n0\n2010-01-31\n99.934812\nNaN\nNaN\n0.000000\n0.000000\n\n\n1\n2010-02-28\n60.736689\nNaN\nNaN\n0.000000\n0.000000\n\n\n2\n2010-03-31\n6.801932\nNaN\nNaN\n0.000000\n0.000000\n\n\n3\n2010-04-30\n47.324930\nNaN\nNaN\n0.000000\n0.000000\n\n\n4\n2010-05-31\n3.845547\nNaN\nNaN\n0.000000\n0.000000\n\n\n…\n…\n…\n…\n…\n…\n…\n\n\n127\n2020-08-31\n19.881904\n61.175829\n-0.675004\n-41.293926\n-0.675004\n\n\n128\n2020-09-30\n28.072124\n26.545938\n0.057492\n1.526187\n0.057492\n\n\n129\n2020-10-31\n18.861094\n64.892849\n-0.709350\n-46.031755\n-0.709350\n\n\n130\n2020-11-30\n27.030143\n87.248627\n-0.690194\n-60.218483\n-0.690194\n\n\n131\n2020-12-31\n60.719457\n91.586339\n-0.337025\n-30.866882\n-0.337025\n\n\n132 rows × 6 columns\ndf[&#x27;year_earlier_3&#x27;] = df[&#x27;v&#x27;].pct_change(periods = 12)df\n\n\n\n\n\nmonth\nv\nlast_year_v\nyear_earlier_1\nyear_diff\nyear_earlier_2\nyear_earlier_3\n\n\n\n0\n2010-01-31\n99.934812\nNaN\nNaN\n0.000000\n0.000000\nNaN\n\n\n1\n2010-02-28\n60.736689\nNaN\nNaN\n0.000000\n0.000000\nNaN\n\n\n2\n2010-03-31\n6.801932\nNaN\nNaN\n0.000000\n0.000000\nNaN\n\n\n3\n2010-04-30\n47.324930\nNaN\nNaN\n0.000000\n0.000000\nNaN\n\n\n4\n2010-05-31\n3.845547\nNaN\nNaN\n0.000000\n0.000000\nNaN\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n\n\n127\n2020-08-31\n19.881904\n61.175829\n-0.675004\n-41.293926\n-0.675004\n-0.675004\n\n\n128\n2020-09-30\n28.072124\n26.545938\n0.057492\n1.526187\n0.057492\n0.057492\n\n\n129\n2020-10-31\n18.861094\n64.892849\n-0.709350\n-46.031755\n-0.709350\n-0.709350\n\n\n130\n2020-11-30\n27.030143\n87.248627\n-0.690194\n-60.218483\n-0.690194\n-0.690194\n\n\n131\n2020-12-31\n60.719457\n91.586339\n-0.337025\n-30.866882\n-0.337025\n-0.337025\n\n\n132 rows × 7 columns\n\n关于pct_change()函数：pct_change主要涉及以下参数，\n\nperiods&#x3D;1，用来设置计算的周期。\n\nfill_method&#x3D;‘pad’，如何在计算百分比变化之前处理缺失值(NA)。\n\nlimit&#x3D;None，设置停止填充条件，即当遇到填充的连续缺失值的数量n时，停止此处填充\n\nfreq&#x3D;None，从时间序列 API 中使用的增量（例如 ‘M’ 或 BDay())\n\n\n","tags":["数据分析"]},{"title":"数据分析｜逻辑回归","url":"/2023/03/12/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%EF%BD%9C%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/","content":"分类和回归Logistic Regression 和 Linear Regression\nLinear Regression：输出一个标量wx+b，是连续值，用以处理回归问题；\nLogistic Regression：将标量wx+b通过sigmoid函数映射到(0,1)上，并划分一个阈值，大于阈值的分为一类，其他归为另一类，可处理二分分类问题；\n对于N分类问题，先得到N组w值不同的wx+b，然后利用softmax函数归一化，最后得到N个类上的概率，可处理多分类问题。\n\n\n\n因此，逻辑回归属于分类方法，其本质是将回归方程映射到了(0,1)上。\n\nSupport Vector Regression 和 Support Vector Machine\nSVR：输出wx+b，即某个样本点到分类面的距离，是连续值，用以处理回归问题；\nSVM：将该距离通过sign(·)函数映射，距离为正的样本点为一类，为负的是另一类，故为分类问题。\n\n相应有哪些常用方法\n常见的分类方法：逻辑回归、决策树分类、KNN(K-近邻)分类、贝叶斯分类、人工神经网络、支持向量机(SVM)等\n\n常见的回归方法：线性回归、多项式回归、逐步回归等\n\n\n（常见的聚类方法：K-Means(K均值)聚类等）\n逻辑回归分析主要思想根据现有数据对决策边界建立回归方程，然后将回归方程映射到分类函数上实现分类。\n原理介绍\n具体见参考[1]\n\nLogistic回归的原理可以理解为以下四步：\n\n利用回归方程表示决策边界\n利用Sigmod函数对回归关系进行映射\n在得到拟合函数后，利用损失函数来评价模型与实际值之间的差异大小\n求出损失函数取得极小值时对应的W，从而得到拟合函数\n\n评价指标常见的分类模型性能指标有准确率(accuracy)、召回率(recall)、ROC曲线等。\n混淆矩阵包括分类器预测结果：真正TP(true positive)、真负TN(true negative)、假正FP(false positive)、假负FN(false negative)的数量，其中真正和真负均为正确分类的结果。\n\n1代表正类，0代表负类\n准确率ACC、真正率TPR及假正率FPR注意区别准确率Accuracy与精确率(查准率)Precision区别：后者是预测与实际均为正类别样本数量 与 预测正样本数量的比值，即 $TP&#x2F;(TP+FP)$ 。一般而言，回归模型中默认的Score都是Accuracy值。\nROC曲线ROC曲线由变量1-Specificity和Sensitivity绘制，其中横轴1-Specificity&#x3D;假正率(FPR)、纵轴Sensitivity&#x3D;真正率(TPR)，ROC曲线的对角线表示随机猜测，若ROC曲线在对角线下表示分类器性能比随机猜测还差，ROC曲线下的区域面积(area under the curve,AUC)表示分类模型的性能。\n意义：\n\n有助于选择最佳阈值：ROC曲线越靠近左上角，模型查全率越高，最靠近左上角的ROC曲线上的点是分类错误最少的最好阈值，其假正例和假反例总数最少。\n可以比较不同学习器的性能：将各个学习器的ROC曲线绘制在同一坐标中，直观比较，越靠近左上角的ROC曲线代表的学习器准确性越高。\nAUC同时考虑了学习器对于正例和负例的分类能力，在样本不平衡的情况下，依然能对分类器做出合理评价。\n\n逻辑回归的Python实现利用Python中sklearn包进行逻辑回归分析。\n提出问题根据已有数据探究“学习时长”与“是否通过考试”之间关系，并建立预测模型。\n理解数据1、导入包和数据\n#1.导入包import warningsimport pandas as pdimport numpy as npfrom collections import OrderedDictimport matplotlib.pyplot as pltwarnings.filterwarnings(&#x27;ignore&#x27;)#2.创建数据（学习时间与是否通过考试）dataDict=&#123;&#x27;学习时间&#x27;:list(np.arange(0.50,5.50,0.25)),        &#x27;考试成绩&#x27;:[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]&#125;dataOrDict=OrderedDict(dataDict)dataDf=pd.DataFrame(dataOrDict)dataDf.head()&gt;&gt;&gt;       学习时间\t考试成绩0\t0.50\t01\t0.75\t02\t1.00\t03\t1.25\t04\t1.50\t0\n\n2、查看数据\n#查看数据具体形式dataDf.head()#查看数据类型及缺失情况dataDf.info()&gt;&gt;&gt;&lt;class &#x27;pandas.core.frame.DataFrame&#x27;&gt;RangeIndex: 20 entries, 0 to 19Data columns (total 2 columns):学习时间    20 non-null float64考试成绩    20 non-null int64dtypes: float64(1), int64(1)memory usage: 400.0 bytes#查看描述性统计信息dataDf.describe()&gt;&gt;&gt;        学习时间\t 考试成绩count\t20.00000 20.000000mean\t2.87500\t0.500000std\t1.47902\t0.512989min\t0.50000\t0.00000025%\t1.68750\t0.00000050%\t2.87500\t0.50000075%\t4.06250\t1.000000max\t5.25000\t1.000000\n\n3、绘制散点图查看数据分布情况\n#提取特征和标签exam_X=dataDf[&#x27;学习时间&#x27;]exam_y=dataDf[&#x27;考试成绩&#x27;]#绘制散点图plt.scatter(exam_X,exam_y,color=&#x27;b&#x27;,label=&#x27;考试数据&#x27;)plt.legend(loc=2)plt.xlabel(&#x27;学习时间&#x27;)plt.ylabel(&#x27;考试成绩&#x27;)plt.show()\n\n\n从图中可以看出当学习时间高于某一阈值时，一般都能够通过考试，因此我们利用逻辑回归方法建立模型。\n构建模型1、拆分训练集并利用散点图观察\n#1.拆分训练集和测试集from sklearn.cross_validation import train_test_splitexam_X=exam_X.values.reshape(-1,1)exam_y=exam_y.values.reshape(-1,1)train_X,test_X,train_y,test_y=train_test_split(exam_X,exam_y,train_size=0.8)print(&#x27;训练集数据大小为&#x27;,train_X.size,train_y.size)print(&#x27;测试集数据大小为&#x27;,test_X.size,test_y.size)&gt;&gt;&gt;训练集数据大小为 16 16测试集数据大小为 4 4#2.散点图观察plt.scatter(train_X,train_y,color=&#x27;b&#x27;,label=&#x27;train data&#x27;)plt.scatter(test_X,test_y,color=&#x27;r&#x27;,label=&#x27;test data&#x27;)#plt.plot(test_X,pred_y,color=&#x27;r&#x27;)plt.legend(loc=2)plt.xlabel(&#x27;Hours&#x27;)plt.ylabel(&#x27;Scores&#x27;)plt.show()\n\n\n2、导入模型\nfrom sklearn.linear_model import LogisticRegressionmodelLR=LogisticRegression()\n\n3、训练模型\nmodelLR.fit(train_X,train_y)\n\n模型评估1、模型评分（即准确率）\nmodelLR.score(test_X,test_y)&gt;&gt;&gt;0.75\n\n2、指定某个点的预测情况\n#学习时间确定时，预测为0和1的概率分别为多少？modelLR.predict_proba(3)&gt;&gt;&gt;array([[0.36720478, 0.63279522]])#学习时间确定时，预测能否通过考试？modelLR.predict(3)&gt;&gt;&gt;array([1])\n\n3、求出逻辑回归函数并绘制曲线\n逻辑回归函数\n#先求出回归函数y=a+bx，再代入逻辑函数中pred_y=1/(1+np.exp(-y))b=modelLR.coef_a=modelLR.intercept_print(&#x27;该模型对应的回归函数为:1/(1+exp-(%f+%f*x))&#x27;%(a,b))&gt;&gt;&gt;该模型对应的回归函数为:1/(1+exp-(-1.527106+0.690444*x))\n\n逻辑回归曲线\n#画出相应的逻辑回归曲线plt.scatter(train_X,train_y,color=&#x27;b&#x27;,label=&#x27;train data&#x27;)plt.scatter(test_X,test_y,color=&#x27;r&#x27;,label=&#x27;test data&#x27;)plt.plot(test_X,1/(1+np.exp(-(a+b*test_X))),color=&#x27;r&#x27;)plt.plot(exam_X,1/(1+np.exp(-(a+b*exam_X))),color=&#x27;y&#x27;)plt.legend(loc=2)plt.xlabel(&#x27;Hours&#x27;)plt.ylabel(&#x27;Scores&#x27;)plt.show()\n\n\n黄色S形曲线代表利用数据集拟合得到的逻辑回归曲线\n4、得到模型混淆矩阵\nfrom sklearn.metrics import confusion_matrix#数值处理pred_y=1/(1+np.exp(-(a+b*test_X)))pred_y=pd.DataFrame(pred_y)pred_y=round(pred_y,0).astype(int)#混淆矩阵confusion_matrix(test_y.astype(str),pred_y.astype(str))&gt;&gt;&gt;array([[1, 1],       [0, 2]])\n\n从混淆矩阵可以看出：\n\n该模型的准确率ACC为0.75；\n真正率TPR和假正率FPR分别为0.50和0.00，说明该模型对负例的甄别能力更强（如果数据量更多，该指标更有说服性，而本案例中数据较少，因此受随机影响较大）。\n\n5、绘制模型ROC曲线\nfrom sklearn.metrics import roc_curve, auc  ###计算roc和auc# Compute ROC curve and ROC area for each classfpr,tpr,threshold = roc_curve(test_y, pred_y) ###计算真正率和假正率roc_auc = auc(fpr,tpr) ###计算auc的值plt.figure()lw = 2plt.figure(figsize=(10,10))plt.plot(fpr, tpr, color=&#x27;r&#x27;,         lw=lw, label=&#x27;ROC curve (area = %0.2f)&#x27; % roc_auc) ###假正率为横坐标，真正率为纵坐标做曲线plt.plot([0, 1], [0, 1], color=&#x27;navy&#x27;, lw=lw, linestyle=&#x27;--&#x27;)plt.xlim([0.0, 1.0])plt.ylim([0.0, 1.0])plt.xlabel(&#x27;False Positive Rate&#x27;)plt.ylabel(&#x27;True Positive Rate&#x27;)plt.title(&#x27;Receiver operating characteristic example&#x27;)plt.legend(loc=&quot;lower right&quot;)plt.show()\n\n\n红线以下部分面积等于0.75，即误将一个反例划分为正例。（此处AUC的面积与模型准确率刚好一致，并非总是相等的）\n总结\n理解回归与分类的关系：两者既有区别（三个维度理解），又有联系（将回归方程映射到分类函数）；\n逻辑回归的参数及其含义：准确率（ACC：模型预测准确度）、真正率（TPR：模型将正例分类正确的能力）、假正率（FPR：模型将负例分类正确的能力）、ROC曲线（可以反映模型正确识别正&#x2F;负例的能力，也可利用AUC反映模型准确度）\n\n参考\n机器学习之利用Python进行逻辑回归分析\n\n","tags":["数据分析","Python"]},{"title":"数据分析｜需求沟通","url":"/2023/03/08/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%EF%BD%9C%E9%9C%80%E6%B1%82%E6%B2%9F%E9%80%9A/","content":"\n参考：https://zhuanlan.zhihu.com/p/363896505\n\n\n需求沟通\n需求收集（5+2）\n明确：为什么、做什么、谁做、何时、何地、如何、多少。\n\n需求分析（8）\n\n需求产生的背景和原因\n需求的目的和程度（最好可以量化）\n使用人员和场景\n会影响到哪些业务领域\n统计指标和维度\n展现形式\n数据源\n交付形式和标准\n\n\n目标对齐\n梳理整个流程，把整个流程中的关键环节都列出来，这是其实运用了MVC（最小可行性成品）的思想，每个环节都和业务同学碰一下，保持信息共享，确保需求的进行没有跑偏就好，即使有问题影响也不大，及时发现进行调整。\n\n信息同步\n整个流程一定要数字化，保持信息畅通无阻。信息共享真的很重要，让业务同学清晰看见自己需求的进度，进行得如何了，会让业务同学具有安全感。\n\n\n","tags":["数据分析"]},{"title":"碎碎念｜How is Hadley Wickham able to contribute so much to R, particularly in the form of packages?","url":"/2023/02/08/%E7%A2%8E%E7%A2%8E%E5%BF%B5%EF%BD%9CHow-is-Hadley-Wickham-able-to-contribute-so-much-to-R-particularly-in-the-form-of-packages/","content":"How is Hadley Wickham able to contribute so much to R, particularly in the form of packages?\nDavid Robinson:\nFrom following Hadley’s work, it seems to me that along with being an exceptional programmer and data scientist, and having the advantage of developing R packages as part of his job, Hadley follows a few strategies that serve as useful wisdom for all developers:\n\nHe writes packages that make himself more productive. Three of Hadley’s popular packages, devtools, Roxygen2, and testthat, make it very easy to (respectively) develop, document and test R packages. He recognized that the time spent to create and maintain those was small compared to the time it would save him (and others!) in developing future packages. This extends beyond those package development tools: packages like stringr and lubridate are designed to make working with strings and dates easier. This also extends beyond his own packages: he takes advantage of packages like Rcpp (http://www.rcpp.org/) that make writing R C++ extensions fast and intuitive.\nHe takes full advantage of social coding. He’s a prolific GitHub user (hadley (Hadley Wickham)), which makes it efficient to receive and respond to bug reports and feature requests, and to collaborate with others (for instance, with Romain Francois on dplyr).\nHe works to simplify his packages rather than complicate them. In his announcement of the tidyr package (Introducing tidyr) he notes that “Just as reshape2 did less than reshape, tidyr does less than reshape2.” When packages are simpler (doing a few things well instead of hundreds of things poorly), they’re easier to develop and maintain.\n\n**Hadley Wickham: **\nI like David’s answer, but here are a few more thoughts from a personal perspective ;)\n\nWriting. I have worked really hard to build a solid writing habit - &#x3D;&#x3D;I try and write for 60-90 minutes every morning. It’s the first thing I do after I get out of bed.&#x3D;&#x3D; I think writing is really helpful to me for a few reasons. First, &#x3D;&#x3D;I often use my writing as a reference&#x3D;&#x3D; - I don’t program in C++ every day, so I’m constantly referring to @Rcpp every time I do. Writing also makes me aware of gaps in my knowledge and my tools, and filling in those gaps tends to make me more efficient at tackling new problems.\nReading. I read a lot. I follow about 300 blogs, and keep a pretty close eye on the R tags on Twitter and Stack Overflow. I don’t read most things deeply - &#x3D;&#x3D;the majority of content I only briefly skim. But this wide exposure helps me keep up with changes in technology, interesting new programming languages, and what others are doing with data.&#x3D;&#x3D; It’s also helpful that if when you’re tackling a new problem you can recognise the basic name - then googling for it will suggest possible solutions. If you don’t know the name of a problem, it’s very hard to research it.\nChunking. Context-switching is expensive, so if I worked on many packages at the same time, I’d never get anything done. Instead, at any point in time, most of my packages are lying fallow, steadily accumulating issues and ideas for new feature. Once a critical mass has accumulated, I’ll spend a couple of days on the package.\n\nFinally, it’s hard to over-emphasise the impact that working full-time on R makes. Since I’ve left Rice, I now spend well over 90% of my work time thinking about and programming in R. This has a compounding effect because as I built better tools (cognitive and computational) it becomes even easier to build new tools. I can create a new package in seconds, and I have many techniques on-hand (in-brain) for solving new problems.\n","categories":["碎碎念"]},{"title":"碎碎念｜英文论文中的 Introduction 该怎么写？","url":"/2023/03/20/%E7%A2%8E%E7%A2%8E%E5%BF%B5%EF%BD%9C%E8%8B%B1%E6%96%87%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84Introduction%E8%AF%A5%E6%80%8E%E4%B9%88%E5%86%99/","content":"Summary通常来说，Introduction 占整篇论文的 5-10%，包含以下三部分：\n\n研究背景\n作者的主要论点\n论文的主要内容\n\n重点不是记住我们要写什么内容，而是将 Introduction 的写作逻辑烂熟于心。\n论文的写作逻辑：概括-具体-概括，而 Introduction 作为论文的开头部分，其写作逻辑自然就是：概括-具体。\n\nGeneral\nDefine the general topic\nNarrow the topic to the essay question topic(s)&#x2F;thesis statement - Specific State - what you intend to do in the essay\n\n即最开始先说明研究背景或问题的普遍观点，然后从大的背景范围缩小到具体研究的课题上面；最后阐述你的论文主要内容，其中包含论点和结构。\nIntroduction逻辑结构及模版句\nPolylactide (PLA) has received much attention in recent years due to its biodegradable properties, which offer important economic benefits.\n介绍课题的重要性\n\nPLA is a polymer obtained from corn and is produced by the polymerisation of lactide.介绍研究背景：从最普遍的、读者己经知道的青景开始\n\nIt has many possible uses in the biomedical field and has also been investigated as a potential engineering material.介绍研究背景：更加具体细节的方式，并使用参考文最去支撑\n\nHowever, it has been found to be too weak under impact to be used commercially.该领域存在的普遍问题：要简略，不要具体\n\nOne way to toughen polymers is to incorporate a layer of rubber particles and there has been extensive researchregarding the rubber modification of PLA.\n过渡与转折：从普遍问题过渡到文献综述\n\nFor example, Penney et al. showed that PLA composites could be prepared using blending techniques and more recently Hillier established the toughness of such composites.具体举例：该领域关键研究课题，可按照时间顺序引用文献\n\nHowever, although the effect of the rubber particles on the mechanical properties of copolymer svstems was demonstrated over two years ago, little attention has been paid to the selection of an appropriate rubber component.\n当前研究的空缺\n\nThe present paper presents a set of criteria for selecting such a component.\n本论文的研究内容：目的及重点，描达框架\n\nOn the basis of these criteria it then describes the preparation of a set of polymer blends using PLA and a hydro-carbon rubber(PI).具体介绍本论文的研究的方法论等\n\nThis combination of two mechanistically distinct polymerisations formed a novel copolymer in which the incorporation of Pl significantly increased flexibility.宣布本论文发现的结论：无需给出太多细节\n\n\n","categories":["碎碎念"]},{"title":"读书笔记｜《外婆的道歉信》","url":"/2023/03/21/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BD%9C%E3%80%8A%E5%A4%96%E5%A9%86%E7%9A%84%E9%81%93%E6%AD%89%E4%BF%A1%E3%80%8B/","content":"外婆的道歉信　## [瑞典🇸🇪]弗雷德里克·巴克曼\n不是所有怪物一开始都是怪物。有些因为悲伤才变成了怪物。\n\n“暑期工”警察和抬着担架的护士跑到离车只有几米远时，妈妈慢慢地点了点头。然后，她发动了起亚，轮胎在雪地中转动，一路打着滑上了路，绝尘而去。这是艾莎见过妈妈做的最不负责任的事情。\n为此，她会永远爱她。\n\n爱莎希望今天是万圣节，那样他们就能乘坐公交车，而不至于吓到普通人，别人只会觉得他们是故意装扮成这样的。这也是爱莎喜欢万圣节的原因：在万圣节，与众不同是一件很正常的事。\n\n”每一个经历过战争的人都是破碎的。“\n\n女人深深吸了一口气，深到如果你扔个硬币进去，都听不到它触底的声音。\n\n“人们喝酒是为了忘记那些难受的事情，对吗？”\n“或者来拥有回忆的勇气，我觉得。”\n\n“我觉得他需要帮助。”\n“要帮助那些不想被帮助的人很困难。”\n“需要帮助的人也许不是那些急切寻求他人帮助的人。”爱莎说。\n\n“是因为我，所以你不想要更多的小孩了吗？”她希望他的回答是“不”。\n“是的。”他说。\n“因为我和别人不一样？”她轻声说。\n他没有回答，而她也没有等。她正要从外面关上奥迪的车门时，爸爸从椅子上探过身，抓住她的指尖，视线相交时，他像平时那样闪躲。但随后他说：“因为你是完美的。”\n她从未听过他这么“不犹豫”的口气。如果她大声说出此刻的想法，他会告诉她这根本不是个词。她因此爱他。\n\n死亡最强大的力量不在于它能让人死去，而在于让留下来的人不想再活着。\n\n恐惧就像是香烟，外婆说，困难的不是戒掉，而是不要开始。\n\n孩子们认为时间只是一种情绪，所以“现在”对他们来说时一个毫无意义的词语，对外婆也一样。乔治经常说外婆不是个“时间乐观主义者”，她是一个“时间无神论者”，唯一信奉的宗教是“以后再说”教。\n\n与恶魔斗争的人要时刻警惕，以免自己也变成恶魔。如果你久久地注视深渊，那深渊同时也在注视着你。（[德]尼采）\n\n"},{"title":"读书笔记｜《始于极限》","url":"/2023/03/21/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BD%9C%E3%80%8A%E5%A7%8B%E4%BA%8E%E6%9E%81%E9%99%90%E3%80%8B/","content":"始于极限：女性主义往复书简[日🇯🇵]上野千鹤子 &amp; 铃木凉美“《”AV女演员“的社会学》这个书名让我燃起了希望，我还以为是AV女演员的当事人研究。但这本书采用了微妙的局外人视角，让人以为作者是有特权进入AV现场的女性撰稿人，还是一名拥有情色资本的女性，稍有不慎就可能越界成为AV女演员。”\n（第一章：情色资本，上野千鹤子）\n\n“换句话说，因为别无选择而从事性工作的女性和拥有其他选项、随时可以离开的女性在可行能力上存在巨大的差异。可行能力强的女性将自己的职业说成“自愿的选择”，以这份工作为荣并宣扬其专业精神，这是可以理解的。问题是，她们并不能代表全体性工作者。”\n（第一章：\t情色资本，上野千鹤子）\n\n“女儿是母亲最激烈的批判者。”\n（第一章：\t情色资本，上野千鹤子）\n\n“我从中感受到拥有聪慧母亲的女儿是多么不幸。聪慧的母亲会让她的女儿窒息。聪慧，意味着“妈妈了解你的全部”。于是孩子失去了喘息的空间，暴露在透明的视野中，无路可逃，无处可躲。“孩子长大成人”也就等于“孩子的内心怀揣了父母不了解的阴暗面”。”\n（第一章：\t情色资本，上野千鹤子）\n\n“如果孩子对父母的渴求是一道终极的二选一——“爱还是理解”，曾经的我定会回答：“妈妈，我想要的是理解而不是爱。”但后来我想通了，也懂得感激她了。因为我没有得到理解，却得到了真诚耿直的爱。而且我也意识到，渴望得到理解是强人所难。我没有渴望理解的理由，也没有这个必要。”\n（第一章：\t情色资本，上野千鹤子）\n\n“你在书中提到了母亲说过的话。“我不能原谅你，因为你满不在乎地伤害了我爱到骨子里的女儿的身体和心灵。”多么撕心裂肺的呐喊。”\n（第一章：\t情色资本，上野千鹤子）\n\n“母亲总是用自己的话语与我碰撞，并希望我用同样的方式回应，而不是单方面地告诉我“我说不行就不行”或者“老师说不行就不行”。然而年幼时，不允许沉默、时刻被迫解释自身想法的环境反而让我觉得自己在言语之外没有自由。”\n（第二章：母女，铃木凉美）\n\n“在与母亲交谈时，我总觉得自己说的每句话对她来说都有既视感，是她能报出名字的现象，全无新的惊喜。我感到母亲热衷于育儿的原因之一，就是为了验证自己的研究。”\n（第二章：母女，铃木凉美）\n\n“痛了就喊痛，人的尊严就从这里开始。……支撑受害者不是软弱的表现，反而是强大的证明。”\n（第二章：母女，上野千鹤子）\n\n“我也走过了充满羞耻和失败的人生。我永远无法抬头挺胸地说，我对自己过往的人生无怨无悔。”\n（第二章：母女，上野千鹤子）\n\n“这种自虐与自尊正是女性的阿喀琉斯之踵，是这一行的男性多年来一直在利用的东西。这是自己选的路，没法跟任何人抱怨；做选择的时候就已经做好承担风险的准备，所以没有资格抱怨……但这并不意味着你同意他人对你为所欲为。不仅仅是你，恐怕还有许多女性对她们在现场遭受的（身体和精神上的）创伤保持沉默。”\n（第三章：恋爱与性，上野千鹤子）\n\n“性的门槛已经大幅降低，性的质量却迟迟没有提高。”\n（第三章：恋爱与性，上野千鹤子）\n\n“当“新的男人”问，有没有“新的女人”能与他们对等地开展恋爱游戏时，《青鞜》[4]的女人举起手说“我们在这里”。\n[4]日本首部女性文艺杂志，“青鞜”译自blue stockings，特指18世纪英国贵族女性举办的文化沙龙。”\n（第三章：恋爱与性，上野千鹤子）\n\n““不过是性罢了”，“就这种程度的恋爱而已”……如果你抱有这种想法，那回报也就只有这么一丁点。人只能得到自己所要的。“\n（第三章：恋爱与性，上野千鹤子）\n\n“单身并不意味着没有性属性，而性属性也不以“成对”为条件。”\n（第三章：恋爱与性，上野千鹤子）\n\n“吉本隆明留下了一个哀伤的概念“生理迫使的成熟”。即使一个人实际上没有成熟，年龄和衰老也会强迫他对很多事死心，即变得达观。性欲与生命力相关。”\n（第三章：恋爱与性，上野千鹤子）\n\n“没有性和爱，人也活得下去，但“有”比“没有”确实更能丰富人生的经历。”\n（第三章：恋爱与性，上野千鹤子）\n\n“我并没有因此突然想要结婚成家，但我比以前更理解人们为什么更倾向于扩大婚姻，在婚姻中创造自由，而不是压缩婚姻，扩大婚姻之外的自由。”\n（第四章：婚姻，铃木凉美）\n\n“至少在我周围，那些对婚姻制度说“不”的人往往与伴侣建立了比寻常夫妇稳固得多的联系。我也觉得正是因为有这种精神联系，他们才有底气置身于制度之外。在精英人群的未婚者中，这种倾向尤其明显。”\n（第四章：婚姻，铃木凉美）\n\n“我无法忍受将性和爱置于权利和义务的关系之下，与拥有和被拥有的关系挂钩。”\n（第四章：婚姻，上野千鹤子）\n\n“在市场上用性换取经济回报……市场不就是这么回事吗？将一切都变成商品吃干抹净的不就是资本主义吗？——我不认同这种虚无主义。资本主义创造了一个由自由劳动者（除了出卖自己的劳动力，没有其他生存手段的工资劳动者）组成的劳动市场，但他们的“自由”是受限的。劳动者可以与资本家签订“自由”的契约，但他们成为债务奴隶的“自由”是被禁止的。例如，你无法将自己作为债务的抵押品，“不还钱就沦为奴隶”的契约在现代法律中无法成立。买卖身体部位和器官也是类似，买卖胎儿与贩卖儿童也一样无效。现实世界中确实存在可以买卖器官的黑市，也有以代孕妈妈的名义买卖胎儿的市场，这都是无限接近违法行为的灰色地带。换句话说，在资本主义之下，可以交换的东西是有限制的，并不是所有东西都可以成为商品。性作为一种对身体的侵犯行为，同样处于这个灰色地带。”\n（第五章：认可欲求，上野千鹤子）\n\n“爱是一种积极主动的行为。而积极主动的行为正是自主的标志。如此想来，世间最有意义的行为不正是不求回报的付出吗？这种行为的回报不来自他人，而来自我们自己。”\n（第五章：认可欲求，上野千鹤子）\n\n“在日常生活中，已经很少有人会直接发表歧视风俗女郎的言论。与美国相比，对性工作者的暴力（包括来自警察的性暴力）或无视其人权的情况在东京也很少出现，相反，她们受到的侮辱和歧视往往来自将尊严摆在不同位置的女性同行。”\n（第六章：能力，铃木凉美）\n\n“我寻求的是“性”关系，而不是爱或认可，所以男人在床上低语的“我爱你”都令我厌恶。我心想，我的性欲是纯洁的，不容玷污。”\n（第六章：能力，上野千鹤子）\n\n“受威胁的不单单是女性的自尊心，男性的自尊心也危在旦夕”。“将身心扔进阴沟的性事”不仅是对自己的侮辱，也是对对方的侮辱。”\n（第六章：能力，上野千鹤子）\n\n“草平大概是想调戏一下雷鸟这位有智慧、有教养、有自尊的女人，看看她会有什么反应。但雷鸟也想试探到底，心想：“我会服从自己的意志，可你有多大的思想觉悟呢？”没有几个男人经受得住这样的考验。草平终究配不上雷鸟。在我看来，器量小的男人夹着尾巴逃跑了，就是这起殉情未遂事件的始末。……《死之棘》的岛尾敏雄是极少数的例外，面对女人赌上全身心施加的考验，他坚持到最后都没有逃避。”\n（第六章：能力，上野千鹤子）\n\n“长久以来，人们认为殉情通常是男人带着女人踏上通往另一个世界的旅程。但富冈老师对《心中天网岛》[4]做出了不同的诠释，她认为女人自己也有去死的理由，是女人把男人拖去了死地。殉情丝毫不意味着爱的圆满。男人和女人因不同的理由赴死，在不同的剧本中同床共枕。\n[4]日本木偶戏的经典剧作，描写相爱的两个人因义理的束缚而无法结合，最终殉情。”\n（第六章：能力，上野千鹤子）\n\n“性观念越是自由、进步，性伴侣就越多。这个标准实在太直白，教我忍俊不禁。从这个角度看，基于自我决定使用自己身体的性工作者也是某种意义上的“独立女性”。这也成了她们尊严的源泉。”\n（第六章：能力，上野千鹤子）\n\n“把易碎品当作易碎品对待。”\n（第六章：能力，上野千鹤子）\n\n“诚然乙武先生[1]有“作为残疾人的当事人性”，伊藤诗织女士也有“作为性暴力受害者的当事人性”。但这种当事人经历写过一次就结束了。人不能反复书写自己的历史。”\n（第七章：工作，上野千鹤子）\n\n“我素来认为，想象力无法超越自身的认知，而现实远超想象……所以我对虚构作品的要求极高，很少有小说能让我觉得有趣。读到无聊的小说时，我只想大吼一声“把时间还给我”。但论文或纪实作品不然，只要能告诉我原本不了解的事实，哪怕文章写得再拙劣，心里都是喜悦胜过烦闷。”\n（第七章：工作，上野千鹤子）\n\n“我还想，如果我不适合做研究，那就让研究来迎合我吧。”\n（第七章：工作，上野千鹤子）\n\n“过于害怕被误解，人就一句话都没法说了。既有正解又有误解也无妨，管它是八二开，还是六四开，只要我觉得正解多于误解，就有勇气继续写下去。”\n（第七章：工作，上野千鹤子）\n\n“据说，如果通知下周停课，日本学生会拍手叫好，美国学生却会嘘声一片，因为他们很清楚自己上的是私立学校，每年要交大约400万日元的学费，理应享受服务。”\n（第七章：工作，上野千鹤子）\n\n“大学院的工作尤其严肃，因为老师培养的是可能在不久的未来成为自己对手的学者。”\n（第七章：工作，上野千鹤子）\n\n“无论面对怎样的困境，都能告诉自己船到桥头自然直，我觉得这种乐观精神是父母的馈赠，不过这背后存在依赖心理。你觉得实在不行了还可以靠父母，当年的我也一样。我曾经在一次鲁莽的旅行中花光了钱，只得打电报回家让父母寄钱来。结果当然是挨了一顿臭骂，但我坚信他们不可能不给我寄钱。”\n（第八章：独立，上野千鹤子）\n\n“女儿最大的叛逆，就是狠狠糟蹋父母无比珍视的自己。但反过来说，女儿越是下得了手，就说明她越相信父母的爱呀。”\n（第八章：独立，上野千鹤子）\n\n“有句话叫“英雄是能够化命运为选择的人”。”\n（第八章：独立，上野千鹤子）\n\n“天职（vocation）、职业（profession）、工作（job）是有区别的。三者重合是无上的幸运，但这样的情况寥寥无几。“无论能不能赚到钱都会做”的是天职，“利用专长谋生的差事”是职业，而工作是“奉人之命的有偿劳动，无关好恶”。除此之外还有爱好（hobby），指自掏腰包也要做的事。”\n（第八章：独立，上野千鹤子）\n\n“想必你已经在写作的乐趣中品尝到了自我表达的愉悦。写作是一种技能。而技能是可以磨炼的。这个过程中最大的陷阱就是自我模仿。不止作家，所有创作者都要面对这样的陷阱。你一旦产生市场价值，买家（编辑）就会约你写“类似于××的东西”，只为复制昔日的辉煌。因为这样最保险稳妥。但越是顺着他们的要求来，你的市场价值就越低。”\n（第八章：独立，上野千鹤子）\n\n““希望你拿出更有意义的作品，为后人铺路搭桥，树立路标，甚至建起庇护所或瞭望塔。””\n（第八章：独立，上野千鹤子）\n\n“想必孩子们正在竭尽全力阻止家庭分崩离析，甚至不惜用自己的身体堵住裂缝。”\n（第八章：独立，上野千鹤子）\n\n“我在夜世界（不限于AV行业）遇到过许多曾经的未成年照顾者，也遇到过正在照顾双亲的人，有男有女。一方面因为夜世界是没有受过多少教育或培训的人也能轻松涉足的行当，另一方面似乎是因为夜世界的工作模式相对灵活，对单亲妈妈和照顾者来说都比较方便。他们的家庭情况各不相同，有的是家人疾病缠身或对某种东西成瘾，需要人照顾，有的则是一直被父母寄生，迟迟无法解脱。但总的来说，我的夜班朋友和熟人显然比大学院、报社的同学和同事更能接受自己对家庭的职责，也认为履行这种职责理所当然。”\n（第九章：团结，铃木凉美）\n\n“东京都内的公寓要好几百万一坪[3]，哪来的地方放书。而建在山里的这栋房子堪比装满书的书库。在空无一人、好似阅览室的空间里独自阅读写作真是太幸福了。”\n（第九章：团结，上野千鹤子）\n\n“话说在结交女性朋友的时候，我一直有意识地和比自己大十岁左右的人来往。要是年龄相差二十或三十岁，你会很难想象那个年纪的自己……但只差十岁的话，便能进入想象力的射程。于是你就会知道“哦……我再过十年会变成这样啊”。”\n（第九章：团结，上野千鹤子）\n\n“在人生的旅途中，也许有人与你同行，也许没有。有旅伴也许是幸运的，也可能不幸。有时候，旅伴确实能为我们的人生增光添彩。不过到头来，终究是孤身一人。只要做好这样的思想准备，便不难做出选择了。”\n（第九章：团结，上野千鹤子）\n\n“既然他们能在家庭之外做好社会的一员，照顾他人的感受，那回到家以后也应该这么做。”\n（第十章：女性主义，上野千鹤子）\n\n“你反复问我“如何能对男人不感到绝望”，我之所以相信别人，是因为遇到了让我觉得值得相信的人，与他们的关系带出了我最纯净美好的一面。人的好与坏取决于关系。恶意会牵出恶意，善意则会得到善意的回报。权力会滋生揣摩上意与阿谀奉承，无助会催生出傲慢和自大。我看某人不顺眼，对方可能觉得我更讨人嫌。也许大家都有狡猾卑劣的一面，若想让自己心中的美好成长壮大，远离计较得失的关系才是明智之举。”\n（第十章：女性主义，上野千鹤子）\n\n“信息提供者会下意识地对采访者潜在的期望做出反应。”\n（第十章：女性主义，上野千鹤子）\n\n“以掏心挖肺的诚实写就的作品，就是出色的文学作品。”\n（第十一章：自由，上野千鹤子）\n\n“文学作品中充满了凄惨的谋杀和性暴力，但没有人嚷嚷着要禁止它们。现实和表达之间的关系非常复杂。有时候，正因为人们在表达中做出了犯罪、杀人、虐待之类的事情，才不至于在现实中这么做。也正是通过这些表达，我们才能深入学习男人、女人和人。这就是为什么我是女性主义者中少有的“表达自由派”。因为我认为想象力是无法管控的。”\n（第十一章：自由，上野千鹤子）\n\n“她们有时候也只在自身处境比较从容的情况下，才能为改善公司制度出力，声讨不合理的规矩。”\n（第十二章：男人，铃木凉美）\n\n“想用钱摆布女人的男人永远不会变少，那就以青春为武器，把他们的钱统统卷走；性骚扰言论永远都不会消失，那就干脆戴着耳塞工作；总有男人想睡单纯的年轻女人，所以要多留个心眼，不要孤男寡女出去喝酒；刚进公司的时候要多讨大叔上司的欢心……像这样绞尽脑汁为自己创造容身之地的过程，确实和学习如何对付色狼的过程相似。即便内心暗藏一定的反抗精神，表面上看起来也是森先生所谓“拎得清”的女人。也许正因为我们只精通逃跑的方法，色狼才没有变少。我也意识到，正因为我们心底已经对男人灰心，认定色狼永远都不可能绝迹，才会优先采取应对策略而非试图改变社会。”\n（第十二章：男人，铃木凉美）\n\n“质疑结构本身（我们这一代容易忽视的事情）和姑且应对当前的现实、以免受到伤害（现在的年轻女性容易忽视的事情）必须两手抓。”\n（第十二章：男人，铃木凉美）\n\n“我殷切希望，社会变革和追求个人幸福可以越来越容易兼容，变革者能够在幸福生活的同时对社会提出抗议，而不至于陷入危险。”\n（第十二章：男人，铃木凉美）\n\n“专门研究性骚扰和家暴的心理咨询师信田小夜子在最近的著作《家庭和国家的共谋》中写道：“承认伤害并非屈服，而是抵抗。”那不是软弱的表现，而是坚忍的证明。”\n（第十二章：男人，上野千鹤子）\n\n“可为什么要由作为受害方的女性出面解决性暴力问题呢？我百思不得其解。男人的问题难道不该由男人来解决吗？是色狼逼得女性不再信任男性，可广大男性为什么不将怒火对准色狼？为什么男性不主动发起打击色狼的运动，还把女性的指控看成诽谤，坚持主张“色狼蒙冤”？最有资格对性骚扰者感到愤怒的就是不会性骚扰的男人，可他们为什么要反过来包庇败类，而不是痛骂？出入风俗店的男人为什么不引以为耻？……男人可真是难懂。”\n（第十二章：男人，上野千鹤子）\n\n“不过我感觉，每一代人接受“男人就是这样”的方式存在一定差异。我母亲那一代将“男人就是这样”作为不可改变的前提，在那样的大环境下她们的生存策略是一味隐忍，“给足男人面子，好好捧着就行了”，并把这种“女性的智慧”传授给了女儿。而她们的女儿，也就是我这代人看着父母的背影长大，心想“这也太荒唐了”，拼命反抗却不断碰壁，遍体鳞伤。你们这一代相当于我们的女儿，也许你们认识到了墙有多厚，以侮蔑男人为代价，学会了如何以更狡猾、更省力的方式活下去。“拎得清才更占便宜”大概也是你们的选项之一。再下一代的年轻女性生于少子化的时代背景，在父母的呵护下长大成人，坚信女人在各方面都不比男人逊色，所以发出了无比正当合理的呼声：“我无法忍受这样的不公！”“岂有此理！”\n（第十二章：男人，上野千鹤子）\n\n“即使在今天，“母性”也要求母亲自我牺牲，但没人要求父亲这么做。”\n（第十二章：男人，上野千鹤子）\n\n“她们不必期望男人说出“我想给你幸福”“我会一辈子保护你”之类的话，而可以抬头挺胸地说：“自己的幸福自己争取！”出现这样一大批“厚着脸皮”优先自身利益的姑娘是我喜闻乐见的，因为男人打从一开始就把自己的利益放在第一位，人都是天生的利己主义者，最看重自己，无关性别。”\n（第十二章：男人，上野千鹤子）\n\n““你现在是谁”比“你过去是谁”重要得多。”\n（第十二章：男人，上野千鹤子）\n\n“聪慧的母亲”能看透女儿的心思，将女儿逼入绝境，借此磨炼她的自我。一个大人倾其一生与你面对面，这也是无比珍贵的馈赠。”\n（第十二章：男人，上野千鹤子）\n\n“我在四十岁出头的时候失去了母亲，只能捧着堆积在我们之间的课题，没完没了地絮絮叨叨。与母亲在一起的时光戛然而止，让我深陷无法挽回的情绪之中。母亲走了一段时间以后，我半夜里给一位女性朋友打电话，感慨万千道：“原来逝者也是会成长的啊……”\n（第十二章：男人，上野千鹤子）\n\n“在与您通信的过程中，我反思最多的便是自己哪怕受到伤害也绝不承认的态度。我总是因此倾向于认定男人不值得当真为之愤怒。不得不承认，正是这种态度导致我缺乏变革的想法，也缺乏对他人的尊重。”\n（代后记，铃木凉美）\n\n“女人受伤的模样会成为男人的消费对象。”\n（代后记，铃木凉美）\n\n“不过这一年的通信确确实实改变了我，您的每一封信仿佛都在我的活法上打了一个问号。”\n（代后记，铃木凉美）\n\n““你现在是谁”比“你过去是谁”重要得多——用温柔来形容您最后的寄语并不贴切。它好似利刃，无比严厉地刺入我的背脊。我会努力改变精明而迟钝的自己，鼓起勇气打破对自身性情的定义，超越种种抵触，去更广阔的天地尽情表达。”\n（代后记，铃木凉美）\n\n“起初我心里也有些忐忑，好在顺顺利利进行了十二轮通信，总共二十四封。这是一场没有海图的航行，每个回合都教人满怀期待，好奇接下来会发生什么。”\n（代后记，上野千鹤子）\n\n“出售性的女人暴露在好奇的视线之下，购买性的男人却从不被质疑。”\n（代后记，上野千鹤子）\n","categories":["读书笔记"],"tags":["摘抄"]}]